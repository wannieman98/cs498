{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEdo-WqY_0x6",
    "outputId": "972942e8-6185-4da4-97d5-4a66408519a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os \n",
    "os.chdir('drive/MyDrive/assignment5/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmxvfq-F6_Db"
   },
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8uhpdVE6_De"
   },
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ms2TG6Bk6_De",
    "outputId": "4769e24a-7a1d-4bf6-a4d2-e8a3d53a4ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install gym pyvirtualdisplay\n",
    "# !sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "iUwBb-v96_Df",
    "outputId": "a5b1ea26-a0d8-40bf-e00d-2e020d4a9757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/15/5041473f5d142ee93bf1593deb8f932e27a078f6f04e2020cf44044f72c5/setuptools-56.2.0-py3-none-any.whl (785kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 18.6MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 24.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 25.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 19.2MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 51kB 11.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 61kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 11.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 92kB 12.9MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 102kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 112kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 122kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 133kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 143kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 153kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 163kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 174kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 184kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 204kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 215kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 225kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 235kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 245kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 256kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 266kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 276kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 286kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 296kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 307kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 317kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 327kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 337kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 348kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 358kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 368kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 378kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 389kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 399kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 409kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 419kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 430kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 440kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 450kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 460kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 471kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 481kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 491kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 501kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 512kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 522kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 532kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 542kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 552kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 563kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 573kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 583kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 593kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 604kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 614kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 624kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 634kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 645kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 655kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 665kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 675kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 686kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 696kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 706kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 716kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 727kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 737kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 747kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 757kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 768kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 778kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 788kB 9.1MB/s \n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "Successfully installed setuptools-56.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ez_setup\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/2c/743df41bd6b3298706dfe91b0c7ecdc47f2dc1a3104abeb6e9aa4a45fa5d/ez_setup-0.9.tar.gz\n",
      "Building wheels for collected packages: ez-setup\n",
      "  Building wheel for ez-setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ez-setup: filename=ez_setup-0.9-cp37-none-any.whl size=11014 sha256=5594dc0762c285c46141a709800680a9ae4fbce159b4bb7797b89537f890c914\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/e8/6b/3d5ff5a3efd7b5338d1e173ac981771e2628ceb2f7866d49ad\n",
      "Successfully built ez-setup\n",
      "Installing collected packages: ez-setup\n",
      "Successfully installed ez-setup-0.9\n",
      "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.4.1)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.6)\n",
      "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.1.2.30)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari]) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install --upgrade setuptools --user\n",
    "# !pip3 install ez_setup \n",
    "# !pip3 install gym[atari] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHkrhfT66_Df"
   },
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tEzMRo8i6_Df"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBbQapga6_Df"
   },
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xO4mEfO6_Df"
   },
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2qVbiIKB6_Df"
   },
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNIscus5KnCW",
    "outputId": "1c57c761-932c-486f-b162-bd0b21739fe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6xYO68ky6_Dg"
   },
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qo9KUDo6_Dg"
   },
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLXPkoUl6_Dg"
   },
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X16PhFjK6_Dg"
   },
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "  from agent_double import Agent\n",
    "else:\n",
    "  from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "train_frame = 100\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBKlpaEr6_Dg"
   },
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSbSqiOY6_Dg"
   },
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6mwVM-WN6_Dg",
    "outputId": "302ca7a3-90cd-4fc7-a1d6-2cd1e845e760",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/assignment5/agent.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state_values[musk] = self.policy_net(torch.tensor(next_states, device = device)[musk]).max(1)[0].detach()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 0.0   memory length: 123   epsilon: 0.999952480000001    steps: 123    lr: 0.0001     evaluation reward: 0.0\n",
      "episode: 1   score: 0.0   memory length: 246   epsilon: 0.9997089400000063    steps: 123    lr: 0.0001     evaluation reward: 0.0\n",
      "episode: 2   score: 2.0   memory length: 444   epsilon: 0.9993169000000148    steps: 198    lr: 0.0001     evaluation reward: 0.6666666666666666\n",
      "episode: 3   score: 0.0   memory length: 567   epsilon: 0.9990733600000201    steps: 123    lr: 0.0001     evaluation reward: 0.5\n",
      "episode: 4   score: 2.0   memory length: 784   epsilon: 0.9986437000000294    steps: 217    lr: 0.0001     evaluation reward: 0.8\n",
      "episode: 5   score: 3.0   memory length: 1010   epsilon: 0.9981962200000392    steps: 226    lr: 0.0001     evaluation reward: 1.1666666666666667\n",
      "episode: 6   score: 3.0   memory length: 1264   epsilon: 0.9976933000000501    steps: 254    lr: 0.0001     evaluation reward: 1.4285714285714286\n",
      "episode: 7   score: 1.0   memory length: 1415   epsilon: 0.9973943200000566    steps: 151    lr: 0.0001     evaluation reward: 1.375\n",
      "episode: 8   score: 0.0   memory length: 1537   epsilon: 0.9971527600000618    steps: 122    lr: 0.0001     evaluation reward: 1.2222222222222223\n",
      "episode: 9   score: 2.0   memory length: 1735   epsilon: 0.9967607200000703    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 10   score: 3.0   memory length: 1963   epsilon: 0.9963092800000801    steps: 228    lr: 0.0001     evaluation reward: 1.4545454545454546\n",
      "episode: 11   score: 0.0   memory length: 2085   epsilon: 0.9960677200000854    steps: 122    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 12   score: 2.0   memory length: 2283   epsilon: 0.9956756800000939    steps: 198    lr: 0.0001     evaluation reward: 1.3846153846153846\n",
      "episode: 13   score: 2.0   memory length: 2500   epsilon: 0.9952460200001032    steps: 217    lr: 0.0001     evaluation reward: 1.4285714285714286\n",
      "episode: 14   score: 3.0   memory length: 2747   epsilon: 0.9947569600001138    steps: 247    lr: 0.0001     evaluation reward: 1.5333333333333334\n",
      "episode: 15   score: 3.0   memory length: 3010   epsilon: 0.9942362200001251    steps: 263    lr: 0.0001     evaluation reward: 1.625\n",
      "episode: 16   score: 1.0   memory length: 3179   epsilon: 0.9939016000001324    steps: 169    lr: 0.0001     evaluation reward: 1.588235294117647\n",
      "episode: 17   score: 0.0   memory length: 3302   epsilon: 0.9936580600001377    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 18   score: 2.0   memory length: 3519   epsilon: 0.993228400000147    steps: 217    lr: 0.0001     evaluation reward: 1.5263157894736843\n",
      "episode: 19   score: 3.0   memory length: 3766   epsilon: 0.9927393400001576    steps: 247    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 20   score: 0.0   memory length: 3888   epsilon: 0.9924977800001629    steps: 122    lr: 0.0001     evaluation reward: 1.5238095238095237\n",
      "episode: 21   score: 5.0   memory length: 4212   epsilon: 0.9918562600001768    steps: 324    lr: 0.0001     evaluation reward: 1.6818181818181819\n",
      "episode: 22   score: 0.0   memory length: 4335   epsilon: 0.9916127200001821    steps: 123    lr: 0.0001     evaluation reward: 1.608695652173913\n",
      "episode: 23   score: 2.0   memory length: 4532   epsilon: 0.9912226600001905    steps: 197    lr: 0.0001     evaluation reward: 1.625\n",
      "episode: 24   score: 2.0   memory length: 4711   epsilon: 0.9908682400001982    steps: 179    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 25   score: 2.0   memory length: 4928   epsilon: 0.9904385800002076    steps: 217    lr: 0.0001     evaluation reward: 1.6538461538461537\n",
      "episode: 26   score: 1.0   memory length: 5099   epsilon: 0.9901000000002149    steps: 171    lr: 0.0001     evaluation reward: 1.6296296296296295\n",
      "episode: 27   score: 0.0   memory length: 5222   epsilon: 0.9898564600002202    steps: 123    lr: 0.0001     evaluation reward: 1.5714285714285714\n",
      "episode: 28   score: 2.0   memory length: 5420   epsilon: 0.9894644200002287    steps: 198    lr: 0.0001     evaluation reward: 1.5862068965517242\n",
      "episode: 29   score: 0.0   memory length: 5543   epsilon: 0.989220880000234    steps: 123    lr: 0.0001     evaluation reward: 1.5333333333333334\n",
      "episode: 30   score: 1.0   memory length: 5712   epsilon: 0.9888862600002413    steps: 169    lr: 0.0001     evaluation reward: 1.5161290322580645\n",
      "episode: 31   score: 2.0   memory length: 5910   epsilon: 0.9884942200002498    steps: 198    lr: 0.0001     evaluation reward: 1.53125\n",
      "episode: 32   score: 0.0   memory length: 6033   epsilon: 0.9882506800002551    steps: 123    lr: 0.0001     evaluation reward: 1.4848484848484849\n",
      "episode: 33   score: 1.0   memory length: 6184   epsilon: 0.9879517000002616    steps: 151    lr: 0.0001     evaluation reward: 1.4705882352941178\n",
      "episode: 34   score: 0.0   memory length: 6307   epsilon: 0.9877081600002668    steps: 123    lr: 0.0001     evaluation reward: 1.4285714285714286\n",
      "episode: 35   score: 2.0   memory length: 6504   epsilon: 0.9873181000002753    steps: 197    lr: 0.0001     evaluation reward: 1.4444444444444444\n",
      "episode: 36   score: 2.0   memory length: 6724   epsilon: 0.9868825000002848    steps: 220    lr: 0.0001     evaluation reward: 1.4594594594594594\n",
      "episode: 37   score: 0.0   memory length: 6847   epsilon: 0.98663896000029    steps: 123    lr: 0.0001     evaluation reward: 1.4210526315789473\n",
      "episode: 38   score: 1.0   memory length: 7018   epsilon: 0.9863003800002974    steps: 171    lr: 0.0001     evaluation reward: 1.4102564102564104\n",
      "episode: 39   score: 1.0   memory length: 7186   epsilon: 0.9859677400003046    steps: 168    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 40   score: 0.0   memory length: 7309   epsilon: 0.9857242000003099    steps: 123    lr: 0.0001     evaluation reward: 1.3658536585365855\n",
      "episode: 41   score: 0.0   memory length: 7432   epsilon: 0.9854806600003152    steps: 123    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 42   score: 0.0   memory length: 7555   epsilon: 0.9852371200003205    steps: 123    lr: 0.0001     evaluation reward: 1.302325581395349\n",
      "episode: 43   score: 0.0   memory length: 7678   epsilon: 0.9849935800003258    steps: 123    lr: 0.0001     evaluation reward: 1.2727272727272727\n",
      "episode: 44   score: 3.0   memory length: 7927   epsilon: 0.9845005600003365    steps: 249    lr: 0.0001     evaluation reward: 1.3111111111111111\n",
      "episode: 45   score: 2.0   memory length: 8143   epsilon: 0.9840728800003458    steps: 216    lr: 0.0001     evaluation reward: 1.326086956521739\n",
      "episode: 46   score: 1.0   memory length: 8294   epsilon: 0.9837739000003523    steps: 151    lr: 0.0001     evaluation reward: 1.3191489361702127\n",
      "episode: 47   score: 2.0   memory length: 8492   epsilon: 0.9833818600003608    steps: 198    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 48   score: 0.0   memory length: 8615   epsilon: 0.983138320000366    steps: 123    lr: 0.0001     evaluation reward: 1.3061224489795917\n",
      "episode: 49   score: 1.0   memory length: 8786   epsilon: 0.9827997400003734    steps: 171    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 50   score: 2.0   memory length: 8983   epsilon: 0.9824096800003819    steps: 197    lr: 0.0001     evaluation reward: 1.3137254901960784\n",
      "episode: 51   score: 2.0   memory length: 9180   epsilon: 0.9820196200003903    steps: 197    lr: 0.0001     evaluation reward: 1.3269230769230769\n",
      "episode: 52   score: 0.0   memory length: 9303   epsilon: 0.9817760800003956    steps: 123    lr: 0.0001     evaluation reward: 1.3018867924528301\n",
      "episode: 53   score: 1.0   memory length: 9471   epsilon: 0.9814434400004028    steps: 168    lr: 0.0001     evaluation reward: 1.2962962962962963\n",
      "episode: 54   score: 2.0   memory length: 9689   epsilon: 0.9810118000004122    steps: 218    lr: 0.0001     evaluation reward: 1.309090909090909\n",
      "episode: 55   score: 0.0   memory length: 9811   epsilon: 0.9807702400004175    steps: 122    lr: 0.0001     evaluation reward: 1.2857142857142858\n",
      "episode: 56   score: 1.0   memory length: 9962   epsilon: 0.980471260000424    steps: 151    lr: 0.0001     evaluation reward: 1.280701754385965\n",
      "episode: 57   score: 1.0   memory length: 10132   epsilon: 0.9801346600004313    steps: 170    lr: 0.0001     evaluation reward: 1.2758620689655173\n",
      "episode: 58   score: 2.0   memory length: 10349   epsilon: 0.9797050000004406    steps: 217    lr: 0.0001     evaluation reward: 1.2881355932203389\n",
      "episode: 59   score: 2.0   memory length: 10547   epsilon: 0.9793129600004491    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 60   score: 0.0   memory length: 10670   epsilon: 0.9790694200004544    steps: 123    lr: 0.0001     evaluation reward: 1.278688524590164\n",
      "episode: 61   score: 2.0   memory length: 10868   epsilon: 0.9786773800004629    steps: 198    lr: 0.0001     evaluation reward: 1.2903225806451613\n",
      "episode: 62   score: 2.0   memory length: 11087   epsilon: 0.9782437600004723    steps: 219    lr: 0.0001     evaluation reward: 1.3015873015873016\n",
      "episode: 63   score: 0.0   memory length: 11209   epsilon: 0.9780022000004776    steps: 122    lr: 0.0001     evaluation reward: 1.28125\n",
      "episode: 64   score: 1.0   memory length: 11378   epsilon: 0.9776675800004848    steps: 169    lr: 0.0001     evaluation reward: 1.2769230769230768\n",
      "episode: 65   score: 3.0   memory length: 11623   epsilon: 0.9771824800004953    steps: 245    lr: 0.0001     evaluation reward: 1.303030303030303\n",
      "episode: 66   score: 2.0   memory length: 11821   epsilon: 0.9767904400005039    steps: 198    lr: 0.0001     evaluation reward: 1.3134328358208955\n",
      "episode: 67   score: 3.0   memory length: 12088   epsilon: 0.9762617800005153    steps: 267    lr: 0.0001     evaluation reward: 1.338235294117647\n",
      "episode: 68   score: 0.0   memory length: 12211   epsilon: 0.9760182400005206    steps: 123    lr: 0.0001     evaluation reward: 1.318840579710145\n",
      "episode: 69   score: 0.0   memory length: 12334   epsilon: 0.9757747000005259    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 70   score: 2.0   memory length: 12533   epsilon: 0.9753806800005345    steps: 199    lr: 0.0001     evaluation reward: 1.3098591549295775\n",
      "episode: 71   score: 3.0   memory length: 12779   epsilon: 0.974893600000545    steps: 246    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 72   score: 0.0   memory length: 12902   epsilon: 0.9746500600005503    steps: 123    lr: 0.0001     evaluation reward: 1.3150684931506849\n",
      "episode: 73   score: 1.0   memory length: 13071   epsilon: 0.9743154400005576    steps: 169    lr: 0.0001     evaluation reward: 1.3108108108108107\n",
      "episode: 74   score: 2.0   memory length: 13288   epsilon: 0.9738857800005669    steps: 217    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 75   score: 0.0   memory length: 13411   epsilon: 0.9736422400005722    steps: 123    lr: 0.0001     evaluation reward: 1.3026315789473684\n",
      "episode: 76   score: 1.0   memory length: 13562   epsilon: 0.9733432600005787    steps: 151    lr: 0.0001     evaluation reward: 1.2987012987012987\n",
      "episode: 77   score: 1.0   memory length: 13713   epsilon: 0.9730442800005852    steps: 151    lr: 0.0001     evaluation reward: 1.294871794871795\n",
      "episode: 78   score: 2.0   memory length: 13892   epsilon: 0.9726898600005929    steps: 179    lr: 0.0001     evaluation reward: 1.3037974683544304\n",
      "episode: 79   score: 2.0   memory length: 14090   epsilon: 0.9722978200006014    steps: 198    lr: 0.0001     evaluation reward: 1.3125\n",
      "episode: 80   score: 2.0   memory length: 14308   epsilon: 0.9718661800006108    steps: 218    lr: 0.0001     evaluation reward: 1.3209876543209877\n",
      "episode: 81   score: 0.0   memory length: 14430   epsilon: 0.971624620000616    steps: 122    lr: 0.0001     evaluation reward: 1.3048780487804879\n",
      "episode: 82   score: 0.0   memory length: 14552   epsilon: 0.9713830600006212    steps: 122    lr: 0.0001     evaluation reward: 1.2891566265060241\n",
      "episode: 83   score: 2.0   memory length: 14749   epsilon: 0.9709930000006297    steps: 197    lr: 0.0001     evaluation reward: 1.2976190476190477\n",
      "episode: 84   score: 2.0   memory length: 14968   epsilon: 0.9705593800006391    steps: 219    lr: 0.0001     evaluation reward: 1.3058823529411765\n",
      "episode: 85   score: 0.0   memory length: 15091   epsilon: 0.9703158400006444    steps: 123    lr: 0.0001     evaluation reward: 1.2906976744186047\n",
      "episode: 86   score: 0.0   memory length: 15214   epsilon: 0.9700723000006497    steps: 123    lr: 0.0001     evaluation reward: 1.2758620689655173\n",
      "episode: 87   score: 0.0   memory length: 15337   epsilon: 0.969828760000655    steps: 123    lr: 0.0001     evaluation reward: 1.2613636363636365\n",
      "episode: 88   score: 0.0   memory length: 15460   epsilon: 0.9695852200006603    steps: 123    lr: 0.0001     evaluation reward: 1.247191011235955\n",
      "episode: 89   score: 5.0   memory length: 15787   epsilon: 0.9689377600006743    steps: 327    lr: 0.0001     evaluation reward: 1.288888888888889\n",
      "episode: 90   score: 0.0   memory length: 15910   epsilon: 0.9686942200006796    steps: 123    lr: 0.0001     evaluation reward: 1.2747252747252746\n",
      "episode: 91   score: 1.0   memory length: 16062   epsilon: 0.9683932600006862    steps: 152    lr: 0.0001     evaluation reward: 1.2717391304347827\n",
      "episode: 92   score: 0.0   memory length: 16185   epsilon: 0.9681497200006914    steps: 123    lr: 0.0001     evaluation reward: 1.2580645161290323\n",
      "episode: 93   score: 0.0   memory length: 16308   epsilon: 0.9679061800006967    steps: 123    lr: 0.0001     evaluation reward: 1.2446808510638299\n",
      "episode: 94   score: 1.0   memory length: 16478   epsilon: 0.967569580000704    steps: 170    lr: 0.0001     evaluation reward: 1.2421052631578948\n",
      "episode: 95   score: 3.0   memory length: 16703   epsilon: 0.9671240800007137    steps: 225    lr: 0.0001     evaluation reward: 1.2604166666666667\n",
      "episode: 96   score: 0.0   memory length: 16826   epsilon: 0.966880540000719    steps: 123    lr: 0.0001     evaluation reward: 1.2474226804123711\n",
      "episode: 97   score: 3.0   memory length: 17070   epsilon: 0.9663974200007295    steps: 244    lr: 0.0001     evaluation reward: 1.2653061224489797\n",
      "episode: 98   score: 1.0   memory length: 17220   epsilon: 0.9661004200007359    steps: 150    lr: 0.0001     evaluation reward: 1.2626262626262625\n",
      "episode: 99   score: 1.0   memory length: 17371   epsilon: 0.9658014400007424    steps: 151    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 100   score: 1.0   memory length: 17540   epsilon: 0.9654668200007497    steps: 169    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 101   score: 1.0   memory length: 17709   epsilon: 0.965132200000757    steps: 169    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 102   score: 0.0   memory length: 17832   epsilon: 0.9648886600007622    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 103   score: 0.0   memory length: 17954   epsilon: 0.9646471000007675    steps: 122    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 104   score: 1.0   memory length: 18124   epsilon: 0.9643105000007748    steps: 170    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 105   score: 3.0   memory length: 18368   epsilon: 0.9638273800007853    steps: 244    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 106   score: 3.0   memory length: 18612   epsilon: 0.9633442600007958    steps: 244    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 107   score: 0.0   memory length: 18734   epsilon: 0.963102700000801    steps: 122    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 108   score: 3.0   memory length: 18963   epsilon: 0.9626492800008108    steps: 229    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 109   score: 0.0   memory length: 19086   epsilon: 0.9624057400008161    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 110   score: 1.0   memory length: 19254   epsilon: 0.9620731000008234    steps: 168    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 111   score: 1.0   memory length: 19422   epsilon: 0.9617404600008306    steps: 168    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 112   score: 0.0   memory length: 19545   epsilon: 0.9614969200008359    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 113   score: 4.0   memory length: 19859   epsilon: 0.9608752000008494    steps: 314    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 114   score: 1.0   memory length: 20028   epsilon: 0.9605405800008566    steps: 169    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 115   score: 2.0   memory length: 20226   epsilon: 0.9601485400008651    steps: 198    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 116   score: 1.0   memory length: 20398   epsilon: 0.9598079800008725    steps: 172    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 117   score: 0.0   memory length: 20520   epsilon: 0.9595664200008778    steps: 122    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 118   score: 3.0   memory length: 20768   epsilon: 0.9590753800008884    steps: 248    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 119   score: 4.0   memory length: 21045   epsilon: 0.9585269200009003    steps: 277    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 120   score: 2.0   memory length: 21242   epsilon: 0.9581368600009088    steps: 197    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 121   score: 1.0   memory length: 21414   epsilon: 0.9577963000009162    steps: 172    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 122   score: 1.0   memory length: 21564   epsilon: 0.9574993000009226    steps: 150    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 123   score: 3.0   memory length: 21831   epsilon: 0.9569706400009341    steps: 267    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 124   score: 1.0   memory length: 22000   epsilon: 0.9566360200009414    steps: 169    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 125   score: 1.0   memory length: 22153   epsilon: 0.956333080000948    steps: 153    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 126   score: 2.0   memory length: 22368   epsilon: 0.9559073800009572    steps: 215    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 127   score: 2.0   memory length: 22589   epsilon: 0.9554698000009667    steps: 221    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 128   score: 0.0   memory length: 22711   epsilon: 0.955228240000972    steps: 122    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 129   score: 0.0   memory length: 22834   epsilon: 0.9549847000009772    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 130   score: 3.0   memory length: 23062   epsilon: 0.954533260000987    steps: 228    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 131   score: 0.0   memory length: 23185   epsilon: 0.9542897200009923    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 132   score: 0.0   memory length: 23307   epsilon: 0.9540481600009976    steps: 122    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 133   score: 2.0   memory length: 23505   epsilon: 0.9536561200010061    steps: 198    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 134   score: 0.0   memory length: 23628   epsilon: 0.9534125800010114    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 135   score: 0.0   memory length: 23751   epsilon: 0.9531690400010167    steps: 123    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 136   score: 2.0   memory length: 23949   epsilon: 0.9527770000010252    steps: 198    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 137   score: 2.0   memory length: 24169   epsilon: 0.9523414000010346    steps: 220    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 138   score: 2.0   memory length: 24367   epsilon: 0.9519493600010431    steps: 198    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 139   score: 0.0   memory length: 24490   epsilon: 0.9517058200010484    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 140   score: 0.0   memory length: 24613   epsilon: 0.9514622800010537    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 141   score: 2.0   memory length: 24812   epsilon: 0.9510682600010623    steps: 199    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 142   score: 0.0   memory length: 24935   epsilon: 0.9508247200010675    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 143   score: 0.0   memory length: 25057   epsilon: 0.9505831600010728    steps: 122    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 144   score: 2.0   memory length: 25277   epsilon: 0.9501475600010822    steps: 220    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 145   score: 1.0   memory length: 25446   epsilon: 0.9498129400010895    steps: 169    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 146   score: 2.0   memory length: 25662   epsilon: 0.9493852600010988    steps: 216    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 147   score: 0.0   memory length: 25784   epsilon: 0.949143700001104    steps: 122    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 148   score: 3.0   memory length: 26052   epsilon: 0.9486130600011156    steps: 268    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 149   score: 2.0   memory length: 26252   epsilon: 0.9482170600011242    steps: 200    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 150   score: 0.0   memory length: 26374   epsilon: 0.9479755000011294    steps: 122    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 151   score: 2.0   memory length: 26572   epsilon: 0.9475834600011379    steps: 198    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 152   score: 0.0   memory length: 26695   epsilon: 0.9473399200011432    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 153   score: 3.0   memory length: 26921   epsilon: 0.9468924400011529    steps: 226    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 154   score: 2.0   memory length: 27138   epsilon: 0.9464627800011622    steps: 217    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 155   score: 1.0   memory length: 27309   epsilon: 0.9461242000011696    steps: 171    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 156   score: 1.0   memory length: 27479   epsilon: 0.9457876000011769    steps: 170    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 157   score: 0.0   memory length: 27602   epsilon: 0.9455440600011822    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 158   score: 2.0   memory length: 27818   epsilon: 0.9451163800011915    steps: 216    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 159   score: 0.0   memory length: 27941   epsilon: 0.9448728400011968    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 160   score: 4.0   memory length: 28236   epsilon: 0.9442887400012094    steps: 295    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 161   score: 2.0   memory length: 28453   epsilon: 0.9438590800012188    steps: 217    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 162   score: 0.0   memory length: 28576   epsilon: 0.943615540001224    steps: 123    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 163   score: 0.0   memory length: 28698   epsilon: 0.9433739800012293    steps: 122    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 164   score: 1.0   memory length: 28849   epsilon: 0.9430750000012358    steps: 151    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 165   score: 3.0   memory length: 29097   epsilon: 0.9425839600012464    steps: 248    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 166   score: 0.0   memory length: 29220   epsilon: 0.9423404200012517    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 167   score: 1.0   memory length: 29389   epsilon: 0.942005800001259    steps: 169    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 168   score: 0.0   memory length: 29511   epsilon: 0.9417642400012642    steps: 122    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 169   score: 0.0   memory length: 29634   epsilon: 0.9415207000012695    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 170   score: 0.0   memory length: 29757   epsilon: 0.9412771600012748    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 171   score: 2.0   memory length: 29955   epsilon: 0.9408851200012833    steps: 198    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 172   score: 1.0   memory length: 30105   epsilon: 0.9405881200012898    steps: 150    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 173   score: 1.0   memory length: 30274   epsilon: 0.940253500001297    steps: 169    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 174   score: 1.0   memory length: 30444   epsilon: 0.9399169000013043    steps: 170    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 175   score: 1.0   memory length: 30596   epsilon: 0.9396159400013109    steps: 152    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 176   score: 1.0   memory length: 30748   epsilon: 0.9393149800013174    steps: 152    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 177   score: 1.0   memory length: 30899   epsilon: 0.9390160000013239    steps: 151    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 178   score: 0.0   memory length: 31022   epsilon: 0.9387724600013292    steps: 123    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 179   score: 0.0   memory length: 31144   epsilon: 0.9385309000013344    steps: 122    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 180   score: 5.0   memory length: 31466   epsilon: 0.9378933400013483    steps: 322    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 181   score: 1.0   memory length: 31637   epsilon: 0.9375547600013556    steps: 171    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 182   score: 0.0   memory length: 31760   epsilon: 0.9373112200013609    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 183   score: 0.0   memory length: 31883   epsilon: 0.9370676800013662    steps: 123    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 184   score: 2.0   memory length: 32081   epsilon: 0.9366756400013747    steps: 198    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 185   score: 3.0   memory length: 32327   epsilon: 0.9361885600013853    steps: 246    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 186   score: 0.0   memory length: 32450   epsilon: 0.9359450200013906    steps: 123    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 187   score: 3.0   memory length: 32713   epsilon: 0.9354242800014019    steps: 263    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 188   score: 3.0   memory length: 32980   epsilon: 0.9348956200014134    steps: 267    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 189   score: 2.0   memory length: 33178   epsilon: 0.9345035800014219    steps: 198    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 190   score: 3.0   memory length: 33406   epsilon: 0.9340521400014317    steps: 228    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 191   score: 0.0   memory length: 33528   epsilon: 0.9338105800014369    steps: 122    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 192   score: 2.0   memory length: 33726   epsilon: 0.9334185400014454    steps: 198    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 193   score: 2.0   memory length: 33924   epsilon: 0.9330265000014539    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 194   score: 1.0   memory length: 34074   epsilon: 0.9327295000014604    steps: 150    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 195   score: 2.0   memory length: 34294   epsilon: 0.9322939000014698    steps: 220    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 196   score: 2.0   memory length: 34495   epsilon: 0.9318959200014785    steps: 201    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 197   score: 1.0   memory length: 34664   epsilon: 0.9315613000014857    steps: 169    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 198   score: 0.0   memory length: 34786   epsilon: 0.931319740001491    steps: 122    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 199   score: 0.0   memory length: 34909   epsilon: 0.9310762000014963    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 200   score: 2.0   memory length: 35106   epsilon: 0.9306861400015047    steps: 197    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 201   score: 0.0   memory length: 35229   epsilon: 0.93044260000151    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 202   score: 2.0   memory length: 35427   epsilon: 0.9300505600015185    steps: 198    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 203   score: 0.0   memory length: 35549   epsilon: 0.9298090000015238    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 204   score: 3.0   memory length: 35797   epsilon: 0.9293179600015344    steps: 248    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 205   score: 2.0   memory length: 35997   epsilon: 0.928921960001543    steps: 200    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 206   score: 0.0   memory length: 36120   epsilon: 0.9286784200015483    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 207   score: 0.0   memory length: 36243   epsilon: 0.9284348800015536    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 208   score: 1.0   memory length: 36414   epsilon: 0.928096300001561    steps: 171    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 209   score: 4.0   memory length: 36689   epsilon: 0.9275518000015728    steps: 275    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 210   score: 1.0   memory length: 36839   epsilon: 0.9272548000015792    steps: 150    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 211   score: 1.0   memory length: 37011   epsilon: 0.9269142400015866    steps: 172    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 212   score: 2.0   memory length: 37209   epsilon: 0.9265222000015951    steps: 198    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 213   score: 2.0   memory length: 37410   epsilon: 0.9261242200016038    steps: 201    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 214   score: 2.0   memory length: 37630   epsilon: 0.9256886200016132    steps: 220    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 215   score: 1.0   memory length: 37780   epsilon: 0.9253916200016197    steps: 150    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 216   score: 0.0   memory length: 37903   epsilon: 0.925148080001625    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 217   score: 0.0   memory length: 38026   epsilon: 0.9249045400016302    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 218   score: 1.0   memory length: 38176   epsilon: 0.9246075400016367    steps: 150    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 219   score: 0.0   memory length: 38298   epsilon: 0.9243659800016419    steps: 122    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 220   score: 0.0   memory length: 38420   epsilon: 0.9241244200016472    steps: 122    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 221   score: 1.0   memory length: 38590   epsilon: 0.9237878200016545    steps: 170    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 222   score: 1.0   memory length: 38741   epsilon: 0.923488840001661    steps: 151    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 223   score: 0.0   memory length: 38863   epsilon: 0.9232472800016662    steps: 122    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 224   score: 0.0   memory length: 38986   epsilon: 0.9230037400016715    steps: 123    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 225   score: 0.0   memory length: 39109   epsilon: 0.9227602000016768    steps: 123    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 226   score: 2.0   memory length: 39326   epsilon: 0.9223305400016861    steps: 217    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 227   score: 2.0   memory length: 39529   epsilon: 0.9219286000016949    steps: 203    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 228   score: 3.0   memory length: 39756   epsilon: 0.9214791400017046    steps: 227    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 229   score: 1.0   memory length: 39924   epsilon: 0.9211465000017118    steps: 168    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 230   score: 1.0   memory length: 40075   epsilon: 0.9208475200017183    steps: 151    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 231   score: 3.0   memory length: 40300   epsilon: 0.920402020001728    steps: 225    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 232   score: 4.0   memory length: 40596   epsilon: 0.9198159400017407    steps: 296    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 233   score: 0.0   memory length: 40719   epsilon: 0.919572400001746    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 234   score: 0.0   memory length: 40842   epsilon: 0.9193288600017513    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 235   score: 3.0   memory length: 41106   epsilon: 0.9188061400017626    steps: 264    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 236   score: 1.0   memory length: 41257   epsilon: 0.9185071600017691    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 237   score: 0.0   memory length: 41380   epsilon: 0.9182636200017744    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 238   score: 1.0   memory length: 41530   epsilon: 0.9179666200017809    steps: 150    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 239   score: 2.0   memory length: 41728   epsilon: 0.9175745800017894    steps: 198    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 240   score: 4.0   memory length: 41983   epsilon: 0.9170696800018003    steps: 255    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 241   score: 1.0   memory length: 42153   epsilon: 0.9167330800018076    steps: 170    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 242   score: 3.0   memory length: 42404   epsilon: 0.9162361000018184    steps: 251    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 243   score: 1.0   memory length: 42554   epsilon: 0.9159391000018249    steps: 150    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 244   score: 1.0   memory length: 42705   epsilon: 0.9156401200018314    steps: 151    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 245   score: 5.0   memory length: 43014   epsilon: 0.9150283000018447    steps: 309    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 246   score: 2.0   memory length: 43232   epsilon: 0.914596660001854    steps: 218    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 247   score: 3.0   memory length: 43441   epsilon: 0.914182840001863    steps: 209    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 248   score: 1.0   memory length: 43612   epsilon: 0.9138442600018704    steps: 171    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 249   score: 1.0   memory length: 43782   epsilon: 0.9135076600018777    steps: 170    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 250   score: 1.0   memory length: 43951   epsilon: 0.9131730400018849    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 251   score: 2.0   memory length: 44149   epsilon: 0.9127810000018934    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 252   score: 4.0   memory length: 44445   epsilon: 0.9121949200019062    steps: 296    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 253   score: 0.0   memory length: 44568   epsilon: 0.9119513800019114    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 254   score: 0.0   memory length: 44691   epsilon: 0.9117078400019167    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 255   score: 2.0   memory length: 44911   epsilon: 0.9112722400019262    steps: 220    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 256   score: 2.0   memory length: 45109   epsilon: 0.9108802000019347    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 257   score: 2.0   memory length: 45307   epsilon: 0.9104881600019432    steps: 198    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 258   score: 3.0   memory length: 45553   epsilon: 0.9100010800019538    steps: 246    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 259   score: 1.0   memory length: 45724   epsilon: 0.9096625000019611    steps: 171    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 260   score: 1.0   memory length: 45895   epsilon: 0.9093239200019685    steps: 171    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 261   score: 3.0   memory length: 46108   epsilon: 0.9089021800019776    steps: 213    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 262   score: 1.0   memory length: 46278   epsilon: 0.908565580001985    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 263   score: 3.0   memory length: 46510   epsilon: 0.9081062200019949    steps: 232    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 264   score: 2.0   memory length: 46693   epsilon: 0.9077438800020028    steps: 183    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 265   score: 3.0   memory length: 46940   epsilon: 0.9072548200020134    steps: 247    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 266   score: 5.0   memory length: 47266   epsilon: 0.9066093400020274    steps: 326    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 267   score: 0.0   memory length: 47389   epsilon: 0.9063658000020327    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 268   score: 3.0   memory length: 47602   epsilon: 0.9059440600020419    steps: 213    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 269   score: 2.0   memory length: 47800   epsilon: 0.9055520200020504    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 270   score: 2.0   memory length: 47997   epsilon: 0.9051619600020588    steps: 197    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 271   score: 0.0   memory length: 48119   epsilon: 0.9049204000020641    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 272   score: 2.0   memory length: 48317   epsilon: 0.9045283600020726    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 273   score: 2.0   memory length: 48533   epsilon: 0.9041006800020819    steps: 216    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 274   score: 0.0   memory length: 48656   epsilon: 0.9038571400020872    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 275   score: 0.0   memory length: 48779   epsilon: 0.9036136000020925    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 276   score: 1.0   memory length: 48931   epsilon: 0.903312640002099    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 277   score: 0.0   memory length: 49054   epsilon: 0.9030691000021043    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 278   score: 1.0   memory length: 49204   epsilon: 0.9027721000021107    steps: 150    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 279   score: 0.0   memory length: 49327   epsilon: 0.902528560002116    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 280   score: 4.0   memory length: 49615   epsilon: 0.9019583200021284    steps: 288    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 281   score: 2.0   memory length: 49815   epsilon: 0.901562320002137    steps: 200    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 282   score: 2.0   memory length: 50033   epsilon: 0.9011306800021464    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 283   score: 3.0   memory length: 50298   epsilon: 0.9006059800021577    steps: 265    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 284   score: 2.0   memory length: 50496   epsilon: 0.9002139400021663    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 285   score: 0.0   memory length: 50619   epsilon: 0.8999704000021715    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 286   score: 2.0   memory length: 50819   epsilon: 0.8995744000021801    steps: 200    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 287   score: 4.0   memory length: 51076   epsilon: 0.8990655400021912    steps: 257    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 288   score: 1.0   memory length: 51227   epsilon: 0.8987665600021977    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 289   score: 1.0   memory length: 51396   epsilon: 0.8984319400022049    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 290   score: 3.0   memory length: 51625   epsilon: 0.8979785200022148    steps: 229    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 291   score: 6.0   memory length: 51978   epsilon: 0.89727958000223    steps: 353    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 292   score: 3.0   memory length: 52221   epsilon: 0.8967984400022404    steps: 243    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 293   score: 0.0   memory length: 52344   epsilon: 0.8965549000022457    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 294   score: 0.0   memory length: 52467   epsilon: 0.896311360002251    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 295   score: 2.0   memory length: 52667   epsilon: 0.8959153600022596    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 296   score: 3.0   memory length: 52931   epsilon: 0.8953926400022709    steps: 264    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 297   score: 0.0   memory length: 53054   epsilon: 0.8951491000022762    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 298   score: 2.0   memory length: 53254   epsilon: 0.8947531000022848    steps: 200    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 299   score: 1.0   memory length: 53422   epsilon: 0.894420460002292    steps: 168    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 300   score: 2.0   memory length: 53620   epsilon: 0.8940284200023005    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 301   score: 1.0   memory length: 53771   epsilon: 0.893729440002307    steps: 151    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 302   score: 0.0   memory length: 53894   epsilon: 0.8934859000023123    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 303   score: 0.0   memory length: 54017   epsilon: 0.8932423600023176    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 304   score: 2.0   memory length: 54214   epsilon: 0.8928523000023261    steps: 197    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 305   score: 0.0   memory length: 54337   epsilon: 0.8926087600023314    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 306   score: 0.0   memory length: 54460   epsilon: 0.8923652200023366    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 307   score: 1.0   memory length: 54611   epsilon: 0.8920662400023431    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 308   score: 1.0   memory length: 54780   epsilon: 0.8917316200023504    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 309   score: 1.0   memory length: 54948   epsilon: 0.8913989800023576    steps: 168    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 310   score: 2.0   memory length: 55148   epsilon: 0.8910029800023662    steps: 200    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 311   score: 1.0   memory length: 55317   epsilon: 0.8906683600023735    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 312   score: 0.0   memory length: 55439   epsilon: 0.8904268000023787    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 313   score: 3.0   memory length: 55706   epsilon: 0.8898981400023902    steps: 267    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 314   score: 0.0   memory length: 55829   epsilon: 0.8896546000023955    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 315   score: 0.0   memory length: 55952   epsilon: 0.8894110600024008    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 316   score: 3.0   memory length: 56219   epsilon: 0.8888824000024123    steps: 267    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 317   score: 0.0   memory length: 56342   epsilon: 0.8886388600024175    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 318   score: 2.0   memory length: 56540   epsilon: 0.888246820002426    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 319   score: 1.0   memory length: 56691   epsilon: 0.8879478400024325    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 320   score: 1.0   memory length: 56842   epsilon: 0.887648860002439    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 321   score: 0.0   memory length: 56964   epsilon: 0.8874073000024443    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 322   score: 1.0   memory length: 57134   epsilon: 0.8870707000024516    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 323   score: 3.0   memory length: 57403   epsilon: 0.8865380800024631    steps: 269    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 324   score: 2.0   memory length: 57600   epsilon: 0.8861480200024716    steps: 197    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 325   score: 3.0   memory length: 57816   epsilon: 0.8857203400024809    steps: 216    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 326   score: 2.0   memory length: 58032   epsilon: 0.8852926600024902    steps: 216    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 327   score: 0.0   memory length: 58154   epsilon: 0.8850511000024954    steps: 122    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 328   score: 2.0   memory length: 58370   epsilon: 0.8846234200025047    steps: 216    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 329   score: 1.0   memory length: 58539   epsilon: 0.884288800002512    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 330   score: 0.0   memory length: 58662   epsilon: 0.8840452600025173    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 331   score: 1.0   memory length: 58813   epsilon: 0.8837462800025238    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 332   score: 1.0   memory length: 58982   epsilon: 0.883411660002531    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 333   score: 1.0   memory length: 59152   epsilon: 0.8830750600025383    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 334   score: 1.0   memory length: 59320   epsilon: 0.8827424200025455    steps: 168    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 335   score: 6.0   memory length: 59680   epsilon: 0.882029620002561    steps: 360    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 336   score: 3.0   memory length: 59927   epsilon: 0.8815405600025716    steps: 247    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 337   score: 1.0   memory length: 60077   epsilon: 0.8812435600025781    steps: 150    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 338   score: 1.0   memory length: 60228   epsilon: 0.8809445800025846    steps: 151    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 339   score: 0.0   memory length: 60351   epsilon: 0.8807010400025899    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 340   score: 2.0   memory length: 60569   epsilon: 0.8802694000025992    steps: 218    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 341   score: 0.0   memory length: 60692   epsilon: 0.8800258600026045    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 342   score: 5.0   memory length: 61019   epsilon: 0.8793784000026186    steps: 327    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 343   score: 2.0   memory length: 61237   epsilon: 0.878946760002628    steps: 218    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 344   score: 3.0   memory length: 61484   epsilon: 0.8784577000026386    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 345   score: 5.0   memory length: 61824   epsilon: 0.8777845000026532    steps: 340    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 346   score: 1.0   memory length: 61995   epsilon: 0.8774459200026605    steps: 171    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 347   score: 3.0   memory length: 62265   epsilon: 0.8769113200026721    steps: 270    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 348   score: 0.0   memory length: 62388   epsilon: 0.8766677800026774    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 349   score: 1.0   memory length: 62540   epsilon: 0.876366820002684    steps: 152    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 350   score: 0.0   memory length: 62663   epsilon: 0.8761232800026892    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 351   score: 3.0   memory length: 62933   epsilon: 0.8755886800027008    steps: 270    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 352   score: 1.0   memory length: 63084   epsilon: 0.8752897000027073    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 353   score: 1.0   memory length: 63255   epsilon: 0.8749511200027147    steps: 171    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 354   score: 2.0   memory length: 63454   epsilon: 0.8745571000027232    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 355   score: 3.0   memory length: 63701   epsilon: 0.8740680400027339    steps: 247    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 356   score: 2.0   memory length: 63924   epsilon: 0.8736265000027434    steps: 223    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 357   score: 1.0   memory length: 64074   epsilon: 0.8733295000027499    steps: 150    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 358   score: 1.0   memory length: 64244   epsilon: 0.8729929000027572    steps: 170    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 359   score: 1.0   memory length: 64413   epsilon: 0.8726582800027645    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 360   score: 2.0   memory length: 64611   epsilon: 0.872266240002773    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 361   score: 2.0   memory length: 64808   epsilon: 0.8718761800027814    steps: 197    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 362   score: 2.0   memory length: 64989   epsilon: 0.8715178000027892    steps: 181    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 363   score: 2.0   memory length: 65169   epsilon: 0.871161400002797    steps: 180    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 364   score: 2.0   memory length: 65387   epsilon: 0.8707297600028063    steps: 218    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 365   score: 0.0   memory length: 65510   epsilon: 0.8704862200028116    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 366   score: 1.0   memory length: 65678   epsilon: 0.8701535800028188    steps: 168    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 367   score: 1.0   memory length: 65848   epsilon: 0.8698169800028261    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 368   score: 1.0   memory length: 66017   epsilon: 0.8694823600028334    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 369   score: 2.0   memory length: 66215   epsilon: 0.8690903200028419    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 370   score: 0.0   memory length: 66338   epsilon: 0.8688467800028472    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 371   score: 1.0   memory length: 66489   epsilon: 0.8685478000028537    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 372   score: 1.0   memory length: 66640   epsilon: 0.8682488200028602    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 373   score: 2.0   memory length: 66838   epsilon: 0.8678567800028687    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 374   score: 0.0   memory length: 66961   epsilon: 0.867613240002874    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 375   score: 0.0   memory length: 67083   epsilon: 0.8673716800028792    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 376   score: 1.0   memory length: 67253   epsilon: 0.8670350800028865    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 377   score: 1.0   memory length: 67404   epsilon: 0.866736100002893    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 378   score: 1.0   memory length: 67555   epsilon: 0.8664371200028995    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 379   score: 0.0   memory length: 67677   epsilon: 0.8661955600029048    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 380   score: 2.0   memory length: 67879   epsilon: 0.8657956000029134    steps: 202    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 381   score: 1.0   memory length: 68030   epsilon: 0.8654966200029199    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 382   score: 2.0   memory length: 68230   epsilon: 0.8651006200029285    steps: 200    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 383   score: 0.0   memory length: 68353   epsilon: 0.8648570800029338    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 384   score: 0.0   memory length: 68476   epsilon: 0.8646135400029391    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 385   score: 2.0   memory length: 68674   epsilon: 0.8642215000029476    steps: 198    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 386   score: 3.0   memory length: 68940   epsilon: 0.863694820002959    steps: 266    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 387   score: 2.0   memory length: 69138   epsilon: 0.8633027800029676    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 388   score: 1.0   memory length: 69309   epsilon: 0.8629642000029749    steps: 171    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 389   score: 0.0   memory length: 69432   epsilon: 0.8627206600029802    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 390   score: 0.0   memory length: 69555   epsilon: 0.8624771200029855    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 391   score: 0.0   memory length: 69678   epsilon: 0.8622335800029908    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 392   score: 3.0   memory length: 69905   epsilon: 0.8617841200030005    steps: 227    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 393   score: 1.0   memory length: 70056   epsilon: 0.861485140003007    steps: 151    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 394   score: 2.0   memory length: 70254   epsilon: 0.8610931000030155    steps: 198    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 395   score: 5.0   memory length: 70600   epsilon: 0.8604080200030304    steps: 346    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 396   score: 1.0   memory length: 70750   epsilon: 0.8601110200030369    steps: 150    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 397   score: 1.0   memory length: 70919   epsilon: 0.8597764000030441    steps: 169    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 398   score: 0.0   memory length: 71042   epsilon: 0.8595328600030494    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 399   score: 3.0   memory length: 71268   epsilon: 0.8590853800030591    steps: 226    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 400   score: 0.0   memory length: 71391   epsilon: 0.8588418400030644    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 401   score: 2.0   memory length: 71612   epsilon: 0.8584042600030739    steps: 221    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 402   score: 1.0   memory length: 71781   epsilon: 0.8580696400030812    steps: 169    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 403   score: 2.0   memory length: 71978   epsilon: 0.8576795800030896    steps: 197    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 404   score: 5.0   memory length: 72323   epsilon: 0.8569964800031045    steps: 345    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 405   score: 2.0   memory length: 72521   epsilon: 0.856604440003113    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 406   score: 2.0   memory length: 72719   epsilon: 0.8562124000031215    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 407   score: 0.0   memory length: 72842   epsilon: 0.8559688600031268    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 408   score: 2.0   memory length: 73040   epsilon: 0.8555768200031353    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 409   score: 2.0   memory length: 73257   epsilon: 0.8551471600031446    steps: 217    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 410   score: 2.0   memory length: 73458   epsilon: 0.8547491800031533    steps: 201    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 411   score: 1.0   memory length: 73626   epsilon: 0.8544165400031605    steps: 168    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 412   score: 3.0   memory length: 73889   epsilon: 0.8538958000031718    steps: 263    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 413   score: 1.0   memory length: 74058   epsilon: 0.853561180003179    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 414   score: 2.0   memory length: 74276   epsilon: 0.8531295400031884    steps: 218    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 415   score: 2.0   memory length: 74474   epsilon: 0.8527375000031969    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 416   score: 0.0   memory length: 74596   epsilon: 0.8524959400032022    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 417   score: 0.0   memory length: 74718   epsilon: 0.8522543800032074    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 418   score: 3.0   memory length: 74946   epsilon: 0.8518029400032172    steps: 228    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 419   score: 0.0   memory length: 75068   epsilon: 0.8515613800032225    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 420   score: 3.0   memory length: 75297   epsilon: 0.8511079600032323    steps: 229    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 421   score: 0.0   memory length: 75420   epsilon: 0.8508644200032376    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 422   score: 7.0   memory length: 75813   epsilon: 0.8500862800032545    steps: 393    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 423   score: 1.0   memory length: 75982   epsilon: 0.8497516600032617    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 424   score: 2.0   memory length: 76201   epsilon: 0.8493180400032712    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 425   score: 2.0   memory length: 76399   epsilon: 0.8489260000032797    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 426   score: 0.0   memory length: 76521   epsilon: 0.8486844400032849    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 427   score: 3.0   memory length: 76749   epsilon: 0.8482330000032947    steps: 228    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 428   score: 1.0   memory length: 76918   epsilon: 0.847898380003302    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 429   score: 0.0   memory length: 77040   epsilon: 0.8476568200033072    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 430   score: 9.0   memory length: 77419   epsilon: 0.8469064000033235    steps: 379    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 431   score: 1.0   memory length: 77570   epsilon: 0.84660742000333    steps: 151    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 432   score: 1.0   memory length: 77741   epsilon: 0.8462688400033374    steps: 171    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 433   score: 2.0   memory length: 77938   epsilon: 0.8458787800033458    steps: 197    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 434   score: 0.0   memory length: 78060   epsilon: 0.8456372200033511    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 435   score: 5.0   memory length: 78355   epsilon: 0.8450531200033637    steps: 295    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 436   score: 2.0   memory length: 78574   epsilon: 0.8446195000033732    steps: 219    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 437   score: 0.0   memory length: 78696   epsilon: 0.8443779400033784    steps: 122    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 438   score: 2.0   memory length: 78913   epsilon: 0.8439482800033877    steps: 217    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 439   score: 1.0   memory length: 79063   epsilon: 0.8436512800033942    steps: 150    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 440   score: 3.0   memory length: 79311   epsilon: 0.8431602400034048    steps: 248    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 441   score: 0.0   memory length: 79434   epsilon: 0.8429167000034101    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 442   score: 1.0   memory length: 79603   epsilon: 0.8425820800034174    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 443   score: 0.0   memory length: 79726   epsilon: 0.8423385400034227    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 444   score: 1.0   memory length: 79895   epsilon: 0.8420039200034299    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 445   score: 1.0   memory length: 80066   epsilon: 0.8416653400034373    steps: 171    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 446   score: 0.0   memory length: 80188   epsilon: 0.8414237800034425    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 447   score: 2.0   memory length: 80407   epsilon: 0.840990160003452    steps: 219    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 448   score: 0.0   memory length: 80530   epsilon: 0.8407466200034572    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 449   score: 0.0   memory length: 80652   epsilon: 0.8405050600034625    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 450   score: 2.0   memory length: 80849   epsilon: 0.840115000003471    steps: 197    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 451   score: 3.0   memory length: 81075   epsilon: 0.8396675200034807    steps: 226    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 452   score: 2.0   memory length: 81255   epsilon: 0.8393111200034884    steps: 180    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 453   score: 3.0   memory length: 81508   epsilon: 0.8388101800034993    steps: 253    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 454   score: 3.0   memory length: 81754   epsilon: 0.8383231000035098    steps: 246    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 455   score: 1.0   memory length: 81904   epsilon: 0.8380261000035163    steps: 150    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 456   score: 0.0   memory length: 82027   epsilon: 0.8377825600035216    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 457   score: 2.0   memory length: 82243   epsilon: 0.8373548800035309    steps: 216    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 458   score: 0.0   memory length: 82366   epsilon: 0.8371113400035362    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 459   score: 1.0   memory length: 82536   epsilon: 0.8367747400035435    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 460   score: 3.0   memory length: 82782   epsilon: 0.836287660003554    steps: 246    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 461   score: 2.0   memory length: 82979   epsilon: 0.8358976000035625    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 462   score: 1.0   memory length: 83151   epsilon: 0.8355570400035699    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 463   score: 0.0   memory length: 83274   epsilon: 0.8353135000035752    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 464   score: 1.0   memory length: 83424   epsilon: 0.8350165000035816    steps: 150    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 465   score: 0.0   memory length: 83546   epsilon: 0.8347749400035869    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 466   score: 2.0   memory length: 83743   epsilon: 0.8343848800035953    steps: 197    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 467   score: 0.0   memory length: 83866   epsilon: 0.8341413400036006    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 468   score: 0.0   memory length: 83989   epsilon: 0.8338978000036059    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 469   score: 1.0   memory length: 84160   epsilon: 0.8335592200036133    steps: 171    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 470   score: 1.0   memory length: 84310   epsilon: 0.8332622200036197    steps: 150    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 471   score: 0.0   memory length: 84433   epsilon: 0.833018680003625    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 472   score: 1.0   memory length: 84602   epsilon: 0.8326840600036323    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 473   score: 0.0   memory length: 84725   epsilon: 0.8324405200036376    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 474   score: 5.0   memory length: 85071   epsilon: 0.8317554400036524    steps: 346    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 475   score: 2.0   memory length: 85290   epsilon: 0.8313218200036618    steps: 219    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 476   score: 3.0   memory length: 85534   epsilon: 0.8308387000036723    steps: 244    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 477   score: 2.0   memory length: 85716   epsilon: 0.8304783400036801    steps: 182    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 478   score: 1.0   memory length: 85886   epsilon: 0.8301417400036875    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 479   score: 3.0   memory length: 86134   epsilon: 0.8296507000036981    steps: 248    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 480   score: 0.0   memory length: 86257   epsilon: 0.8294071600037034    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 481   score: 1.0   memory length: 86408   epsilon: 0.8291081800037099    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 482   score: 3.0   memory length: 86654   epsilon: 0.8286211000037205    steps: 246    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 483   score: 4.0   memory length: 86970   epsilon: 0.827995420003734    steps: 316    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 484   score: 2.0   memory length: 87167   epsilon: 0.8276053600037425    steps: 197    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 485   score: 1.0   memory length: 87338   epsilon: 0.8272667800037499    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 486   score: 0.0   memory length: 87460   epsilon: 0.8270252200037551    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 487   score: 3.0   memory length: 87728   epsilon: 0.8264945800037666    steps: 268    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 488   score: 2.0   memory length: 87928   epsilon: 0.8260985800037752    steps: 200    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 489   score: 2.0   memory length: 88108   epsilon: 0.825742180003783    steps: 180    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 490   score: 3.0   memory length: 88355   epsilon: 0.8252531200037936    steps: 247    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 491   score: 2.0   memory length: 88553   epsilon: 0.8248610800038021    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 492   score: 0.0   memory length: 88676   epsilon: 0.8246175400038074    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 493   score: 1.0   memory length: 88846   epsilon: 0.8242809400038147    steps: 170    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 494   score: 0.0   memory length: 88969   epsilon: 0.82403740000382    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 495   score: 1.0   memory length: 89120   epsilon: 0.8237384200038265    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 496   score: 1.0   memory length: 89289   epsilon: 0.8234038000038337    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 497   score: 0.0   memory length: 89412   epsilon: 0.823160260003839    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 498   score: 0.0   memory length: 89535   epsilon: 0.8229167200038443    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 499   score: 2.0   memory length: 89732   epsilon: 0.8225266600038528    steps: 197    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 500   score: 1.0   memory length: 89883   epsilon: 0.8222276800038593    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 501   score: 2.0   memory length: 90080   epsilon: 0.8218376200038677    steps: 197    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 502   score: 2.0   memory length: 90280   epsilon: 0.8214416200038763    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 503   score: 2.0   memory length: 90483   epsilon: 0.821039680003885    steps: 203    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 504   score: 0.0   memory length: 90606   epsilon: 0.8207961400038903    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 505   score: 1.0   memory length: 90757   epsilon: 0.8204971600038968    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 506   score: 1.0   memory length: 90908   epsilon: 0.8201981800039033    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 507   score: 3.0   memory length: 91155   epsilon: 0.8197091200039139    steps: 247    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 508   score: 2.0   memory length: 91354   epsilon: 0.8193151000039225    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 509   score: 1.0   memory length: 91505   epsilon: 0.819016120003929    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 510   score: 0.0   memory length: 91627   epsilon: 0.8187745600039342    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 511   score: 3.0   memory length: 91874   epsilon: 0.8182855000039448    steps: 247    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 512   score: 4.0   memory length: 92149   epsilon: 0.8177410000039567    steps: 275    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 513   score: 2.0   memory length: 92349   epsilon: 0.8173450000039653    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 514   score: 0.0   memory length: 92472   epsilon: 0.8171014600039705    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 515   score: 2.0   memory length: 92687   epsilon: 0.8166757600039798    steps: 215    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 516   score: 2.0   memory length: 92885   epsilon: 0.8162837200039883    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 517   score: 1.0   memory length: 93056   epsilon: 0.8159451400039957    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 518   score: 1.0   memory length: 93206   epsilon: 0.8156481400040021    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 519   score: 0.0   memory length: 93329   epsilon: 0.8154046000040074    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 520   score: 2.0   memory length: 93545   epsilon: 0.8149769200040167    steps: 216    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 521   score: 3.0   memory length: 93794   epsilon: 0.8144839000040274    steps: 249    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 522   score: 2.0   memory length: 93994   epsilon: 0.814087900004036    steps: 200    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 523   score: 2.0   memory length: 94192   epsilon: 0.8136958600040445    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 524   score: 3.0   memory length: 94418   epsilon: 0.8132483800040542    steps: 226    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 525   score: 2.0   memory length: 94616   epsilon: 0.8128563400040627    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 526   score: 2.0   memory length: 94813   epsilon: 0.8124662800040712    steps: 197    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 527   score: 0.0   memory length: 94936   epsilon: 0.8122227400040765    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 528   score: 2.0   memory length: 95155   epsilon: 0.8117891200040859    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 529   score: 2.0   memory length: 95355   epsilon: 0.8113931200040945    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 530   score: 1.0   memory length: 95526   epsilon: 0.8110545400041018    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 531   score: 2.0   memory length: 95726   epsilon: 0.8106585400041104    steps: 200    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 532   score: 0.0   memory length: 95848   epsilon: 0.8104169800041157    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 533   score: 4.0   memory length: 96127   epsilon: 0.8098645600041277    steps: 279    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 534   score: 1.0   memory length: 96296   epsilon: 0.8095299400041349    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 535   score: 3.0   memory length: 96565   epsilon: 0.8089973200041465    steps: 269    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 536   score: 0.0   memory length: 96688   epsilon: 0.8087537800041518    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 537   score: 4.0   memory length: 96986   epsilon: 0.8081637400041646    steps: 298    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 538   score: 4.0   memory length: 97246   epsilon: 0.8076489400041758    steps: 260    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 539   score: 4.0   memory length: 97520   epsilon: 0.8071064200041875    steps: 274    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 540   score: 0.0   memory length: 97642   epsilon: 0.8068648600041928    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 541   score: 1.0   memory length: 97811   epsilon: 0.8065302400042    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 542   score: 1.0   memory length: 97962   epsilon: 0.8062312600042065    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 543   score: 1.0   memory length: 98131   epsilon: 0.8058966400042138    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 544   score: 3.0   memory length: 98379   epsilon: 0.8054056000042245    steps: 248    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 545   score: 3.0   memory length: 98625   epsilon: 0.804918520004235    steps: 246    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 546   score: 2.0   memory length: 98841   epsilon: 0.8044908400042443    steps: 216    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 547   score: 4.0   memory length: 99136   epsilon: 0.803906740004257    steps: 295    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 548   score: 0.0   memory length: 99259   epsilon: 0.8036632000042623    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 549   score: 1.0   memory length: 99430   epsilon: 0.8033246200042696    steps: 171    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 550   score: 0.0   memory length: 99553   epsilon: 0.8030810800042749    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 551   score: 0.0   memory length: 99676   epsilon: 0.8028375400042802    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 552   score: 0.0   memory length: 99798   epsilon: 0.8025959800042854    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 553   score: 1.0   memory length: 99949   epsilon: 0.8022970000042919    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 554   score: 1.0   memory length: 100117   epsilon: 0.8019643600042992    steps: 168    lr: 4e-05     evaluation reward: 1.51\n",
      "episode: 555   score: 2.0   memory length: 100332   epsilon: 0.8015386600043084    steps: 215    lr: 4e-05     evaluation reward: 1.52\n",
      "episode: 556   score: 0.0   memory length: 100454   epsilon: 0.8012971000043136    steps: 122    lr: 4e-05     evaluation reward: 1.52\n",
      "episode: 557   score: 4.0   memory length: 100728   epsilon: 0.8007545800043254    steps: 274    lr: 4e-05     evaluation reward: 1.54\n",
      "episode: 558   score: 1.0   memory length: 100900   epsilon: 0.8004140200043328    steps: 172    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 559   score: 1.0   memory length: 101069   epsilon: 0.8000794000043401    steps: 169    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 560   score: 3.0   memory length: 101295   epsilon: 0.7996319200043498    steps: 226    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 561   score: 2.0   memory length: 101493   epsilon: 0.7992398800043583    steps: 198    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 562   score: 3.0   memory length: 101740   epsilon: 0.7987508200043689    steps: 247    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 563   score: 2.0   memory length: 101958   epsilon: 0.7983191800043783    steps: 218    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 564   score: 2.0   memory length: 102177   epsilon: 0.7978855600043877    steps: 219    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 565   score: 3.0   memory length: 102405   epsilon: 0.7974341200043975    steps: 228    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 566   score: 0.0   memory length: 102527   epsilon: 0.7971925600044028    steps: 122    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 567   score: 1.0   memory length: 102696   epsilon: 0.79685794000441    steps: 169    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 568   score: 0.0   memory length: 102818   epsilon: 0.7966163800044153    steps: 122    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 569   score: 1.0   memory length: 102987   epsilon: 0.7962817600044225    steps: 169    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 570   score: 1.0   memory length: 103139   epsilon: 0.7959808000044291    steps: 152    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 571   score: 1.0   memory length: 103310   epsilon: 0.7956422200044364    steps: 171    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 572   score: 1.0   memory length: 103479   epsilon: 0.7953076000044437    steps: 169    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 573   score: 2.0   memory length: 103677   epsilon: 0.7949155600044522    steps: 198    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 574   score: 1.0   memory length: 103849   epsilon: 0.7945750000044596    steps: 172    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 575   score: 2.0   memory length: 104067   epsilon: 0.794143360004469    steps: 218    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 576   score: 5.0   memory length: 104381   epsilon: 0.7935216400044824    steps: 314    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 577   score: 0.0   memory length: 104503   epsilon: 0.7932800800044877    steps: 122    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 578   score: 3.0   memory length: 104749   epsilon: 0.7927930000044983    steps: 246    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 579   score: 2.0   memory length: 104967   epsilon: 0.7923613600045076    steps: 218    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 580   score: 1.0   memory length: 105136   epsilon: 0.7920267400045149    steps: 169    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 581   score: 1.0   memory length: 105307   epsilon: 0.7916881600045222    steps: 171    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 582   score: 4.0   memory length: 105581   epsilon: 0.791145640004534    steps: 274    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 583   score: 5.0   memory length: 105928   epsilon: 0.7904585800045489    steps: 347    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 584   score: 0.0   memory length: 106051   epsilon: 0.7902150400045542    steps: 123    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 585   score: 1.0   memory length: 106220   epsilon: 0.7898804200045615    steps: 169    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 586   score: 1.0   memory length: 106370   epsilon: 0.7895834200045679    steps: 150    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 587   score: 1.0   memory length: 106521   epsilon: 0.7892844400045744    steps: 151    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 588   score: 1.0   memory length: 106672   epsilon: 0.7889854600045809    steps: 151    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 589   score: 2.0   memory length: 106870   epsilon: 0.7885934200045894    steps: 198    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 590   score: 3.0   memory length: 107114   epsilon: 0.7881103000045999    steps: 244    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 591   score: 3.0   memory length: 107326   epsilon: 0.787690540004609    steps: 212    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 592   score: 0.0   memory length: 107449   epsilon: 0.7874470000046143    steps: 123    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 593   score: 3.0   memory length: 107676   epsilon: 0.7869975400046241    steps: 227    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 594   score: 2.0   memory length: 107876   epsilon: 0.7866015400046327    steps: 200    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 595   score: 2.0   memory length: 108073   epsilon: 0.7862114800046411    steps: 197    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 596   score: 0.0   memory length: 108196   epsilon: 0.7859679400046464    steps: 123    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 597   score: 4.0   memory length: 108488   epsilon: 0.785389780004659    steps: 292    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 598   score: 2.0   memory length: 108686   epsilon: 0.7849977400046675    steps: 198    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 599   score: 1.0   memory length: 108854   epsilon: 0.7846651000046747    steps: 168    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 600   score: 3.0   memory length: 109079   epsilon: 0.7842196000046844    steps: 225    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 601   score: 5.0   memory length: 109389   epsilon: 0.7836058000046977    steps: 310    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 602   score: 1.0   memory length: 109558   epsilon: 0.783271180004705    steps: 169    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 603   score: 0.0   memory length: 109680   epsilon: 0.7830296200047102    steps: 122    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 604   score: 1.0   memory length: 109832   epsilon: 0.7827286600047167    steps: 152    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 605   score: 1.0   memory length: 110000   epsilon: 0.782396020004724    steps: 168    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 606   score: 2.0   memory length: 110218   epsilon: 0.7819643800047333    steps: 218    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 607   score: 1.0   memory length: 110386   epsilon: 0.7816317400047406    steps: 168    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 608   score: 3.0   memory length: 110654   epsilon: 0.7811011000047521    steps: 268    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 609   score: 2.0   memory length: 110855   epsilon: 0.7807031200047607    steps: 201    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 610   score: 0.0   memory length: 110978   epsilon: 0.780459580004766    steps: 123    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 611   score: 0.0   memory length: 111100   epsilon: 0.7802180200047713    steps: 122    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 612   score: 0.0   memory length: 111223   epsilon: 0.7799744800047765    steps: 123    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 613   score: 0.0   memory length: 111345   epsilon: 0.7797329200047818    steps: 122    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 614   score: 3.0   memory length: 111570   epsilon: 0.7792874200047915    steps: 225    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 615   score: 1.0   memory length: 111720   epsilon: 0.7789904200047979    steps: 150    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 616   score: 1.0   memory length: 111891   epsilon: 0.7786518400048053    steps: 171    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 617   score: 3.0   memory length: 112139   epsilon: 0.7781608000048159    steps: 248    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 618   score: 4.0   memory length: 112435   epsilon: 0.7775747200048286    steps: 296    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 619   score: 0.0   memory length: 112558   epsilon: 0.7773311800048339    steps: 123    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 620   score: 0.0   memory length: 112680   epsilon: 0.7770896200048392    steps: 122    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 621   score: 0.0   memory length: 112802   epsilon: 0.7768480600048444    steps: 122    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 622   score: 0.0   memory length: 112924   epsilon: 0.7766065000048497    steps: 122    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 623   score: 3.0   memory length: 113152   epsilon: 0.7761550600048595    steps: 228    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 624   score: 2.0   memory length: 113371   epsilon: 0.7757214400048689    steps: 219    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 625   score: 1.0   memory length: 113521   epsilon: 0.7754244400048753    steps: 150    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 626   score: 2.0   memory length: 113718   epsilon: 0.7750343800048838    steps: 197    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 627   score: 2.0   memory length: 113940   epsilon: 0.7745948200048933    steps: 222    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 628   score: 2.0   memory length: 114138   epsilon: 0.7742027800049018    steps: 198    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 629   score: 3.0   memory length: 114403   epsilon: 0.7736780800049132    steps: 265    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 630   score: 3.0   memory length: 114628   epsilon: 0.7732325800049229    steps: 225    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 631   score: 4.0   memory length: 114948   epsilon: 0.7725989800049367    steps: 320    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 632   score: 1.0   memory length: 115119   epsilon: 0.772260400004944    steps: 171    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 633   score: 0.0   memory length: 115241   epsilon: 0.7720188400049492    steps: 122    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 634   score: 2.0   memory length: 115458   epsilon: 0.7715891800049586    steps: 217    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 635   score: 2.0   memory length: 115640   epsilon: 0.7712288200049664    steps: 182    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 636   score: 0.0   memory length: 115762   epsilon: 0.7709872600049716    steps: 122    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 637   score: 0.0   memory length: 115884   epsilon: 0.7707457000049769    steps: 122    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 638   score: 0.0   memory length: 116006   epsilon: 0.7705041400049821    steps: 122    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 639   score: 4.0   memory length: 116282   epsilon: 0.769957660004994    steps: 276    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 640   score: 0.0   memory length: 116404   epsilon: 0.7697161000049992    steps: 122    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 641   score: 0.0   memory length: 116527   epsilon: 0.7694725600050045    steps: 123    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 642   score: 3.0   memory length: 116753   epsilon: 0.7690250800050142    steps: 226    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 643   score: 2.0   memory length: 116933   epsilon: 0.768668680005022    steps: 180    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 644   score: 2.0   memory length: 117150   epsilon: 0.7682390200050313    steps: 217    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 645   score: 2.0   memory length: 117349   epsilon: 0.7678450000050399    steps: 199    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 646   score: 3.0   memory length: 117579   epsilon: 0.7673896000050497    steps: 230    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 647   score: 1.0   memory length: 117750   epsilon: 0.7670510200050571    steps: 171    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 648   score: 0.0   memory length: 117872   epsilon: 0.7668094600050623    steps: 122    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 649   score: 0.0   memory length: 117995   epsilon: 0.7665659200050676    steps: 123    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 650   score: 0.0   memory length: 118117   epsilon: 0.7663243600050729    steps: 122    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 651   score: 3.0   memory length: 118344   epsilon: 0.7658749000050826    steps: 227    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 652   score: 0.0   memory length: 118467   epsilon: 0.7656313600050879    steps: 123    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 653   score: 1.0   memory length: 118636   epsilon: 0.7652967400050952    steps: 169    lr: 4e-05     evaluation reward: 1.6\n",
      "episode: 654   score: 0.0   memory length: 118758   epsilon: 0.7650551800051004    steps: 122    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 655   score: 0.0   memory length: 118880   epsilon: 0.7648136200051057    steps: 122    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 656   score: 0.0   memory length: 119002   epsilon: 0.7645720600051109    steps: 122    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 657   score: 1.0   memory length: 119171   epsilon: 0.7642374400051182    steps: 169    lr: 4e-05     evaluation reward: 1.54\n",
      "episode: 658   score: 0.0   memory length: 119293   epsilon: 0.7639958800051234    steps: 122    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 659   score: 1.0   memory length: 119461   epsilon: 0.7636632400051306    steps: 168    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 660   score: 0.0   memory length: 119584   epsilon: 0.7634197000051359    steps: 123    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 661   score: 1.0   memory length: 119753   epsilon: 0.7630850800051432    steps: 169    lr: 4e-05     evaluation reward: 1.49\n",
      "episode: 662   score: 2.0   memory length: 119970   epsilon: 0.7626554200051525    steps: 217    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 663   score: 2.0   memory length: 120187   epsilon: 0.7622257600051618    steps: 217    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 664   score: 0.0   memory length: 120310   epsilon: 0.7619822200051671    steps: 123    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 665   score: 2.0   memory length: 120507   epsilon: 0.7615921600051756    steps: 197    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 666   score: 3.0   memory length: 120775   epsilon: 0.7610615200051871    steps: 268    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 667   score: 0.0   memory length: 120897   epsilon: 0.7608199600051924    steps: 122    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 668   score: 3.0   memory length: 121122   epsilon: 0.760374460005202    steps: 225    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 669   score: 0.0   memory length: 121244   epsilon: 0.7601329000052073    steps: 122    lr: 4e-05     evaluation reward: 1.49\n",
      "episode: 670   score: 3.0   memory length: 121491   epsilon: 0.7596438400052179    steps: 247    lr: 4e-05     evaluation reward: 1.51\n",
      "episode: 671   score: 3.0   memory length: 121702   epsilon: 0.759226060005227    steps: 211    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 672   score: 1.0   memory length: 121870   epsilon: 0.7588934200052342    steps: 168    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 673   score: 3.0   memory length: 122137   epsilon: 0.7583647600052457    steps: 267    lr: 4e-05     evaluation reward: 1.54\n",
      "episode: 674   score: 4.0   memory length: 122429   epsilon: 0.7577866000052582    steps: 292    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 675   score: 2.0   memory length: 122627   epsilon: 0.7573945600052667    steps: 198    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 676   score: 3.0   memory length: 122894   epsilon: 0.7568659000052782    steps: 267    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 677   score: 1.0   memory length: 123044   epsilon: 0.7565689000052847    steps: 150    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 678   score: 0.0   memory length: 123167   epsilon: 0.7563253600052899    steps: 123    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 679   score: 2.0   memory length: 123364   epsilon: 0.7559353000052984    steps: 197    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 680   score: 0.0   memory length: 123487   epsilon: 0.7556917600053037    steps: 123    lr: 4e-05     evaluation reward: 1.52\n",
      "episode: 681   score: 0.0   memory length: 123610   epsilon: 0.755448220005309    steps: 123    lr: 4e-05     evaluation reward: 1.51\n",
      "episode: 682   score: 1.0   memory length: 123761   epsilon: 0.7551492400053155    steps: 151    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 683   score: 3.0   memory length: 124008   epsilon: 0.7546601800053261    steps: 247    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 684   score: 0.0   memory length: 124130   epsilon: 0.7544186200053313    steps: 122    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 685   score: 0.0   memory length: 124253   epsilon: 0.7541750800053366    steps: 123    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 686   score: 1.0   memory length: 124403   epsilon: 0.7538780800053431    steps: 150    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 687   score: 0.0   memory length: 124526   epsilon: 0.7536345400053484    steps: 123    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 688   score: 1.0   memory length: 124677   epsilon: 0.7533355600053548    steps: 151    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 689   score: 3.0   memory length: 124902   epsilon: 0.7528900600053645    steps: 225    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 690   score: 0.0   memory length: 125024   epsilon: 0.7526485000053698    steps: 122    lr: 4e-05     evaluation reward: 1.42\n",
      "episode: 691   score: 3.0   memory length: 125268   epsilon: 0.7521653800053802    steps: 244    lr: 4e-05     evaluation reward: 1.42\n",
      "episode: 692   score: 3.0   memory length: 125533   epsilon: 0.7516406800053916    steps: 265    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 693   score: 0.0   memory length: 125655   epsilon: 0.7513991200053969    steps: 122    lr: 4e-05     evaluation reward: 1.42\n",
      "episode: 694   score: 0.0   memory length: 125778   epsilon: 0.7511555800054022    steps: 123    lr: 4e-05     evaluation reward: 1.4\n",
      "episode: 695   score: 2.0   memory length: 125976   epsilon: 0.7507635400054107    steps: 198    lr: 4e-05     evaluation reward: 1.4\n",
      "episode: 696   score: 1.0   memory length: 126145   epsilon: 0.7504289200054179    steps: 169    lr: 4e-05     evaluation reward: 1.41\n",
      "episode: 697   score: 2.0   memory length: 126364   epsilon: 0.7499953000054274    steps: 219    lr: 4e-05     evaluation reward: 1.39\n",
      "episode: 698   score: 6.0   memory length: 126743   epsilon: 0.7492448800054436    steps: 379    lr: 4e-05     evaluation reward: 1.43\n",
      "episode: 699   score: 1.0   memory length: 126894   epsilon: 0.7489459000054501    steps: 151    lr: 4e-05     evaluation reward: 1.43\n",
      "episode: 700   score: 3.0   memory length: 127164   epsilon: 0.7484113000054617    steps: 270    lr: 4e-05     evaluation reward: 1.43\n",
      "episode: 701   score: 2.0   memory length: 127364   epsilon: 0.7480153000054703    steps: 200    lr: 4e-05     evaluation reward: 1.4\n",
      "episode: 702   score: 2.0   memory length: 127580   epsilon: 0.7475876200054796    steps: 216    lr: 4e-05     evaluation reward: 1.41\n",
      "episode: 703   score: 3.0   memory length: 127850   epsilon: 0.7470530200054912    steps: 270    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 704   score: 1.0   memory length: 128019   epsilon: 0.7467184000054985    steps: 169    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 705   score: 4.0   memory length: 128316   epsilon: 0.7461303400055113    steps: 297    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 706   score: 0.0   memory length: 128438   epsilon: 0.7458887800055165    steps: 122    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 707   score: 2.0   memory length: 128653   epsilon: 0.7454630800055257    steps: 215    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 708   score: 1.0   memory length: 128803   epsilon: 0.7451660800055322    steps: 150    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 709   score: 1.0   memory length: 128974   epsilon: 0.7448275000055395    steps: 171    lr: 4e-05     evaluation reward: 1.43\n",
      "episode: 710   score: 1.0   memory length: 129144   epsilon: 0.7444909000055469    steps: 170    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 711   score: 0.0   memory length: 129266   epsilon: 0.7442493400055521    steps: 122    lr: 4e-05     evaluation reward: 1.44\n",
      "episode: 712   score: 4.0   memory length: 129545   epsilon: 0.7436969200055641    steps: 279    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 713   score: 0.0   memory length: 129667   epsilon: 0.7434553600055693    steps: 122    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 714   score: 2.0   memory length: 129864   epsilon: 0.7430653000055778    steps: 197    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 715   score: 0.0   memory length: 129987   epsilon: 0.7428217600055831    steps: 123    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 716   score: 1.0   memory length: 130137   epsilon: 0.7425247600055895    steps: 150    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 717   score: 2.0   memory length: 130352   epsilon: 0.7420990600055988    steps: 215    lr: 4e-05     evaluation reward: 1.45\n",
      "episode: 718   score: 2.0   memory length: 130533   epsilon: 0.7417406800056066    steps: 181    lr: 4e-05     evaluation reward: 1.43\n",
      "episode: 719   score: 3.0   memory length: 130761   epsilon: 0.7412892400056164    steps: 228    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 720   score: 0.0   memory length: 130884   epsilon: 0.7410457000056216    steps: 123    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 721   score: 3.0   memory length: 131112   epsilon: 0.7405942600056314    steps: 228    lr: 4e-05     evaluation reward: 1.49\n",
      "episode: 722   score: 1.0   memory length: 131263   epsilon: 0.7402952800056379    steps: 151    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 723   score: 2.0   memory length: 131444   epsilon: 0.7399369000056457    steps: 181    lr: 4e-05     evaluation reward: 1.49\n",
      "episode: 724   score: 1.0   memory length: 131594   epsilon: 0.7396399000056522    steps: 150    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 725   score: 1.0   memory length: 131762   epsilon: 0.7393072600056594    steps: 168    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 726   score: 3.0   memory length: 132009   epsilon: 0.73881820000567    steps: 247    lr: 4e-05     evaluation reward: 1.49\n",
      "episode: 727   score: 0.0   memory length: 132132   epsilon: 0.7385746600056753    steps: 123    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 728   score: 2.0   memory length: 132351   epsilon: 0.7381410400056847    steps: 219    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 729   score: 4.0   memory length: 132608   epsilon: 0.7376321800056957    steps: 257    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 730   score: 2.0   memory length: 132805   epsilon: 0.7372421200057042    steps: 197    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 731   score: 3.0   memory length: 133071   epsilon: 0.7367154400057156    steps: 266    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 732   score: 1.0   memory length: 133239   epsilon: 0.7363828000057229    steps: 168    lr: 4e-05     evaluation reward: 1.46\n",
      "episode: 733   score: 1.0   memory length: 133389   epsilon: 0.7360858000057293    steps: 150    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 734   score: 2.0   memory length: 133569   epsilon: 0.735729400005737    steps: 180    lr: 4e-05     evaluation reward: 1.47\n",
      "episode: 735   score: 3.0   memory length: 133797   epsilon: 0.7352779600057469    steps: 228    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 736   score: 2.0   memory length: 133995   epsilon: 0.7348859200057554    steps: 198    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 737   score: 0.0   memory length: 134118   epsilon: 0.7346423800057607    steps: 123    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 738   score: 0.0   memory length: 134241   epsilon: 0.7343988400057659    steps: 123    lr: 4e-05     evaluation reward: 1.5\n",
      "episode: 739   score: 2.0   memory length: 134438   epsilon: 0.7340087800057744    steps: 197    lr: 4e-05     evaluation reward: 1.48\n",
      "episode: 740   score: 8.0   memory length: 134780   epsilon: 0.7333316200057891    steps: 342    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 741   score: 2.0   memory length: 134977   epsilon: 0.7329415600057976    steps: 197    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 742   score: 1.0   memory length: 135128   epsilon: 0.7326425800058041    steps: 151    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 743   score: 1.0   memory length: 135278   epsilon: 0.7323455800058105    steps: 150    lr: 4e-05     evaluation reward: 1.55\n",
      "episode: 744   score: 0.0   memory length: 135401   epsilon: 0.7321020400058158    steps: 123    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 745   score: 1.0   memory length: 135572   epsilon: 0.7317634600058232    steps: 171    lr: 4e-05     evaluation reward: 1.52\n",
      "episode: 746   score: 3.0   memory length: 135800   epsilon: 0.731312020005833    steps: 228    lr: 4e-05     evaluation reward: 1.52\n",
      "episode: 747   score: 2.0   memory length: 135998   epsilon: 0.7309199800058415    steps: 198    lr: 4e-05     evaluation reward: 1.53\n",
      "episode: 748   score: 1.0   memory length: 136149   epsilon: 0.730621000005848    steps: 151    lr: 4e-05     evaluation reward: 1.54\n",
      "episode: 749   score: 0.0   memory length: 136271   epsilon: 0.7303794400058532    steps: 122    lr: 4e-05     evaluation reward: 1.54\n",
      "episode: 750   score: 5.0   memory length: 136586   epsilon: 0.7297557400058667    steps: 315    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 751   score: 1.0   memory length: 136755   epsilon: 0.729421120005874    steps: 169    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 752   score: 2.0   memory length: 136953   epsilon: 0.7290290800058825    steps: 198    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 753   score: 0.0   memory length: 137075   epsilon: 0.7287875200058878    steps: 122    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 754   score: 0.0   memory length: 137198   epsilon: 0.728543980005893    steps: 123    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 755   score: 0.0   memory length: 137321   epsilon: 0.7283004400058983    steps: 123    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 756   score: 1.0   memory length: 137489   epsilon: 0.7279678000059056    steps: 168    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 757   score: 3.0   memory length: 137734   epsilon: 0.7274827000059161    steps: 245    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 758   score: 2.0   memory length: 137950   epsilon: 0.7270550200059254    steps: 216    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 759   score: 0.0   memory length: 138072   epsilon: 0.7268134600059306    steps: 122    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 760   score: 2.0   memory length: 138270   epsilon: 0.7264214200059391    steps: 198    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 761   score: 0.0   memory length: 138393   epsilon: 0.7261778800059444    steps: 123    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 762   score: 2.0   memory length: 138611   epsilon: 0.7257462400059538    steps: 218    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 763   score: 1.0   memory length: 138761   epsilon: 0.7254492400059602    steps: 150    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 764   score: 1.0   memory length: 138912   epsilon: 0.7251502600059667    steps: 151    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 765   score: 2.0   memory length: 139109   epsilon: 0.7247602000059752    steps: 197    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 766   score: 1.0   memory length: 139260   epsilon: 0.7244612200059817    steps: 151    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 767   score: 2.0   memory length: 139478   epsilon: 0.724029580005991    steps: 218    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 768   score: 2.0   memory length: 139697   epsilon: 0.7235959600060005    steps: 219    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 769   score: 3.0   memory length: 139943   epsilon: 0.723108880006011    steps: 246    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 770   score: 0.0   memory length: 140065   epsilon: 0.7228673200060163    steps: 122    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 771   score: 2.0   memory length: 140263   epsilon: 0.7224752800060248    steps: 198    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 772   score: 4.0   memory length: 140559   epsilon: 0.7218892000060375    steps: 296    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 773   score: 4.0   memory length: 140855   epsilon: 0.7213031200060502    steps: 296    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 774   score: 3.0   memory length: 141123   epsilon: 0.7207724800060618    steps: 268    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 775   score: 3.0   memory length: 141354   epsilon: 0.7203151000060717    steps: 231    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 776   score: 2.0   memory length: 141569   epsilon: 0.7198894000060809    steps: 215    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 777   score: 0.0   memory length: 141691   epsilon: 0.7196478400060862    steps: 122    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 778   score: 2.0   memory length: 141913   epsilon: 0.7192082800060957    steps: 222    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 779   score: 0.0   memory length: 142035   epsilon: 0.718966720006101    steps: 122    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 780   score: 0.0   memory length: 142158   epsilon: 0.7187231800061062    steps: 123    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 781   score: 2.0   memory length: 142355   epsilon: 0.7183331200061147    steps: 197    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 782   score: 0.0   memory length: 142478   epsilon: 0.71808958000612    steps: 123    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 783   score: 2.0   memory length: 142696   epsilon: 0.7176579400061294    steps: 218    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 784   score: 1.0   memory length: 142847   epsilon: 0.7173589600061359    steps: 151    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 785   score: 3.0   memory length: 143073   epsilon: 0.7169114800061456    steps: 226    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 786   score: 4.0   memory length: 143384   epsilon: 0.7162957000061589    steps: 311    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 787   score: 2.0   memory length: 143582   epsilon: 0.7159036600061675    steps: 198    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 788   score: 2.0   memory length: 143779   epsilon: 0.7155136000061759    steps: 197    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 789   score: 6.0   memory length: 144172   epsilon: 0.7147354600061928    steps: 393    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 790   score: 3.0   memory length: 144438   epsilon: 0.7142087800062042    steps: 266    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 791   score: 0.0   memory length: 144561   epsilon: 0.7139652400062095    steps: 123    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 792   score: 1.0   memory length: 144730   epsilon: 0.7136306200062168    steps: 169    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 793   score: 2.0   memory length: 144927   epsilon: 0.7132405600062253    steps: 197    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 794   score: 3.0   memory length: 145195   epsilon: 0.7127099200062368    steps: 268    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 795   score: 1.0   memory length: 145345   epsilon: 0.7124129200062432    steps: 150    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 796   score: 2.0   memory length: 145545   epsilon: 0.7120169200062518    steps: 200    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 797   score: 3.0   memory length: 145791   epsilon: 0.7115298400062624    steps: 246    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 798   score: 0.0   memory length: 145914   epsilon: 0.7112863000062677    steps: 123    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 799   score: 3.0   memory length: 146162   epsilon: 0.7107952600062784    steps: 248    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 800   score: 2.0   memory length: 146379   epsilon: 0.7103656000062877    steps: 217    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 801   score: 0.0   memory length: 146501   epsilon: 0.7101240400062929    steps: 122    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 802   score: 2.0   memory length: 146699   epsilon: 0.7097320000063014    steps: 198    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 803   score: 0.0   memory length: 146821   epsilon: 0.7094904400063067    steps: 122    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 804   score: 0.0   memory length: 146944   epsilon: 0.709246900006312    steps: 123    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 805   score: 3.0   memory length: 147153   epsilon: 0.708833080006321    steps: 209    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 806   score: 1.0   memory length: 147304   epsilon: 0.7085341000063274    steps: 151    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 807   score: 2.0   memory length: 147501   epsilon: 0.7081440400063359    steps: 197    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 808   score: 3.0   memory length: 147727   epsilon: 0.7076965600063456    steps: 226    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 809   score: 1.0   memory length: 147877   epsilon: 0.7073995600063521    steps: 150    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 810   score: 2.0   memory length: 148074   epsilon: 0.7070095000063605    steps: 197    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 811   score: 2.0   memory length: 148274   epsilon: 0.7066135000063691    steps: 200    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 812   score: 2.0   memory length: 148492   epsilon: 0.7061818600063785    steps: 218    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 813   score: 3.0   memory length: 148737   epsilon: 0.705696760006389    steps: 245    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 814   score: 6.0   memory length: 149144   epsilon: 0.7048909000064065    steps: 407    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 815   score: 2.0   memory length: 149341   epsilon: 0.704500840006415    steps: 197    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 816   score: 0.0   memory length: 149464   epsilon: 0.7042573000064203    steps: 123    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 817   score: 0.0   memory length: 149587   epsilon: 0.7040137600064256    steps: 123    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 818   score: 3.0   memory length: 149830   epsilon: 0.703532620006436    steps: 243    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 819   score: 1.0   memory length: 149998   epsilon: 0.7031999800064432    steps: 168    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 820   score: 4.0   memory length: 150273   epsilon: 0.7026554800064551    steps: 275    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 821   score: 0.0   memory length: 150396   epsilon: 0.7024119400064603    steps: 123    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 822   score: 1.0   memory length: 150565   epsilon: 0.7020773200064676    steps: 169    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 823   score: 1.0   memory length: 150734   epsilon: 0.7017427000064749    steps: 169    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 824   score: 2.0   memory length: 150951   epsilon: 0.7013130400064842    steps: 217    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 825   score: 1.0   memory length: 151101   epsilon: 0.7010160400064906    steps: 150    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 826   score: 2.0   memory length: 151299   epsilon: 0.7006240000064992    steps: 198    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 827   score: 0.0   memory length: 151421   epsilon: 0.7003824400065044    steps: 122    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 828   score: 0.0   memory length: 151544   epsilon: 0.7001389000065097    steps: 123    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 829   score: 3.0   memory length: 151788   epsilon: 0.6996557800065202    steps: 244    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 830   score: 2.0   memory length: 151969   epsilon: 0.699297400006528    steps: 181    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 831   score: 2.0   memory length: 152186   epsilon: 0.6988677400065373    steps: 217    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 832   score: 2.0   memory length: 152384   epsilon: 0.6984757000065458    steps: 198    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 833   score: 0.0   memory length: 152507   epsilon: 0.6982321600065511    steps: 123    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 834   score: 1.0   memory length: 152678   epsilon: 0.6978935800065584    steps: 171    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 835   score: 3.0   memory length: 152925   epsilon: 0.697404520006569    steps: 247    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 836   score: 0.0   memory length: 153048   epsilon: 0.6971609800065743    steps: 123    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 837   score: 2.0   memory length: 153266   epsilon: 0.6967293400065837    steps: 218    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 838   score: 2.0   memory length: 153485   epsilon: 0.6962957200065931    steps: 219    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 839   score: 3.0   memory length: 153733   epsilon: 0.6958046800066038    steps: 248    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 840   score: 2.0   memory length: 153931   epsilon: 0.6954126400066123    steps: 198    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 841   score: 2.0   memory length: 154128   epsilon: 0.6950225800066208    steps: 197    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 842   score: 3.0   memory length: 154373   epsilon: 0.6945374800066313    steps: 245    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 843   score: 0.0   memory length: 154495   epsilon: 0.6942959200066365    steps: 122    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 844   score: 3.0   memory length: 154721   epsilon: 0.6938484400066462    steps: 226    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 845   score: 6.0   memory length: 155096   epsilon: 0.6931059400066624    steps: 375    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 846   score: 2.0   memory length: 155294   epsilon: 0.6927139000066709    steps: 198    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 847   score: 1.0   memory length: 155463   epsilon: 0.6923792800066781    steps: 169    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 848   score: 0.0   memory length: 155585   epsilon: 0.6921377200066834    steps: 122    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 849   score: 1.0   memory length: 155754   epsilon: 0.6918031000066907    steps: 169    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 850   score: 1.0   memory length: 155922   epsilon: 0.6914704600066979    steps: 168    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 851   score: 3.0   memory length: 156150   epsilon: 0.6910190200067077    steps: 228    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 852   score: 2.0   memory length: 156347   epsilon: 0.6906289600067161    steps: 197    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 853   score: 2.0   memory length: 156545   epsilon: 0.6902369200067247    steps: 198    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 854   score: 2.0   memory length: 156725   epsilon: 0.6898805200067324    steps: 180    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 855   score: 0.0   memory length: 156847   epsilon: 0.6896389600067376    steps: 122    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 856   score: 0.0   memory length: 156970   epsilon: 0.6893954200067429    steps: 123    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 857   score: 0.0   memory length: 157092   epsilon: 0.6891538600067482    steps: 122    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 858   score: 0.0   memory length: 157215   epsilon: 0.6889103200067535    steps: 123    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 859   score: 1.0   memory length: 157386   epsilon: 0.6885717400067608    steps: 171    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 860   score: 2.0   memory length: 157566   epsilon: 0.6882153400067685    steps: 180    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 861   score: 2.0   memory length: 157784   epsilon: 0.6877837000067779    steps: 218    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 862   score: 1.0   memory length: 157955   epsilon: 0.6874451200067853    steps: 171    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 863   score: 0.0   memory length: 158078   epsilon: 0.6872015800067905    steps: 123    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 864   score: 2.0   memory length: 158275   epsilon: 0.686811520006799    steps: 197    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 865   score: 3.0   memory length: 158521   epsilon: 0.6863244400068096    steps: 246    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 866   score: 2.0   memory length: 158719   epsilon: 0.6859324000068181    steps: 198    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 867   score: 6.0   memory length: 159033   epsilon: 0.6853106800068316    steps: 314    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 868   score: 0.0   memory length: 159155   epsilon: 0.6850691200068368    steps: 122    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 869   score: 5.0   memory length: 159480   epsilon: 0.6844256200068508    steps: 325    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 870   score: 0.0   memory length: 159603   epsilon: 0.6841820800068561    steps: 123    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 871   score: 7.0   memory length: 160029   epsilon: 0.6833386000068744    steps: 426    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 872   score: 1.0   memory length: 160197   epsilon: 0.6830059600068816    steps: 168    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 873   score: 0.0   memory length: 160320   epsilon: 0.6827624200068869    steps: 123    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 874   score: 0.0   memory length: 160443   epsilon: 0.6825188800068922    steps: 123    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 875   score: 2.0   memory length: 160640   epsilon: 0.6821288200069007    steps: 197    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 876   score: 4.0   memory length: 160934   epsilon: 0.6815467000069133    steps: 294    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 877   score: 4.0   memory length: 161229   epsilon: 0.680962600006926    steps: 295    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 878   score: 2.0   memory length: 161428   epsilon: 0.6805685800069345    steps: 199    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 879   score: 4.0   memory length: 161720   epsilon: 0.6799904200069471    steps: 292    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 880   score: 4.0   memory length: 162012   epsilon: 0.6794122600069596    steps: 292    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 881   score: 2.0   memory length: 162209   epsilon: 0.6790222000069681    steps: 197    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 882   score: 3.0   memory length: 162457   epsilon: 0.6785311600069788    steps: 248    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 883   score: 4.0   memory length: 162775   epsilon: 0.6779015200069924    steps: 318    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 884   score: 2.0   memory length: 162991   epsilon: 0.6774738400070017    steps: 216    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 885   score: 2.0   memory length: 163188   epsilon: 0.6770837800070102    steps: 197    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 886   score: 1.0   memory length: 163360   epsilon: 0.6767432200070176    steps: 172    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 887   score: 0.0   memory length: 163482   epsilon: 0.6765016600070228    steps: 122    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 888   score: 3.0   memory length: 163746   epsilon: 0.6759789400070342    steps: 264    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 889   score: 3.0   memory length: 163971   epsilon: 0.6755334400070439    steps: 225    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 890   score: 5.0   memory length: 164315   epsilon: 0.6748523200070586    steps: 344    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 891   score: 3.0   memory length: 164585   epsilon: 0.6743177200070702    steps: 270    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 892   score: 2.0   memory length: 164783   epsilon: 0.6739256800070788    steps: 198    lr: 4e-05     evaluation reward: 1.92\n",
      "episode: 893   score: 1.0   memory length: 164954   epsilon: 0.6735871000070861    steps: 171    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 894   score: 0.0   memory length: 165077   epsilon: 0.6733435600070914    steps: 123    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 895   score: 1.0   memory length: 165228   epsilon: 0.6730445800070979    steps: 151    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 896   score: 2.0   memory length: 165425   epsilon: 0.6726545200071063    steps: 197    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 897   score: 4.0   memory length: 165685   epsilon: 0.6721397200071175    steps: 260    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 898   score: 0.0   memory length: 165808   epsilon: 0.6718961800071228    steps: 123    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 899   score: 2.0   memory length: 166006   epsilon: 0.6715041400071313    steps: 198    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 900   score: 3.0   memory length: 166232   epsilon: 0.671056660007141    steps: 226    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 901   score: 1.0   memory length: 166383   epsilon: 0.6707576800071475    steps: 151    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 902   score: 2.0   memory length: 166601   epsilon: 0.6703260400071569    steps: 218    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 903   score: 2.0   memory length: 166799   epsilon: 0.6699340000071654    steps: 198    lr: 4e-05     evaluation reward: 1.92\n",
      "episode: 904   score: 2.0   memory length: 166996   epsilon: 0.6695439400071739    steps: 197    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 905   score: 2.0   memory length: 167193   epsilon: 0.6691538800071823    steps: 197    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 906   score: 1.0   memory length: 167346   epsilon: 0.6688509400071889    steps: 153    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 907   score: 2.0   memory length: 167564   epsilon: 0.6684193000071983    steps: 218    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 908   score: 5.0   memory length: 167870   epsilon: 0.6678134200072114    steps: 306    lr: 4e-05     evaluation reward: 1.95\n",
      "episode: 909   score: 5.0   memory length: 168212   epsilon: 0.6671362600072261    steps: 342    lr: 4e-05     evaluation reward: 1.99\n",
      "episode: 910   score: 3.0   memory length: 168440   epsilon: 0.666684820007236    steps: 228    lr: 4e-05     evaluation reward: 2.0\n",
      "episode: 911   score: 0.0   memory length: 168563   epsilon: 0.6664412800072412    steps: 123    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 912   score: 2.0   memory length: 168760   epsilon: 0.6660512200072497    steps: 197    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 913   score: 9.0   memory length: 169118   epsilon: 0.6653423800072651    steps: 358    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 914   score: 4.0   memory length: 169394   epsilon: 0.664795900007277    steps: 276    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 915   score: 2.0   memory length: 169591   epsilon: 0.6644058400072854    steps: 197    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 916   score: 0.0   memory length: 169714   epsilon: 0.6641623000072907    steps: 123    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 917   score: 3.0   memory length: 169939   epsilon: 0.6637168000073004    steps: 225    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 918   score: 1.0   memory length: 170108   epsilon: 0.6633821800073076    steps: 169    lr: 4e-05     evaluation reward: 2.03\n",
      "episode: 919   score: 1.0   memory length: 170278   epsilon: 0.663045580007315    steps: 170    lr: 4e-05     evaluation reward: 2.03\n",
      "episode: 920   score: 3.0   memory length: 170544   epsilon: 0.6625189000073264    steps: 266    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 921   score: 2.0   memory length: 170761   epsilon: 0.6620892400073357    steps: 217    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 922   score: 2.0   memory length: 170960   epsilon: 0.6616952200073443    steps: 199    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 923   score: 1.0   memory length: 171110   epsilon: 0.6613982200073507    steps: 150    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 924   score: 3.0   memory length: 171336   epsilon: 0.6609507400073604    steps: 226    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 925   score: 3.0   memory length: 171582   epsilon: 0.660463660007371    steps: 246    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 926   score: 3.0   memory length: 171807   epsilon: 0.6600181600073807    steps: 225    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 927   score: 2.0   memory length: 172005   epsilon: 0.6596261200073892    steps: 198    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 928   score: 0.0   memory length: 172127   epsilon: 0.6593845600073944    steps: 122    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 929   score: 0.0   memory length: 172250   epsilon: 0.6591410200073997    steps: 123    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 930   score: 5.0   memory length: 172616   epsilon: 0.6584163400074154    steps: 366    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 931   score: 0.0   memory length: 172738   epsilon: 0.6581747800074207    steps: 122    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 932   score: 2.0   memory length: 172936   epsilon: 0.6577827400074292    steps: 198    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 933   score: 0.0   memory length: 173058   epsilon: 0.6575411800074344    steps: 122    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 934   score: 2.0   memory length: 173255   epsilon: 0.6571511200074429    steps: 197    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 935   score: 3.0   memory length: 173517   epsilon: 0.6566323600074542    steps: 262    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 936   score: 3.0   memory length: 173742   epsilon: 0.6561868600074638    steps: 225    lr: 4e-05     evaluation reward: 2.13\n",
      "episode: 937   score: 3.0   memory length: 173990   epsilon: 0.6556958200074745    steps: 248    lr: 4e-05     evaluation reward: 2.14\n",
      "episode: 938   score: 5.0   memory length: 174332   epsilon: 0.6550186600074892    steps: 342    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 939   score: 2.0   memory length: 174530   epsilon: 0.6546266200074977    steps: 198    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 940   score: 3.0   memory length: 174755   epsilon: 0.6541811200075074    steps: 225    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 941   score: 2.0   memory length: 174953   epsilon: 0.6537890800075159    steps: 198    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 942   score: 3.0   memory length: 175164   epsilon: 0.653371300007525    steps: 211    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 943   score: 0.0   memory length: 175286   epsilon: 0.6531297400075302    steps: 122    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 944   score: 3.0   memory length: 175512   epsilon: 0.6526822600075399    steps: 226    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 945   score: 3.0   memory length: 175737   epsilon: 0.6522367600075496    steps: 225    lr: 4e-05     evaluation reward: 2.14\n",
      "episode: 946   score: 0.0   memory length: 175860   epsilon: 0.6519932200075549    steps: 123    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 947   score: 3.0   memory length: 176086   epsilon: 0.6515457400075646    steps: 226    lr: 4e-05     evaluation reward: 2.14\n",
      "episode: 948   score: 7.0   memory length: 176405   epsilon: 0.6509141200075783    steps: 319    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 949   score: 3.0   memory length: 176675   epsilon: 0.6503795200075899    steps: 270    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 950   score: 0.0   memory length: 176798   epsilon: 0.6501359800075952    steps: 123    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 951   score: 3.0   memory length: 177024   epsilon: 0.6496885000076049    steps: 226    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 952   score: 3.0   memory length: 177271   epsilon: 0.6491994400076155    steps: 247    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 953   score: 3.0   memory length: 177518   epsilon: 0.6487103800076262    steps: 247    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 954   score: 2.0   memory length: 177716   epsilon: 0.6483183400076347    steps: 198    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 955   score: 4.0   memory length: 177991   epsilon: 0.6477738400076465    steps: 275    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 956   score: 2.0   memory length: 178190   epsilon: 0.647379820007655    steps: 199    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 957   score: 0.0   memory length: 178313   epsilon: 0.6471362800076603    steps: 123    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 958   score: 3.0   memory length: 178561   epsilon: 0.646645240007671    steps: 248    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 959   score: 2.0   memory length: 178759   epsilon: 0.6462532000076795    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 960   score: 2.0   memory length: 178974   epsilon: 0.6458275000076887    steps: 215    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 961   score: 1.0   memory length: 179143   epsilon: 0.645492880007696    steps: 169    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 962   score: 2.0   memory length: 179341   epsilon: 0.6451008400077045    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 963   score: 1.0   memory length: 179510   epsilon: 0.6447662200077118    steps: 169    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 964   score: 2.0   memory length: 179728   epsilon: 0.6443345800077211    steps: 218    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 965   score: 3.0   memory length: 179997   epsilon: 0.6438019600077327    steps: 269    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 966   score: 0.0   memory length: 180120   epsilon: 0.643558420007738    steps: 123    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 967   score: 2.0   memory length: 180319   epsilon: 0.6431644000077466    steps: 199    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 968   score: 4.0   memory length: 180596   epsilon: 0.6426159400077585    steps: 277    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 969   score: 3.0   memory length: 180844   epsilon: 0.6421249000077691    steps: 248    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 970   score: 1.0   memory length: 180995   epsilon: 0.6418259200077756    steps: 151    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 971   score: 0.0   memory length: 181117   epsilon: 0.6415843600077809    steps: 122    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 972   score: 1.0   memory length: 181267   epsilon: 0.6412873600077873    steps: 150    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 973   score: 2.0   memory length: 181465   epsilon: 0.6408953200077958    steps: 198    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 974   score: 1.0   memory length: 181617   epsilon: 0.6405943600078023    steps: 152    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 975   score: 1.0   memory length: 181789   epsilon: 0.6402538000078097    steps: 172    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 976   score: 4.0   memory length: 182067   epsilon: 0.6397033600078217    steps: 278    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 977   score: 2.0   memory length: 182265   epsilon: 0.6393113200078302    steps: 198    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 978   score: 3.0   memory length: 182491   epsilon: 0.6388638400078399    steps: 226    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 979   score: 2.0   memory length: 182688   epsilon: 0.6384737800078484    steps: 197    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 980   score: 3.0   memory length: 182931   epsilon: 0.6379926400078588    steps: 243    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 981   score: 2.0   memory length: 183129   epsilon: 0.6376006000078673    steps: 198    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 982   score: 4.0   memory length: 183443   epsilon: 0.6369788800078808    steps: 314    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 983   score: 3.0   memory length: 183689   epsilon: 0.6364918000078914    steps: 246    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 984   score: 4.0   memory length: 183970   epsilon: 0.6359354200079035    steps: 281    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 985   score: 2.0   memory length: 184185   epsilon: 0.6355097200079127    steps: 215    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 986   score: 1.0   memory length: 184336   epsilon: 0.6352107400079192    steps: 151    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 987   score: 2.0   memory length: 184533   epsilon: 0.6348206800079277    steps: 197    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 988   score: 0.0   memory length: 184656   epsilon: 0.634577140007933    steps: 123    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 989   score: 2.0   memory length: 184874   epsilon: 0.6341455000079423    steps: 218    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 990   score: 0.0   memory length: 184996   epsilon: 0.6339039400079476    steps: 122    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 991   score: 4.0   memory length: 185271   epsilon: 0.6333594400079594    steps: 275    lr: 4e-05     evaluation reward: 2.19\n",
      "episode: 992   score: 4.0   memory length: 185527   epsilon: 0.6328525600079704    steps: 256    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 993   score: 4.0   memory length: 185823   epsilon: 0.6322664800079831    steps: 296    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 994   score: 1.0   memory length: 185973   epsilon: 0.6319694800079896    steps: 150    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 995   score: 3.0   memory length: 186219   epsilon: 0.6314824000080002    steps: 246    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 996   score: 3.0   memory length: 186462   epsilon: 0.6310012600080106    steps: 243    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 997   score: 1.0   memory length: 186613   epsilon: 0.6307022800080171    steps: 151    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 998   score: 4.0   memory length: 186866   epsilon: 0.630201340008028    steps: 253    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 999   score: 4.0   memory length: 187162   epsilon: 0.6296152600080407    steps: 296    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1000   score: 2.0   memory length: 187379   epsilon: 0.62918560000805    steps: 217    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1001   score: 2.0   memory length: 187598   epsilon: 0.6287519800080594    steps: 219    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1002   score: 4.0   memory length: 187892   epsilon: 0.6281698600080721    steps: 294    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1003   score: 2.0   memory length: 188090   epsilon: 0.6277778200080806    steps: 198    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1004   score: 4.0   memory length: 188349   epsilon: 0.6272650000080917    steps: 259    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1005   score: 4.0   memory length: 188603   epsilon: 0.6267620800081026    steps: 254    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1006   score: 3.0   memory length: 188829   epsilon: 0.6263146000081123    steps: 226    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1007   score: 2.0   memory length: 189027   epsilon: 0.6259225600081209    steps: 198    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1008   score: 3.0   memory length: 189272   epsilon: 0.6254374600081314    steps: 245    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1009   score: 1.0   memory length: 189443   epsilon: 0.6250988800081387    steps: 171    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1010   score: 2.0   memory length: 189641   epsilon: 0.6247068400081472    steps: 198    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1011   score: 1.0   memory length: 189792   epsilon: 0.6244078600081537    steps: 151    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1012   score: 2.0   memory length: 190009   epsilon: 0.6239782000081631    steps: 217    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1013   score: 2.0   memory length: 190226   epsilon: 0.6235485400081724    steps: 217    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1014   score: 4.0   memory length: 190519   epsilon: 0.622968400008185    steps: 293    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1015   score: 2.0   memory length: 190717   epsilon: 0.6225763600081935    steps: 198    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1016   score: 4.0   memory length: 191017   epsilon: 0.6219823600082064    steps: 300    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1017   score: 3.0   memory length: 191225   epsilon: 0.6215705200082153    steps: 208    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1018   score: 3.0   memory length: 191490   epsilon: 0.6210458200082267    steps: 265    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1019   score: 3.0   memory length: 191757   epsilon: 0.6205171600082382    steps: 267    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1020   score: 2.0   memory length: 191954   epsilon: 0.6201271000082467    steps: 197    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1021   score: 2.0   memory length: 192171   epsilon: 0.619697440008256    steps: 217    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1022   score: 1.0   memory length: 192322   epsilon: 0.6193984600082625    steps: 151    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1023   score: 3.0   memory length: 192568   epsilon: 0.6189113800082731    steps: 246    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1024   score: 0.0   memory length: 192691   epsilon: 0.6186678400082783    steps: 123    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1025   score: 2.0   memory length: 192888   epsilon: 0.6182777800082868    steps: 197    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1026   score: 1.0   memory length: 193039   epsilon: 0.6179788000082933    steps: 151    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1027   score: 3.0   memory length: 193282   epsilon: 0.6174976600083038    steps: 243    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1028   score: 4.0   memory length: 193525   epsilon: 0.6170165200083142    steps: 243    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1029   score: 2.0   memory length: 193745   epsilon: 0.6165809200083237    steps: 220    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1030   score: 0.0   memory length: 193867   epsilon: 0.6163393600083289    steps: 122    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1031   score: 2.0   memory length: 194064   epsilon: 0.6159493000083374    steps: 197    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1032   score: 1.0   memory length: 194235   epsilon: 0.6156107200083447    steps: 171    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1033   score: 0.0   memory length: 194358   epsilon: 0.61536718000835    steps: 123    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1034   score: 4.0   memory length: 194654   epsilon: 0.6147811000083627    steps: 296    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1035   score: 2.0   memory length: 194872   epsilon: 0.6143494600083721    steps: 218    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1036   score: 3.0   memory length: 195137   epsilon: 0.6138247600083835    steps: 265    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1037   score: 3.0   memory length: 195381   epsilon: 0.613341640008394    steps: 244    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1038   score: 2.0   memory length: 195578   epsilon: 0.6129515800084024    steps: 197    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1039   score: 2.0   memory length: 195799   epsilon: 0.6125140000084119    steps: 221    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1040   score: 2.0   memory length: 195980   epsilon: 0.6121556200084197    steps: 181    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1041   score: 3.0   memory length: 196226   epsilon: 0.6116685400084303    steps: 246    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1042   score: 2.0   memory length: 196423   epsilon: 0.6112784800084388    steps: 197    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1043   score: 5.0   memory length: 196771   epsilon: 0.6105894400084537    steps: 348    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1044   score: 2.0   memory length: 196990   epsilon: 0.6101558200084631    steps: 219    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1045   score: 2.0   memory length: 197188   epsilon: 0.6097637800084716    steps: 198    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1046   score: 6.0   memory length: 197605   epsilon: 0.6089381200084896    steps: 417    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1047   score: 2.0   memory length: 197787   epsilon: 0.6085777600084974    steps: 182    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1048   score: 3.0   memory length: 198013   epsilon: 0.6081302800085071    steps: 226    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1049   score: 2.0   memory length: 198210   epsilon: 0.6077402200085156    steps: 197    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1050   score: 4.0   memory length: 198472   epsilon: 0.6072214600085268    steps: 262    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1051   score: 2.0   memory length: 198671   epsilon: 0.6068274400085354    steps: 199    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1052   score: 4.0   memory length: 198966   epsilon: 0.6062433400085481    steps: 295    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1053   score: 4.0   memory length: 199222   epsilon: 0.6057364600085591    steps: 256    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1054   score: 2.0   memory length: 199441   epsilon: 0.6053028400085685    steps: 219    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1055   score: 3.0   memory length: 199671   epsilon: 0.6048474400085784    steps: 230    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1056   score: 1.0   memory length: 199822   epsilon: 0.6045484600085849    steps: 151    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1057   score: 5.0   memory length: 200188   epsilon: 0.6038237800086006    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 2.39\n",
      "episode: 1058   score: 1.0   memory length: 200339   epsilon: 0.6035248000086071    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.37\n",
      "episode: 1059   score: 3.0   memory length: 200569   epsilon: 0.603069400008617    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 2.38\n",
      "episode: 1060   score: 2.0   memory length: 200749   epsilon: 0.6027130000086247    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 2.38\n",
      "episode: 1061   score: 3.0   memory length: 200996   epsilon: 0.6022239400086353    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.4\n",
      "episode: 1062   score: 1.0   memory length: 201147   epsilon: 0.6019249600086418    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.39\n",
      "episode: 1063   score: 2.0   memory length: 201345   epsilon: 0.6015329200086503    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.4\n",
      "episode: 1064   score: 3.0   memory length: 201591   epsilon: 0.6010458400086609    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 2.41\n",
      "episode: 1065   score: 3.0   memory length: 201841   epsilon: 0.6005508400086716    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 2.41\n",
      "episode: 1066   score: 1.0   memory length: 201991   epsilon: 0.6002538400086781    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 2.42\n",
      "episode: 1067   score: 5.0   memory length: 202312   epsilon: 0.5996182600086919    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 2.45\n",
      "episode: 1068   score: 3.0   memory length: 202540   epsilon: 0.5991668200087017    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 2.44\n",
      "episode: 1069   score: 5.0   memory length: 202866   epsilon: 0.5985213400087157    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 2.46\n",
      "episode: 1070   score: 1.0   memory length: 203038   epsilon: 0.5981807800087231    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 2.46\n",
      "episode: 1071   score: 3.0   memory length: 203284   epsilon: 0.5976937000087337    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 2.49\n",
      "episode: 1072   score: 3.0   memory length: 203534   epsilon: 0.5971987000087444    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 2.51\n",
      "episode: 1073   score: 3.0   memory length: 203781   epsilon: 0.596709640008755    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1074   score: 4.0   memory length: 204056   epsilon: 0.5961651400087669    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 2.55\n",
      "episode: 1075   score: 3.0   memory length: 204285   epsilon: 0.5957117200087767    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1076   score: 0.0   memory length: 204408   epsilon: 0.595468180008782    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.53\n",
      "episode: 1077   score: 1.0   memory length: 204577   epsilon: 0.5951335600087893    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1078   score: 4.0   memory length: 204873   epsilon: 0.594547480008802    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 2.53\n",
      "episode: 1079   score: 3.0   memory length: 205088   epsilon: 0.5941217800088112    steps: 215    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1080   score: 5.0   memory length: 205421   epsilon: 0.5934624400088255    steps: 333    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1081   score: 4.0   memory length: 205697   epsilon: 0.5929159600088374    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 2.58\n",
      "episode: 1082   score: 3.0   memory length: 205944   epsilon: 0.592426900008848    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1083   score: 1.0   memory length: 206095   epsilon: 0.5921279200088545    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.55\n",
      "episode: 1084   score: 6.0   memory length: 206466   epsilon: 0.5913933400088704    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1085   score: 3.0   memory length: 206717   epsilon: 0.5908963600088812    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 2.58\n",
      "episode: 1086   score: 3.0   memory length: 206943   epsilon: 0.590448880008891    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1087   score: 2.0   memory length: 207141   epsilon: 0.5900568400088995    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1088   score: 2.0   memory length: 207359   epsilon: 0.5896252000089088    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 2.62\n",
      "episode: 1089   score: 3.0   memory length: 207605   epsilon: 0.5891381200089194    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 2.63\n",
      "episode: 1090   score: 2.0   memory length: 207823   epsilon: 0.5887064800089288    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1091   score: 4.0   memory length: 208118   epsilon: 0.5881223800089415    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1092   score: 1.0   memory length: 208270   epsilon: 0.587821420008948    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 2.62\n",
      "episode: 1093   score: 1.0   memory length: 208421   epsilon: 0.5875224400089545    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.59\n",
      "episode: 1094   score: 2.0   memory length: 208641   epsilon: 0.5870868400089639    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1095   score: 2.0   memory length: 208858   epsilon: 0.5866571800089733    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 2.59\n",
      "episode: 1096   score: 4.0   memory length: 209150   epsilon: 0.5860790200089858    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1097   score: 1.0   memory length: 209321   epsilon: 0.5857404400089932    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1098   score: 0.0   memory length: 209444   epsilon: 0.5854969000089985    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1099   score: 2.0   memory length: 209642   epsilon: 0.585104860009007    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1100   score: 4.0   memory length: 209934   epsilon: 0.5845267000090195    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1101   score: 4.0   memory length: 210209   epsilon: 0.5839822000090313    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 2.58\n",
      "episode: 1102   score: 2.0   memory length: 210389   epsilon: 0.5836258000090391    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1103   score: 2.0   memory length: 210608   epsilon: 0.5831921800090485    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1104   score: 3.0   memory length: 210856   epsilon: 0.5827011400090591    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 2.55\n",
      "episode: 1105   score: 2.0   memory length: 211075   epsilon: 0.5822675200090686    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 2.53\n",
      "episode: 1106   score: 2.0   memory length: 211291   epsilon: 0.5818398400090778    steps: 216    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1107   score: 2.0   memory length: 211489   epsilon: 0.5814478000090864    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1108   score: 2.0   memory length: 211687   epsilon: 0.5810557600090949    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.51\n",
      "episode: 1109   score: 2.0   memory length: 211866   epsilon: 0.5807013400091026    steps: 179    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1110   score: 2.0   memory length: 212065   epsilon: 0.5803073200091111    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 2.52\n",
      "episode: 1111   score: 2.0   memory length: 212285   epsilon: 0.5798717200091206    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 2.53\n",
      "episode: 1112   score: 4.0   memory length: 212603   epsilon: 0.5792420800091342    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 2.55\n",
      "episode: 1113   score: 1.0   memory length: 212753   epsilon: 0.5789450800091407    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1114   score: 3.0   memory length: 213000   epsilon: 0.5784560200091513    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.53\n",
      "episode: 1115   score: 3.0   memory length: 213247   epsilon: 0.5779669600091619    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1116   score: 1.0   memory length: 213416   epsilon: 0.5776323400091692    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 2.51\n",
      "episode: 1117   score: 6.0   memory length: 213769   epsilon: 0.5769334000091844    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1118   score: 3.0   memory length: 214013   epsilon: 0.5764502800091948    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1119   score: 3.0   memory length: 214239   epsilon: 0.5760028000092046    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 2.54\n",
      "episode: 1120   score: 4.0   memory length: 214537   epsilon: 0.5754127600092174    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1121   score: 3.0   memory length: 214783   epsilon: 0.574925680009228    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1122   score: 4.0   memory length: 215024   epsilon: 0.5744485000092383    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1123   score: 0.0   memory length: 215147   epsilon: 0.5742049600092436    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1124   score: 5.0   memory length: 215485   epsilon: 0.5735357200092581    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 2.62\n",
      "episode: 1125   score: 3.0   memory length: 215710   epsilon: 0.5730902200092678    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 2.63\n",
      "episode: 1126   score: 1.0   memory length: 215860   epsilon: 0.5727932200092742    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 2.63\n",
      "episode: 1127   score: 1.0   memory length: 216031   epsilon: 0.5724546400092816    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 2.61\n",
      "episode: 1128   score: 1.0   memory length: 216182   epsilon: 0.5721556600092881    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.58\n",
      "episode: 1129   score: 1.0   memory length: 216333   epsilon: 0.5718566800092946    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1130   score: 0.0   memory length: 216456   epsilon: 0.5716131400092999    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1131   score: 2.0   memory length: 216654   epsilon: 0.5712211000093084    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1132   score: 1.0   memory length: 216823   epsilon: 0.5708864800093156    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1133   score: 0.0   memory length: 216946   epsilon: 0.5706429400093209    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.57\n",
      "episode: 1134   score: 3.0   memory length: 217189   epsilon: 0.5701618000093314    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 2.56\n",
      "episode: 1135   score: 6.0   memory length: 217509   epsilon: 0.5695282000093451    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 2.6\n",
      "episode: 1136   score: 5.0   memory length: 217797   epsilon: 0.5689579600093575    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 2.62\n",
      "episode: 1137   score: 4.0   memory length: 218093   epsilon: 0.5683718800093702    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 2.63\n",
      "episode: 1138   score: 4.0   memory length: 218370   epsilon: 0.5678234200093821    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1139   score: 3.0   memory length: 218619   epsilon: 0.5673304000093928    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 2.66\n",
      "episode: 1140   score: 3.0   memory length: 218845   epsilon: 0.5668829200094025    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 2.67\n",
      "episode: 1141   score: 1.0   memory length: 218998   epsilon: 0.5665799800094091    steps: 153    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1142   score: 6.0   memory length: 219339   epsilon: 0.5659048000094238    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 2.69\n",
      "episode: 1143   score: 2.0   memory length: 219556   epsilon: 0.5654751400094331    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 2.66\n",
      "episode: 1144   score: 3.0   memory length: 219786   epsilon: 0.565019740009443    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 2.67\n",
      "episode: 1145   score: 5.0   memory length: 220131   epsilon: 0.5643366400094578    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 2.7\n",
      "episode: 1146   score: 2.0   memory length: 220347   epsilon: 0.5639089600094671    steps: 216    lr: 1.6000000000000003e-05     evaluation reward: 2.66\n",
      "episode: 1147   score: 3.0   memory length: 220572   epsilon: 0.5634634600094768    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 2.67\n",
      "episode: 1148   score: 4.0   memory length: 220865   epsilon: 0.5628833200094894    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 2.68\n",
      "episode: 1149   score: 2.0   memory length: 221063   epsilon: 0.5624912800094979    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.68\n",
      "episode: 1150   score: 1.0   memory length: 221232   epsilon: 0.5621566600095051    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1151   score: 2.0   memory length: 221414   epsilon: 0.561796300009513    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1152   score: 4.0   memory length: 221709   epsilon: 0.5612122000095257    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 2.65\n",
      "episode: 1153   score: 3.0   memory length: 221954   epsilon: 0.5607271000095362    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 2.64\n",
      "episode: 1154   score: 2.0   memory length: 222175   epsilon: 0.5602895200095457    steps: 221    lr: 1.6000000000000003e-05     evaluation reward: 2.64\n",
      "episode: 1155   score: 2.0   memory length: 222393   epsilon: 0.559857880009555    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 2.63\n",
      "episode: 1156   score: 5.0   memory length: 222701   epsilon: 0.5592480400095683    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 2.67\n",
      "episode: 1157   score: 5.0   memory length: 223045   epsilon: 0.5585669200095831    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 2.67\n",
      "episode: 1158   score: 2.0   memory length: 223243   epsilon: 0.5581748800095916    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.68\n",
      "episode: 1159   score: 4.0   memory length: 223538   epsilon: 0.5575907800096043    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 2.69\n",
      "episode: 1160   score: 3.0   memory length: 223786   epsilon: 0.5570997400096149    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 2.7\n",
      "episode: 1161   score: 1.0   memory length: 223937   epsilon: 0.5568007600096214    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.68\n",
      "episode: 1162   score: 2.0   memory length: 224118   epsilon: 0.5564423800096292    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 2.69\n",
      "episode: 1163   score: 5.0   memory length: 224442   epsilon: 0.5558008600096431    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 2.72\n",
      "episode: 1164   score: 5.0   memory length: 224756   epsilon: 0.5551791400096566    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 2.74\n",
      "episode: 1165   score: 4.0   memory length: 225033   epsilon: 0.5546306800096685    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 2.75\n",
      "episode: 1166   score: 8.0   memory length: 225438   epsilon: 0.5538287800096859    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 2.82\n",
      "episode: 1167   score: 6.0   memory length: 225765   epsilon: 0.5531813200097    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 2.83\n",
      "episode: 1168   score: 1.0   memory length: 225917   epsilon: 0.5528803600097065    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 2.81\n",
      "episode: 1169   score: 4.0   memory length: 226177   epsilon: 0.5523655600097177    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 2.8\n",
      "episode: 1170   score: 0.0   memory length: 226300   epsilon: 0.552122020009723    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1171   score: 3.0   memory length: 226547   epsilon: 0.5516329600097336    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1172   score: 3.0   memory length: 226774   epsilon: 0.5511835000097434    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1173   score: 3.0   memory length: 226984   epsilon: 0.5507677000097524    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1174   score: 3.0   memory length: 227231   epsilon: 0.550278640009763    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 2.78\n",
      "episode: 1175   score: 3.0   memory length: 227497   epsilon: 0.5497519600097744    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 2.78\n",
      "episode: 1176   score: 1.0   memory length: 227667   epsilon: 0.5494153600097818    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1177   score: 6.0   memory length: 228003   epsilon: 0.5487500800097962    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 2.84\n",
      "episode: 1178   score: 4.0   memory length: 228299   epsilon: 0.5481640000098089    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 2.84\n",
      "episode: 1179   score: 1.0   memory length: 228470   epsilon: 0.5478254200098163    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 2.82\n",
      "episode: 1180   score: 2.0   memory length: 228652   epsilon: 0.5474650600098241    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 2.79\n",
      "episode: 1181   score: 2.0   memory length: 228871   epsilon: 0.5470314400098335    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 2.77\n",
      "episode: 1182   score: 8.0   memory length: 229313   epsilon: 0.5461562800098525    steps: 442    lr: 1.6000000000000003e-05     evaluation reward: 2.82\n",
      "episode: 1183   score: 2.0   memory length: 229511   epsilon: 0.545764240009861    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.83\n",
      "episode: 1184   score: 3.0   memory length: 229757   epsilon: 0.5452771600098716    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 2.8\n",
      "episode: 1185   score: 5.0   memory length: 230045   epsilon: 0.544706920009884    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 2.82\n",
      "episode: 1186   score: 4.0   memory length: 230302   epsilon: 0.544198060009895    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 2.83\n",
      "episode: 1187   score: 2.0   memory length: 230520   epsilon: 0.5437664200099044    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 2.83\n",
      "episode: 1188   score: 6.0   memory length: 230858   epsilon: 0.5430971800099189    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 2.87\n",
      "episode: 1189   score: 4.0   memory length: 231134   epsilon: 0.5425507000099308    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 2.88\n",
      "episode: 1190   score: 5.0   memory length: 231442   epsilon: 0.541940860009944    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 2.91\n",
      "episode: 1191   score: 5.0   memory length: 231723   epsilon: 0.5413844800099561    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 2.92\n",
      "episode: 1192   score: 2.0   memory length: 231923   epsilon: 0.5409884800099647    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 2.93\n",
      "episode: 1193   score: 2.0   memory length: 232120   epsilon: 0.5405984200099732    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 2.94\n",
      "episode: 1194   score: 3.0   memory length: 232347   epsilon: 0.5401489600099829    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 2.95\n",
      "episode: 1195   score: 3.0   memory length: 232577   epsilon: 0.5396935600099928    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 2.96\n",
      "episode: 1196   score: 3.0   memory length: 232790   epsilon: 0.539271820010002    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 2.95\n",
      "episode: 1197   score: 3.0   memory length: 233056   epsilon: 0.5387451400100134    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 2.97\n",
      "episode: 1198   score: 3.0   memory length: 233286   epsilon: 0.5382897400100233    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.0\n",
      "episode: 1199   score: 1.0   memory length: 233437   epsilon: 0.5379907600100298    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 2.99\n",
      "episode: 1200   score: 3.0   memory length: 233663   epsilon: 0.5375432800100395    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 2.98\n",
      "episode: 1201   score: 2.0   memory length: 233861   epsilon: 0.537151240010048    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 2.96\n",
      "episode: 1202   score: 8.0   memory length: 234272   epsilon: 0.5363374600100657    steps: 411    lr: 1.6000000000000003e-05     evaluation reward: 3.02\n",
      "episode: 1203   score: 3.0   memory length: 234500   epsilon: 0.5358860200100755    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.03\n",
      "episode: 1204   score: 4.0   memory length: 234754   epsilon: 0.5353831000100864    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 3.04\n",
      "episode: 1205   score: 3.0   memory length: 234982   epsilon: 0.5349316600100962    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.05\n",
      "episode: 1206   score: 5.0   memory length: 235299   epsilon: 0.5343040000101098    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 3.08\n",
      "episode: 1207   score: 5.0   memory length: 235624   epsilon: 0.5336605000101238    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.11\n",
      "episode: 1208   score: 3.0   memory length: 235852   epsilon: 0.5332090600101336    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.12\n",
      "episode: 1209   score: 6.0   memory length: 236207   epsilon: 0.5325061600101488    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 3.16\n",
      "episode: 1210   score: 3.0   memory length: 236434   epsilon: 0.5320567000101586    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.17\n",
      "episode: 1211   score: 2.0   memory length: 236652   epsilon: 0.531625060010168    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.17\n",
      "episode: 1212   score: 3.0   memory length: 236879   epsilon: 0.5311756000101777    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.16\n",
      "episode: 1213   score: 5.0   memory length: 237224   epsilon: 0.5304925000101925    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n",
      "episode: 1214   score: 4.0   memory length: 237519   epsilon: 0.5299084000102052    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n",
      "episode: 1215   score: 8.0   memory length: 237834   epsilon: 0.5292847000102188    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1216   score: 2.0   memory length: 238014   epsilon: 0.5289283000102265    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1217   score: 6.0   memory length: 238359   epsilon: 0.5282452000102413    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1218   score: 0.0   memory length: 238482   epsilon: 0.5280016600102466    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1219   score: 3.0   memory length: 238729   epsilon: 0.5275126000102572    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1220   score: 3.0   memory length: 238975   epsilon: 0.5270255200102678    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1221   score: 2.0   memory length: 239174   epsilon: 0.5266315000102764    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1222   score: 1.0   memory length: 239346   epsilon: 0.5262909400102838    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n",
      "episode: 1223   score: 0.0   memory length: 239469   epsilon: 0.526047400010289    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n",
      "episode: 1224   score: 3.0   memory length: 239699   epsilon: 0.5255920000102989    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.17\n",
      "episode: 1225   score: 6.0   memory length: 240030   epsilon: 0.5249366200103132    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n",
      "episode: 1226   score: 2.0   memory length: 240248   epsilon: 0.5245049800103225    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n",
      "episode: 1227   score: 1.0   memory length: 240417   epsilon: 0.5241703600103298    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n",
      "episode: 1228   score: 2.0   memory length: 240615   epsilon: 0.5237783200103383    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1229   score: 3.0   memory length: 240861   epsilon: 0.5232912400103489    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1230   score: 2.0   memory length: 241078   epsilon: 0.5228615800103582    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1231   score: 5.0   memory length: 241387   epsilon: 0.5222497600103715    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1232   score: 3.0   memory length: 241632   epsilon: 0.521764660010382    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1233   score: 5.0   memory length: 241961   epsilon: 0.5211132400103962    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1234   score: 3.0   memory length: 242171   epsilon: 0.5206974400104052    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1235   score: 2.0   memory length: 242370   epsilon: 0.5203034200104137    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1236   score: 2.0   memory length: 242567   epsilon: 0.5199133600104222    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1237   score: 4.0   memory length: 242860   epsilon: 0.5193332200104348    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1238   score: 2.0   memory length: 243058   epsilon: 0.5189411800104433    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1239   score: 2.0   memory length: 243277   epsilon: 0.5185075600104527    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1240   score: 2.0   memory length: 243477   epsilon: 0.5181115600104613    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1241   score: 5.0   memory length: 243793   epsilon: 0.5174858800104749    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1242   score: 3.0   memory length: 244019   epsilon: 0.5170384000104846    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1243   score: 1.0   memory length: 244188   epsilon: 0.5167037800104919    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1244   score: 3.0   memory length: 244413   epsilon: 0.5162582800105016    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1245   score: 2.0   memory length: 244611   epsilon: 0.5158662400105101    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1246   score: 4.0   memory length: 244890   epsilon: 0.5153138200105221    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1247   score: 5.0   memory length: 245239   epsilon: 0.5146228000105371    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1248   score: 2.0   memory length: 245437   epsilon: 0.5142307600105456    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1249   score: 3.0   memory length: 245684   epsilon: 0.5137417000105562    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1250   score: 4.0   memory length: 245978   epsilon: 0.5131595800105688    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.28\n",
      "episode: 1251   score: 5.0   memory length: 246262   epsilon: 0.512597260010581    steps: 284    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1252   score: 5.0   memory length: 246553   epsilon: 0.5120210800105935    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1253   score: 3.0   memory length: 246798   epsilon: 0.5115359800106041    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1254   score: 4.0   memory length: 247073   epsilon: 0.5109914800106159    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1255   score: 1.0   memory length: 247224   epsilon: 0.5106925000106224    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1256   score: 4.0   memory length: 247481   epsilon: 0.5101836400106334    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1257   score: 7.0   memory length: 247908   epsilon: 0.5093381800106518    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1258   score: 4.0   memory length: 248203   epsilon: 0.5087540800106645    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1259   score: 7.0   memory length: 248599   epsilon: 0.5079700000106815    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1260   score: 3.0   memory length: 248810   epsilon: 0.5075522200106906    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1261   score: 2.0   memory length: 249009   epsilon: 0.5071582000106991    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1262   score: 2.0   memory length: 249209   epsilon: 0.5067622000107077    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1263   score: 3.0   memory length: 249437   epsilon: 0.5063107600107175    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1264   score: 3.0   memory length: 249702   epsilon: 0.5057860600107289    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1265   score: 4.0   memory length: 250018   epsilon: 0.5051603800107425    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1266   score: 5.0   memory length: 250340   epsilon: 0.5045228200107563    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1267   score: 3.0   memory length: 250568   epsilon: 0.5040713800107661    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1268   score: 3.0   memory length: 250815   epsilon: 0.5035823200107767    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1269   score: 3.0   memory length: 251061   epsilon: 0.5030952400107873    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1270   score: 4.0   memory length: 251318   epsilon: 0.5025863800107984    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1271   score: 3.0   memory length: 251583   epsilon: 0.5020616800108098    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1272   score: 4.0   memory length: 251842   epsilon: 0.5015488600108209    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1273   score: 2.0   memory length: 252042   epsilon: 0.5011528600108295    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1274   score: 2.0   memory length: 252223   epsilon: 0.5007944800108373    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1275   score: 1.0   memory length: 252395   epsilon: 0.5004539200108447    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1276   score: 3.0   memory length: 252623   epsilon: 0.5000024800108545    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1277   score: 4.0   memory length: 252898   epsilon: 0.49945798001085107    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1278   score: 2.0   memory length: 253095   epsilon: 0.4990679200108486    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1279   score: 3.0   memory length: 253339   epsilon: 0.49858480001084554    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1280   score: 5.0   memory length: 253684   epsilon: 0.4979017000108412    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1281   score: 3.0   memory length: 253895   epsilon: 0.4974839200108386    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1282   score: 5.0   memory length: 254221   epsilon: 0.4968384400108345    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1283   score: 4.0   memory length: 254498   epsilon: 0.496289980010831    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1284   score: 2.0   memory length: 254716   epsilon: 0.4958583400108283    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1285   score: 0.0   memory length: 254839   epsilon: 0.49561480001082675    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1286   score: 5.0   memory length: 255166   epsilon: 0.49496734001082265    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1287   score: 3.0   memory length: 255415   epsilon: 0.49447432001081953    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1288   score: 7.0   memory length: 255716   epsilon: 0.49387834001081576    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1289   score: 3.0   memory length: 255948   epsilon: 0.49341898001081286    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1290   score: 0.0   memory length: 256071   epsilon: 0.4931754400108113    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1291   score: 3.0   memory length: 256303   epsilon: 0.4927160800108084    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1292   score: 3.0   memory length: 256548   epsilon: 0.49223098001080534    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1293   score: 5.0   memory length: 256887   epsilon: 0.4915597600108011    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 3.28\n",
      "episode: 1294   score: 3.0   memory length: 257118   epsilon: 0.4911023800107982    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.28\n",
      "episode: 1295   score: 2.0   memory length: 257298   epsilon: 0.49074598001079595    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1296   score: 5.0   memory length: 257638   epsilon: 0.4900727800107917    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1297   score: 5.0   memory length: 257925   epsilon: 0.4895045200107881    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1298   score: 2.0   memory length: 258123   epsilon: 0.4891124800107856    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1299   score: 10.0   memory length: 258488   epsilon: 0.48838978001078104    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1300   score: 5.0   memory length: 258797   epsilon: 0.48777796001077717    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1301   score: 3.0   memory length: 259042   epsilon: 0.4872928600107741    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n",
      "episode: 1302   score: 1.0   memory length: 259213   epsilon: 0.48695428001077196    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1303   score: 3.0   memory length: 259426   epsilon: 0.4865325400107693    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1304   score: 5.0   memory length: 259715   epsilon: 0.48596032001076567    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1305   score: 5.0   memory length: 260039   epsilon: 0.4853188000107616    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1306   score: 4.0   memory length: 260299   epsilon: 0.48480400001075835    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1307   score: 7.0   memory length: 260709   epsilon: 0.4839922000107532    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1308   score: 5.0   memory length: 261056   epsilon: 0.48330514001074887    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1309   score: 3.0   memory length: 261286   epsilon: 0.482849740010746    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1310   score: 4.0   memory length: 261584   epsilon: 0.48225970001074225    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1311   score: 2.0   memory length: 261784   epsilon: 0.48186370001073975    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1312   score: 3.0   memory length: 262032   epsilon: 0.48137266001073664    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1313   score: 6.0   memory length: 262384   epsilon: 0.48067570001073223    steps: 352    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1314   score: 5.0   memory length: 262698   epsilon: 0.4800539800107283    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1315   score: 2.0   memory length: 262880   epsilon: 0.479693620010726    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1316   score: 5.0   memory length: 263227   epsilon: 0.47900656001072167    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1317   score: 2.0   memory length: 263425   epsilon: 0.4786145200107192    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1318   score: 4.0   memory length: 263701   epsilon: 0.47806804001071573    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1319   score: 5.0   memory length: 264010   epsilon: 0.47745622001071186    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1320   score: 6.0   memory length: 264325   epsilon: 0.4768325200107079    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1321   score: 2.0   memory length: 264541   epsilon: 0.4764048400107052    steps: 216    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1322   score: 2.0   memory length: 264738   epsilon: 0.47601478001070274    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1323   score: 6.0   memory length: 265086   epsilon: 0.4753257400106984    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1324   score: 4.0   memory length: 265363   epsilon: 0.4747772800106949    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1325   score: 6.0   memory length: 265765   epsilon: 0.4739813200106899    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1326   score: 0.0   memory length: 265888   epsilon: 0.47373778001068834    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n",
      "episode: 1327   score: 5.0   memory length: 266190   epsilon: 0.47313982001068455    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1328   score: 3.0   memory length: 266399   epsilon: 0.47272600001068193    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1329   score: 4.0   memory length: 266674   epsilon: 0.4721815000106785    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1330   score: 4.0   memory length: 266934   epsilon: 0.47166670001067523    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1331   score: 3.0   memory length: 267146   epsilon: 0.4712469400106726    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1332   score: 3.0   memory length: 267394   epsilon: 0.47075590001066947    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1333   score: 5.0   memory length: 267682   epsilon: 0.47018566001066586    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1334   score: 4.0   memory length: 267957   epsilon: 0.4696411600106624    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1335   score: 3.0   memory length: 268170   epsilon: 0.46921942001065975    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1336   score: 4.0   memory length: 268446   epsilon: 0.4686729400106563    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1337   score: 4.0   memory length: 268704   epsilon: 0.46816210001065306    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1338   score: 6.0   memory length: 269058   epsilon: 0.4674611800106486    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1339   score: 1.0   memory length: 269209   epsilon: 0.46716220001064673    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1340   score: 1.0   memory length: 269380   epsilon: 0.4668236200106446    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1341   score: 1.0   memory length: 269552   epsilon: 0.46648306001064244    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1342   score: 8.0   memory length: 269988   epsilon: 0.465619780010637    steps: 436    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1343   score: 3.0   memory length: 270201   epsilon: 0.4651980400106343    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1344   score: 4.0   memory length: 270480   epsilon: 0.4646456200106308    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1345   score: 3.0   memory length: 270693   epsilon: 0.46422388001062814    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1346   score: 4.0   memory length: 270949   epsilon: 0.46371700001062494    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1347   score: 5.0   memory length: 271251   epsilon: 0.46311904001062115    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1348   score: 1.0   memory length: 271402   epsilon: 0.46282006001061926    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1349   score: 4.0   memory length: 271661   epsilon: 0.462307240010616    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1350   score: 3.0   memory length: 271923   epsilon: 0.46178848001061273    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1351   score: 2.0   memory length: 272103   epsilon: 0.4614320800106105    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1352   score: 2.0   memory length: 272284   epsilon: 0.4610737000106082    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1353   score: 3.0   memory length: 272517   epsilon: 0.4606123600106053    steps: 233    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1354   score: 9.0   memory length: 273018   epsilon: 0.459620380010599    steps: 501    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1355   score: 3.0   memory length: 273264   epsilon: 0.45913330001059593    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1356   score: 3.0   memory length: 273493   epsilon: 0.45867988001059307    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1357   score: 2.0   memory length: 273673   epsilon: 0.4583234800105908    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1358   score: 5.0   memory length: 273997   epsilon: 0.45768196001058675    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1359   score: 2.0   memory length: 274195   epsilon: 0.45728992001058427    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1360   score: 2.0   memory length: 274395   epsilon: 0.45689392001058177    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1361   score: 5.0   memory length: 274740   epsilon: 0.45621082001057744    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1362   score: 4.0   memory length: 275012   epsilon: 0.45567226001057404    steps: 272    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1363   score: 4.0   memory length: 275307   epsilon: 0.45508816001057034    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1364   score: 3.0   memory length: 275520   epsilon: 0.4546664200105677    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1365   score: 5.0   memory length: 275843   epsilon: 0.4540268800105636    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1366   score: 3.0   memory length: 276056   epsilon: 0.45360514001056096    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1367   score: 2.0   memory length: 276274   epsilon: 0.45317350001055823    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1368   score: 5.0   memory length: 276599   epsilon: 0.45253000001055416    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1369   score: 3.0   memory length: 276846   epsilon: 0.45204094001055106    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1370   score: 3.0   memory length: 277076   epsilon: 0.4515855400105482    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1371   score: 3.0   memory length: 277287   epsilon: 0.45116776001054554    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1372   score: 4.0   memory length: 277530   epsilon: 0.4506866200105425    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1373   score: 2.0   memory length: 277713   epsilon: 0.4503242800105402    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1374   score: 3.0   memory length: 277925   epsilon: 0.44990452001053755    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1375   score: 4.0   memory length: 278201   epsilon: 0.4493580400105341    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1376   score: 5.0   memory length: 278484   epsilon: 0.44879770001053054    steps: 283    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1377   score: 4.0   memory length: 278783   epsilon: 0.4482056800105268    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1378   score: 2.0   memory length: 278980   epsilon: 0.44781562001052433    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1379   score: 2.0   memory length: 279178   epsilon: 0.44742358001052185    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1380   score: 5.0   memory length: 279499   epsilon: 0.4467880000105178    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1381   score: 4.0   memory length: 279741   epsilon: 0.4463088400105148    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1382   score: 6.0   memory length: 280077   epsilon: 0.4456435600105106    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1383   score: 3.0   memory length: 280288   epsilon: 0.44522578001050794    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1384   score: 3.0   memory length: 280520   epsilon: 0.44476642001050504    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1385   score: 3.0   memory length: 280767   epsilon: 0.44427736001050194    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1386   score: 4.0   memory length: 281045   epsilon: 0.44372692001049846    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1387   score: 4.0   memory length: 281291   epsilon: 0.4432398400104954    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1388   score: 3.0   memory length: 281519   epsilon: 0.4427884000104925    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1389   score: 3.0   memory length: 281784   epsilon: 0.4422637000104892    steps: 265    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1390   score: 5.0   memory length: 282108   epsilon: 0.44162218001048514    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1391   score: 3.0   memory length: 282335   epsilon: 0.4411727200104823    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1392   score: 3.0   memory length: 282585   epsilon: 0.44067772001047917    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1393   score: 5.0   memory length: 282911   epsilon: 0.4400322400104751    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1394   score: 4.0   memory length: 283229   epsilon: 0.4394026000104711    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1395   score: 2.0   memory length: 283449   epsilon: 0.43896700001046834    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1396   score: 2.0   memory length: 283631   epsilon: 0.43860664001046606    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1397   score: 5.0   memory length: 283957   epsilon: 0.437961160010462    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1398   score: 2.0   memory length: 284139   epsilon: 0.4376008000104597    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1399   score: 4.0   memory length: 284416   epsilon: 0.43705234001045623    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1400   score: 3.0   memory length: 284646   epsilon: 0.43659694001045335    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1401   score: 3.0   memory length: 284876   epsilon: 0.43614154001045047    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1402   score: 3.0   memory length: 285105   epsilon: 0.4356881200104476    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1403   score: 2.0   memory length: 285305   epsilon: 0.4352921200104451    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1404   score: 4.0   memory length: 285606   epsilon: 0.4346961400104413    steps: 301    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1405   score: 3.0   memory length: 285832   epsilon: 0.4342486600104385    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1406   score: 4.0   memory length: 286114   epsilon: 0.43369030001043496    steps: 282    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1407   score: 8.0   memory length: 286497   epsilon: 0.43293196001043016    steps: 383    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1408   score: 2.0   memory length: 286698   epsilon: 0.43253398001042764    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1409   score: 4.0   memory length: 286993   epsilon: 0.43194988001042395    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1410   score: 5.0   memory length: 287296   epsilon: 0.43134994001042015    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1411   score: 5.0   memory length: 287588   epsilon: 0.4307717800104165    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1412   score: 4.0   memory length: 287863   epsilon: 0.43022728001041305    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1413   score: 3.0   memory length: 288075   epsilon: 0.4298075200104104    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1414   score: 3.0   memory length: 288288   epsilon: 0.4293857800104077    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1415   score: 4.0   memory length: 288584   epsilon: 0.428799700010404    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1416   score: 3.0   memory length: 288811   epsilon: 0.4283502400104012    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1417   score: 5.0   memory length: 289136   epsilon: 0.4277067400103971    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1418   score: 2.0   memory length: 289317   epsilon: 0.42734836001039483    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1419   score: 4.0   memory length: 289595   epsilon: 0.42679792001039135    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1420   score: 4.0   memory length: 289872   epsilon: 0.4262494600103879    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1421   score: 1.0   memory length: 290044   epsilon: 0.4259089000103857    steps: 172    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1422   score: 5.0   memory length: 290357   epsilon: 0.4252891600103818    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1423   score: 3.0   memory length: 290567   epsilon: 0.4248733600103792    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1424   score: 4.0   memory length: 290861   epsilon: 0.4242912400103755    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1425   score: 8.0   memory length: 291337   epsilon: 0.42334876001036953    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1426   score: 3.0   memory length: 291567   epsilon: 0.42289336001036665    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1427   score: 3.0   memory length: 291814   epsilon: 0.42240430001036355    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1428   score: 4.0   memory length: 292089   epsilon: 0.4218598000103601    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1429   score: 3.0   memory length: 292300   epsilon: 0.42144202001035747    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1430   score: 4.0   memory length: 292602   epsilon: 0.4208440600103537    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1431   score: 5.0   memory length: 292909   epsilon: 0.42023620001034984    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1432   score: 6.0   memory length: 293271   epsilon: 0.4195194400103453    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1433   score: 3.0   memory length: 293501   epsilon: 0.4190640400103424    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1434   score: 2.0   memory length: 293722   epsilon: 0.41862646001033965    steps: 221    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1435   score: 4.0   memory length: 293982   epsilon: 0.4181116600103364    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1436   score: 4.0   memory length: 294259   epsilon: 0.4175632000103329    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.6\n",
      "episode: 1437   score: 5.0   memory length: 294564   epsilon: 0.4169593000103291    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1438   score: 3.0   memory length: 294776   epsilon: 0.41653954001032645    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1439   score: 4.0   memory length: 295031   epsilon: 0.41603464001032325    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1440   score: 3.0   memory length: 295277   epsilon: 0.41554756001032017    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1441   score: 4.0   memory length: 295570   epsilon: 0.4149674200103165    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1442   score: 5.0   memory length: 295909   epsilon: 0.41429620001031225    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1443   score: 4.0   memory length: 296206   epsilon: 0.41370814001030853    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1444   score: 3.0   memory length: 296419   epsilon: 0.41328640001030587    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1445   score: 6.0   memory length: 296758   epsilon: 0.4126151800103016    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1446   score: 6.0   memory length: 297122   epsilon: 0.41189446001029706    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1447   score: 3.0   memory length: 297348   epsilon: 0.4114469800102942    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1448   score: 3.0   memory length: 297596   epsilon: 0.4109559400102911    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1449   score: 6.0   memory length: 297953   epsilon: 0.41024908001028665    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1450   score: 3.0   memory length: 298166   epsilon: 0.409827340010284    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1451   score: 5.0   memory length: 298475   epsilon: 0.4092155200102801    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1452   score: 2.0   memory length: 298672   epsilon: 0.40882546001027764    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1453   score: 3.0   memory length: 298920   epsilon: 0.40833442001027453    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1454   score: 4.0   memory length: 299216   epsilon: 0.4077483400102708    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1455   score: 4.0   memory length: 299494   epsilon: 0.40719790001026734    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1456   score: 2.0   memory length: 299676   epsilon: 0.40683754001026506    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1457   score: 8.0   memory length: 300133   epsilon: 0.40593268001025934    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1458   score: 4.0   memory length: 300395   epsilon: 0.40541392001025606    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 3.73\n",
      "episode: 1459   score: 4.0   memory length: 300669   epsilon: 0.4048714000102526    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 3.75\n",
      "episode: 1460   score: 3.0   memory length: 300880   epsilon: 0.40445362001025    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 3.76\n",
      "episode: 1461   score: 3.0   memory length: 301108   epsilon: 0.4040021800102471    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1462   score: 4.0   memory length: 301367   epsilon: 0.4034893600102439    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1463   score: 4.0   memory length: 301664   epsilon: 0.40290130001024016    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1464   score: 4.0   memory length: 301926   epsilon: 0.4023825400102369    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 3.75\n",
      "episode: 1465   score: 2.0   memory length: 302108   epsilon: 0.4020221800102346    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 3.72\n",
      "episode: 1466   score: 4.0   memory length: 302348   epsilon: 0.4015469800102316    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 3.73\n",
      "episode: 1467   score: 4.0   memory length: 302623   epsilon: 0.40100248001022815    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 3.75\n",
      "episode: 1468   score: 4.0   memory length: 302939   epsilon: 0.4003768000102242    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1469   score: 3.0   memory length: 303188   epsilon: 0.39988378001022107    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 3.74\n",
      "episode: 1470   score: 5.0   memory length: 303495   epsilon: 0.3992759200102172    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 3.76\n",
      "episode: 1471   score: 4.0   memory length: 303792   epsilon: 0.3986878600102135    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 3.77\n",
      "episode: 1472   score: 3.0   memory length: 304038   epsilon: 0.3982007800102104    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 3.76\n",
      "episode: 1473   score: 3.0   memory length: 304267   epsilon: 0.39774736001020755    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 3.77\n",
      "episode: 1474   score: 4.0   memory length: 304526   epsilon: 0.3972345400102043    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 3.78\n",
      "episode: 1475   score: 4.0   memory length: 304802   epsilon: 0.39668806001020085    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 3.78\n",
      "episode: 1476   score: 5.0   memory length: 305129   epsilon: 0.39604060001019675    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 3.78\n",
      "episode: 1477   score: 3.0   memory length: 305342   epsilon: 0.3956188600101941    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 3.77\n",
      "episode: 1478   score: 4.0   memory length: 305618   epsilon: 0.3950723800101906    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 3.79\n",
      "episode: 1479   score: 5.0   memory length: 305908   epsilon: 0.394498180010187    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 3.82\n",
      "episode: 1480   score: 4.0   memory length: 306186   epsilon: 0.3939477400101835    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 3.81\n",
      "episode: 1481   score: 7.0   memory length: 306591   epsilon: 0.39314584001017844    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 3.84\n",
      "episode: 1482   score: 9.0   memory length: 306914   epsilon: 0.3925063000101744    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 3.87\n",
      "episode: 1483   score: 4.0   memory length: 307192   epsilon: 0.3919558600101709    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 3.88\n",
      "episode: 1484   score: 4.0   memory length: 307469   epsilon: 0.39140740001016744    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 3.89\n",
      "episode: 1485   score: 4.0   memory length: 307711   epsilon: 0.3909282400101644    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 3.9\n",
      "episode: 1486   score: 4.0   memory length: 308008   epsilon: 0.3903401800101607    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 3.9\n",
      "episode: 1487   score: 3.0   memory length: 308221   epsilon: 0.389918440010158    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 3.89\n",
      "episode: 1488   score: 3.0   memory length: 308450   epsilon: 0.38946502001015515    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 3.89\n",
      "episode: 1489   score: 3.0   memory length: 308660   epsilon: 0.3890492200101525    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 3.89\n",
      "episode: 1490   score: 2.0   memory length: 308841   epsilon: 0.38869084001015025    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 3.86\n",
      "episode: 1491   score: 5.0   memory length: 309166   epsilon: 0.3880473400101462    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 3.88\n",
      "episode: 1492   score: 3.0   memory length: 309392   epsilon: 0.38759986001014335    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 3.88\n",
      "episode: 1493   score: 2.0   memory length: 309574   epsilon: 0.38723950001014107    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 3.85\n",
      "episode: 1494   score: 5.0   memory length: 309918   epsilon: 0.38655838001013676    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 3.86\n",
      "episode: 1495   score: 4.0   memory length: 310194   epsilon: 0.3860119000101333    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 3.88\n",
      "episode: 1496   score: 6.0   memory length: 310575   epsilon: 0.38525752001012853    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 3.92\n",
      "episode: 1497   score: 4.0   memory length: 310817   epsilon: 0.3847783600101255    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 3.91\n",
      "episode: 1498   score: 4.0   memory length: 311076   epsilon: 0.38426554001012225    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1499   score: 4.0   memory length: 311353   epsilon: 0.3837170800101188    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1500   score: 5.0   memory length: 311661   epsilon: 0.3831072400101149    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1501   score: 3.0   memory length: 311910   epsilon: 0.3826142200101118    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1502   score: 3.0   memory length: 312121   epsilon: 0.38219644001010916    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1503   score: 4.0   memory length: 312363   epsilon: 0.38171728001010613    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1504   score: 5.0   memory length: 312666   epsilon: 0.38111734001010233    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 3.98\n",
      "episode: 1505   score: 4.0   memory length: 312943   epsilon: 0.38056888001009886    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 3.99\n",
      "episode: 1506   score: 5.0   memory length: 313269   epsilon: 0.3799234000100948    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.0\n",
      "episode: 1507   score: 6.0   memory length: 313605   epsilon: 0.37925812001009057    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 3.98\n",
      "episode: 1508   score: 5.0   memory length: 313931   epsilon: 0.3786126400100865    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.01\n",
      "episode: 1509   score: 3.0   memory length: 314159   epsilon: 0.37816120001008363    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.0\n",
      "episode: 1510   score: 3.0   memory length: 314388   epsilon: 0.37770778001008076    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 3.98\n",
      "episode: 1511   score: 3.0   memory length: 314604   epsilon: 0.37728010001007806    steps: 216    lr: 6.400000000000001e-06     evaluation reward: 3.96\n",
      "episode: 1512   score: 3.0   memory length: 314817   epsilon: 0.3768583600100754    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1513   score: 5.0   memory length: 315122   epsilon: 0.37625446001007157    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1514   score: 3.0   memory length: 315348   epsilon: 0.37580698001006874    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1515   score: 4.0   memory length: 315645   epsilon: 0.375218920010065    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1516   score: 4.0   memory length: 315907   epsilon: 0.37470016001006173    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 3.98\n",
      "episode: 1517   score: 3.0   memory length: 316156   epsilon: 0.3742071400100586    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 3.96\n",
      "episode: 1518   score: 3.0   memory length: 316383   epsilon: 0.37375768001005577    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1519   score: 2.0   memory length: 316583   epsilon: 0.37336168001005327    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1520   score: 3.0   memory length: 316812   epsilon: 0.3729082600100504    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 3.94\n",
      "episode: 1521   score: 3.0   memory length: 317038   epsilon: 0.37246078001004757    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 3.96\n",
      "episode: 1522   score: 3.0   memory length: 317268   epsilon: 0.3720053800100447    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 3.94\n",
      "episode: 1523   score: 4.0   memory length: 317527   epsilon: 0.37149256001004144    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1524   score: 4.0   memory length: 317785   epsilon: 0.3709817200100382    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1525   score: 4.0   memory length: 318062   epsilon: 0.37043326001003474    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 3.91\n",
      "episode: 1526   score: 3.0   memory length: 318271   epsilon: 0.3700194400100321    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 3.91\n",
      "episode: 1527   score: 4.0   memory length: 318549   epsilon: 0.36946900001002864    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 3.92\n",
      "episode: 1528   score: 5.0   memory length: 318858   epsilon: 0.36885718001002477    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1529   score: 3.0   memory length: 319068   epsilon: 0.36844138001002213    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1530   score: 5.0   memory length: 319396   epsilon: 0.367791940010018    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 3.94\n",
      "episode: 1531   score: 3.0   memory length: 319642   epsilon: 0.36730486001001494    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 3.92\n",
      "episode: 1532   score: 5.0   memory length: 319933   epsilon: 0.3667286800100113    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 3.91\n",
      "episode: 1533   score: 5.0   memory length: 320224   epsilon: 0.36615250001000765    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1534   score: 4.0   memory length: 320521   epsilon: 0.36556444001000393    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1535   score: 4.0   memory length: 320763   epsilon: 0.3650852800100009    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1536   score: 4.0   memory length: 321041   epsilon: 0.3645348400099974    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 3.95\n",
      "episode: 1537   score: 3.0   memory length: 321270   epsilon: 0.36408142000999455    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1538   score: 3.0   memory length: 321486   epsilon: 0.36365374000999184    steps: 216    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1539   score: 4.0   memory length: 321765   epsilon: 0.36310132000998835    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 3.93\n",
      "episode: 1540   score: 6.0   memory length: 322118   epsilon: 0.3624023800099839    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 3.96\n",
      "episode: 1541   score: 7.0   memory length: 322523   epsilon: 0.36160048000997885    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 3.99\n",
      "episode: 1542   score: 5.0   memory length: 322827   epsilon: 0.36099856000997504    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 3.99\n",
      "episode: 1543   score: 4.0   memory length: 323103   epsilon: 0.3604520800099716    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 3.99\n",
      "episode: 1544   score: 4.0   memory length: 323397   epsilon: 0.3598699600099679    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 4.0\n",
      "episode: 1545   score: 3.0   memory length: 323627   epsilon: 0.359414560009965    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 3.97\n",
      "episode: 1546   score: 5.0   memory length: 323953   epsilon: 0.35876908000996094    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 3.96\n",
      "episode: 1547   score: 7.0   memory length: 324357   epsilon: 0.3579691600099559    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 4.0\n",
      "episode: 1548   score: 5.0   memory length: 324648   epsilon: 0.35739298000995223    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 4.02\n",
      "episode: 1549   score: 6.0   memory length: 325011   epsilon: 0.3566742400099477    steps: 363    lr: 6.400000000000001e-06     evaluation reward: 4.02\n",
      "episode: 1550   score: 10.0   memory length: 325417   epsilon: 0.3558703600099426    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 4.09\n",
      "episode: 1551   score: 4.0   memory length: 325675   epsilon: 0.35535952000993937    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.08\n",
      "episode: 1552   score: 5.0   memory length: 325978   epsilon: 0.35475958000993557    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 4.11\n",
      "episode: 1553   score: 2.0   memory length: 326178   epsilon: 0.35436358000993307    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.1\n",
      "episode: 1554   score: 2.0   memory length: 326394   epsilon: 0.35393590000993036    steps: 216    lr: 6.400000000000001e-06     evaluation reward: 4.08\n",
      "episode: 1555   score: 6.0   memory length: 326765   epsilon: 0.3532013200099257    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 4.1\n",
      "episode: 1556   score: 7.0   memory length: 327206   epsilon: 0.3523281400099202    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 4.15\n",
      "episode: 1557   score: 2.0   memory length: 327388   epsilon: 0.3519677800099179    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.09\n",
      "episode: 1558   score: 5.0   memory length: 327696   epsilon: 0.35135794000991405    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.1\n",
      "episode: 1559   score: 5.0   memory length: 328016   epsilon: 0.35072434000991004    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.11\n",
      "episode: 1560   score: 2.0   memory length: 328198   epsilon: 0.35036398000990776    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.1\n",
      "episode: 1561   score: 7.0   memory length: 328587   epsilon: 0.3495937600099029    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 4.14\n",
      "episode: 1562   score: 7.0   memory length: 329009   epsilon: 0.3487582000098976    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 4.17\n",
      "episode: 1563   score: 6.0   memory length: 329340   epsilon: 0.34810282000989345    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 4.19\n",
      "episode: 1564   score: 4.0   memory length: 329636   epsilon: 0.34751674000988975    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.19\n",
      "episode: 1565   score: 4.0   memory length: 329908   epsilon: 0.34697818000988634    steps: 272    lr: 6.400000000000001e-06     evaluation reward: 4.21\n",
      "episode: 1566   score: 4.0   memory length: 330186   epsilon: 0.34642774000988286    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.21\n",
      "episode: 1567   score: 3.0   memory length: 330434   epsilon: 0.34593670000987975    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.2\n",
      "episode: 1568   score: 4.0   memory length: 330710   epsilon: 0.3453902200098763    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.2\n",
      "episode: 1569   score: 5.0   memory length: 330994   epsilon: 0.34482790000987273    steps: 284    lr: 6.400000000000001e-06     evaluation reward: 4.22\n",
      "episode: 1570   score: 4.0   memory length: 331236   epsilon: 0.3443487400098697    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.21\n",
      "episode: 1571   score: 4.0   memory length: 331512   epsilon: 0.34380226000986625    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.21\n",
      "episode: 1572   score: 4.0   memory length: 331809   epsilon: 0.3432142000098625    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.22\n",
      "episode: 1573   score: 5.0   memory length: 332098   epsilon: 0.3426419800098589    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.24\n",
      "episode: 1574   score: 5.0   memory length: 332396   epsilon: 0.34205194000985517    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.25\n",
      "episode: 1575   score: 3.0   memory length: 332627   epsilon: 0.3415945600098523    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.24\n",
      "episode: 1576   score: 6.0   memory length: 332940   epsilon: 0.34097482000984836    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 4.25\n",
      "episode: 1577   score: 4.0   memory length: 333182   epsilon: 0.3404956600098453    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.26\n",
      "episode: 1578   score: 4.0   memory length: 333442   epsilon: 0.33998086000984207    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.26\n",
      "episode: 1579   score: 4.0   memory length: 333681   epsilon: 0.3395076400098391    steps: 239    lr: 6.400000000000001e-06     evaluation reward: 4.25\n",
      "episode: 1580   score: 6.0   memory length: 334036   epsilon: 0.3388047400098346    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.27\n",
      "episode: 1581   score: 4.0   memory length: 334279   epsilon: 0.3383236000098316    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 4.24\n",
      "episode: 1582   score: 5.0   memory length: 334571   epsilon: 0.3377454400098279    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 4.2\n",
      "episode: 1583   score: 6.0   memory length: 334946   epsilon: 0.3370029400098232    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.22\n",
      "episode: 1584   score: 5.0   memory length: 335229   epsilon: 0.3364426000098197    steps: 283    lr: 6.400000000000001e-06     evaluation reward: 4.23\n",
      "episode: 1585   score: 4.0   memory length: 335492   epsilon: 0.3359218600098164    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.23\n",
      "episode: 1586   score: 5.0   memory length: 335817   epsilon: 0.3352783600098123    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.24\n",
      "episode: 1587   score: 2.0   memory length: 335997   epsilon: 0.33492196000981006    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 4.23\n",
      "episode: 1588   score: 3.0   memory length: 336247   epsilon: 0.33442696000980693    steps: 250    lr: 6.400000000000001e-06     evaluation reward: 4.23\n",
      "episode: 1589   score: 5.0   memory length: 336554   epsilon: 0.3338191000098031    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.25\n",
      "episode: 1590   score: 7.0   memory length: 336956   epsilon: 0.33302314000979805    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1591   score: 4.0   memory length: 337198   epsilon: 0.332543980009795    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.29\n",
      "episode: 1592   score: 4.0   memory length: 337494   epsilon: 0.3319579000097913    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1593   score: 4.0   memory length: 337756   epsilon: 0.331439140009788    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1594   score: 4.0   memory length: 338016   epsilon: 0.33092434000978477    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.31\n",
      "episode: 1595   score: 3.0   memory length: 338246   epsilon: 0.3304689400097819    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1596   score: 6.0   memory length: 338621   epsilon: 0.3297264400097772    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1597   score: 4.0   memory length: 338865   epsilon: 0.32924332000977413    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1598   score: 3.0   memory length: 339078   epsilon: 0.32882158000977146    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.29\n",
      "episode: 1599   score: 4.0   memory length: 339340   epsilon: 0.3283028200097682    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.29\n",
      "episode: 1600   score: 6.0   memory length: 339695   epsilon: 0.32759992000976373    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1601   score: 9.0   memory length: 340145   epsilon: 0.3267089200097581    steps: 450    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1602   score: 4.0   memory length: 340387   epsilon: 0.32622976000975507    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1603   score: 6.0   memory length: 340744   epsilon: 0.3255229000097506    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1604   score: 5.0   memory length: 341053   epsilon: 0.3249110800097467    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1605   score: 6.0   memory length: 341446   epsilon: 0.3241329400097418    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1606   score: 3.0   memory length: 341691   epsilon: 0.32364784000973873    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1607   score: 2.0   memory length: 341891   epsilon: 0.3232518400097362    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.35\n",
      "episode: 1608   score: 4.0   memory length: 342150   epsilon: 0.322739020009733    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.34\n",
      "episode: 1609   score: 5.0   memory length: 342437   epsilon: 0.3221707600097294    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1610   score: 4.0   memory length: 342679   epsilon: 0.32169160000972635    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1611   score: 4.0   memory length: 342957   epsilon: 0.32114116000972287    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1612   score: 4.0   memory length: 343238   epsilon: 0.32058478000971935    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1613   score: 6.0   memory length: 343618   epsilon: 0.3198323800097146    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1614   score: 2.0   memory length: 343836   epsilon: 0.31940074000971186    steps: 218    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1615   score: 4.0   memory length: 344099   epsilon: 0.31888000000970856    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1616   score: 4.0   memory length: 344341   epsilon: 0.31840084000970553    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1617   score: 5.0   memory length: 344668   epsilon: 0.31775338000970144    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1618   score: 3.0   memory length: 344897   epsilon: 0.31729996000969857    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1619   score: 4.0   memory length: 345156   epsilon: 0.3167871400096953    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1620   score: 7.0   memory length: 345541   epsilon: 0.3160248400096905    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1621   score: 4.0   memory length: 345817   epsilon: 0.31547836000968704    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.48\n",
      "episode: 1622   score: 6.0   memory length: 346193   epsilon: 0.31473388000968233    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1623   score: 4.0   memory length: 346450   epsilon: 0.3142250200096791    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1624   score: 3.0   memory length: 346700   epsilon: 0.313730020009676    steps: 250    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1625   score: 3.0   memory length: 346913   epsilon: 0.3133082800096733    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1626   score: 6.0   memory length: 347249   epsilon: 0.3126430000096691    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1627   score: 2.0   memory length: 347431   epsilon: 0.3122826400096668    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1628   score: 4.0   memory length: 347708   epsilon: 0.31173418000966335    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1629   score: 4.0   memory length: 347968   epsilon: 0.3112193800096601    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1630   score: 3.0   memory length: 348198   epsilon: 0.3107639800096572    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.48\n",
      "episode: 1631   score: 3.0   memory length: 348445   epsilon: 0.3102749200096541    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 4.48\n",
      "episode: 1632   score: 8.0   memory length: 348899   epsilon: 0.30937600000964843    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1633   score: 4.0   memory length: 349195   epsilon: 0.3087899200096447    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1634   score: 5.0   memory length: 349500   epsilon: 0.3081860200096409    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1635   score: 8.0   memory length: 349917   epsilon: 0.3073603600096357    steps: 417    lr: 6.400000000000001e-06     evaluation reward: 4.55\n",
      "episode: 1636   score: 6.0   memory length: 350292   epsilon: 0.306617860009631    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1637   score: 4.0   memory length: 350589   epsilon: 0.30602980000962726    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1638   score: 3.0   memory length: 350817   epsilon: 0.3055783600096244    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1639   score: 4.0   memory length: 351076   epsilon: 0.30506554000962116    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1640   score: 3.0   memory length: 351289   epsilon: 0.3046438000096185    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.55\n",
      "episode: 1641   score: 4.0   memory length: 351550   epsilon: 0.3041270200096152    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1642   score: 4.0   memory length: 351809   epsilon: 0.303614200009612    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1643   score: 3.0   memory length: 352058   epsilon: 0.30312118000960886    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1644   score: 4.0   memory length: 352355   epsilon: 0.30253312000960514    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1645   score: 3.0   memory length: 352585   epsilon: 0.30207772000960226    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1646   score: 5.0   memory length: 352895   epsilon: 0.3014639200095984    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.5\n",
      "episode: 1647   score: 4.0   memory length: 353154   epsilon: 0.30095110000959513    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1648   score: 5.0   memory length: 353464   epsilon: 0.30033730000959125    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1649   score: 6.0   memory length: 353822   epsilon: 0.29962846000958676    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1650   score: 3.0   memory length: 354052   epsilon: 0.2991730600095839    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1651   score: 6.0   memory length: 354395   epsilon: 0.2984939200095796    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1652   score: 4.0   memory length: 354657   epsilon: 0.2979751600095763    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1653   score: 4.0   memory length: 354916   epsilon: 0.29746234000957306    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1654   score: 5.0   memory length: 355260   epsilon: 0.29678122000956875    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1655   score: 3.0   memory length: 355492   epsilon: 0.29632186000956584    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1656   score: 4.0   memory length: 355745   epsilon: 0.29582092000956267    steps: 253    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1657   score: 6.0   memory length: 356085   epsilon: 0.2951477200095584    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1658   score: 5.0   memory length: 356395   epsilon: 0.29453392000955453    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1659   score: 8.0   memory length: 356831   epsilon: 0.29367064000954907    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1660   score: 3.0   memory length: 357059   epsilon: 0.2932192000095462    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.48\n",
      "episode: 1661   score: 5.0   memory length: 357348   epsilon: 0.2926469800095426    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1662   score: 6.0   memory length: 357690   epsilon: 0.2919698200095383    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 4.45\n",
      "episode: 1663   score: 8.0   memory length: 358120   epsilon: 0.2911184200095329    steps: 430    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1664   score: 6.0   memory length: 358493   epsilon: 0.29037988000952825    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1665   score: 4.0   memory length: 358737   epsilon: 0.2898967600095252    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1666   score: 4.0   memory length: 359013   epsilon: 0.28935028000952173    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1667   score: 5.0   memory length: 359309   epsilon: 0.288764200009518    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1668   score: 2.0   memory length: 359525   epsilon: 0.2883365200095153    steps: 216    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1669   score: 4.0   memory length: 359780   epsilon: 0.2878316200095121    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 4.48\n",
      "episode: 1670   score: 3.0   memory length: 359990   epsilon: 0.2874158200095095    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.47\n",
      "episode: 1671   score: 3.0   memory length: 360220   epsilon: 0.2869604200095066    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1672   score: 7.0   memory length: 360556   epsilon: 0.2862951400095024    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1673   score: 5.0   memory length: 360848   epsilon: 0.28571698000949874    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 4.49\n",
      "episode: 1674   score: 2.0   memory length: 361029   epsilon: 0.2853586000094965    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1675   score: 3.0   memory length: 361242   epsilon: 0.2849368600094938    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1676   score: 3.0   memory length: 361469   epsilon: 0.28448740000949096    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1677   score: 3.0   memory length: 361682   epsilon: 0.2840656600094883    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1678   score: 6.0   memory length: 362017   epsilon: 0.2834023600094841    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1679   score: 4.0   memory length: 362293   epsilon: 0.28285588000948064    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1680   score: 3.0   memory length: 362503   epsilon: 0.282440080009478    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1681   score: 6.0   memory length: 362881   epsilon: 0.2816916400094733    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1682   score: 3.0   memory length: 363112   epsilon: 0.2812342600094704    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1683   score: 5.0   memory length: 363437   epsilon: 0.2805907600094663    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1684   score: 3.0   memory length: 363650   epsilon: 0.28016902000946364    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1685   score: 2.0   memory length: 363850   epsilon: 0.27977302000946114    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1686   score: 3.0   memory length: 364080   epsilon: 0.27931762000945826    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.34\n",
      "episode: 1687   score: 5.0   memory length: 364421   epsilon: 0.278642440009454    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1688   score: 3.0   memory length: 364651   epsilon: 0.2781870400094511    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1689   score: 3.0   memory length: 364899   epsilon: 0.277696000009448    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.35\n",
      "episode: 1690   score: 4.0   memory length: 365154   epsilon: 0.2771911000094448    steps: 255    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1691   score: 6.0   memory length: 365530   epsilon: 0.2764466200094401    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 4.34\n",
      "episode: 1692   score: 6.0   memory length: 365887   epsilon: 0.2757397600094356    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1693   score: 4.0   memory length: 366184   epsilon: 0.2751517000094319    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1694   score: 8.0   memory length: 366644   epsilon: 0.27424090000942614    steps: 460    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1695   score: 4.0   memory length: 366886   epsilon: 0.2737617400094231    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1696   score: 5.0   memory length: 367194   epsilon: 0.27315190000941925    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1697   score: 4.0   memory length: 367458   epsilon: 0.27262918000941594    steps: 264    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1698   score: 5.0   memory length: 367761   epsilon: 0.27202924000941214    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1699   score: 6.0   memory length: 368118   epsilon: 0.27132238000940767    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1700   score: 4.0   memory length: 368378   epsilon: 0.2708075800094044    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1701   score: 3.0   memory length: 368608   epsilon: 0.27035218000940153    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1702   score: 4.0   memory length: 368867   epsilon: 0.2698393600093983    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1703   score: 5.0   memory length: 369193   epsilon: 0.2691938800093942    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.35\n",
      "episode: 1704   score: 5.0   memory length: 369540   epsilon: 0.26850682000938986    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 4.35\n",
      "episode: 1705   score: 3.0   memory length: 369766   epsilon: 0.268059340009387    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1706   score: 3.0   memory length: 370015   epsilon: 0.2675663200093839    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1707   score: 3.0   memory length: 370263   epsilon: 0.2670752800093808    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.33\n",
      "episode: 1708   score: 3.0   memory length: 370508   epsilon: 0.26659018000937773    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1709   score: 3.0   memory length: 370737   epsilon: 0.26613676000937486    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1710   score: 5.0   memory length: 371084   epsilon: 0.2654497000093705    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 4.31\n",
      "episode: 1711   score: 3.0   memory length: 371313   epsilon: 0.26499628000936765    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.3\n",
      "episode: 1712   score: 5.0   memory length: 371609   epsilon: 0.26441020000936394    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.31\n",
      "episode: 1713   score: 3.0   memory length: 371857   epsilon: 0.26391916000936083    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.28\n",
      "episode: 1714   score: 6.0   memory length: 372198   epsilon: 0.26324398000935656    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 4.32\n",
      "episode: 1715   score: 7.0   memory length: 372642   epsilon: 0.262364860009351    steps: 444    lr: 6.400000000000001e-06     evaluation reward: 4.35\n",
      "episode: 1716   score: 5.0   memory length: 372992   epsilon: 0.2616718600093466    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1717   score: 3.0   memory length: 373223   epsilon: 0.2612144800093437    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.34\n",
      "episode: 1718   score: 6.0   memory length: 373618   epsilon: 0.26043238000933877    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1719   score: 5.0   memory length: 373912   epsilon: 0.2598502600093351    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1720   score: 9.0   memory length: 374239   epsilon: 0.259202800009331    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1721   score: 4.0   memory length: 374498   epsilon: 0.25868998000932775    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.4\n",
      "episode: 1722   score: 3.0   memory length: 374725   epsilon: 0.2582405200093249    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1723   score: 5.0   memory length: 375035   epsilon: 0.257626720009321    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1724   score: 3.0   memory length: 375286   epsilon: 0.2571297400093179    steps: 251    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1725   score: 3.0   memory length: 375499   epsilon: 0.2567080000093152    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1726   score: 4.0   memory length: 375794   epsilon: 0.2561239000093115    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.36\n",
      "episode: 1727   score: 3.0   memory length: 376022   epsilon: 0.25567246000930866    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.37\n",
      "episode: 1728   score: 5.0   memory length: 376350   epsilon: 0.25502302000930455    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 4.38\n",
      "episode: 1729   score: 5.0   memory length: 376678   epsilon: 0.25437358000930044    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1730   score: 5.0   memory length: 377005   epsilon: 0.25372612000929634    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1731   score: 6.0   memory length: 377345   epsilon: 0.2530529200092921    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1732   score: 3.0   memory length: 377574   epsilon: 0.2525995000092892    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.39\n",
      "episode: 1733   score: 7.0   memory length: 377980   epsilon: 0.2517956200092841    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1734   score: 9.0   memory length: 378308   epsilon: 0.25114618000928    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 4.46\n",
      "episode: 1735   score: 4.0   memory length: 378569   epsilon: 0.25062940000927675    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1736   score: 5.0   memory length: 378877   epsilon: 0.2500195600092729    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1737   score: 4.0   memory length: 379136   epsilon: 0.24950674000926965    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.41\n",
      "episode: 1738   score: 5.0   memory length: 379441   epsilon: 0.24890284000926582    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 4.43\n",
      "episode: 1739   score: 3.0   memory length: 379670   epsilon: 0.24844942000926296    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.42\n",
      "episode: 1740   score: 5.0   memory length: 379961   epsilon: 0.2478732400092593    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1741   score: 4.0   memory length: 380203   epsilon: 0.24739408000925628    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 4.44\n",
      "episode: 1742   score: 5.0   memory length: 380529   epsilon: 0.2467486000092522    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.45\n",
      "episode: 1743   score: 9.0   memory length: 381015   epsilon: 0.2457863200092461    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 4.51\n",
      "episode: 1744   score: 7.0   memory length: 381401   epsilon: 0.24502204000924127    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1745   score: 2.0   memory length: 381582   epsilon: 0.244663660009239    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 4.53\n",
      "episode: 1746   score: 5.0   memory length: 381889   epsilon: 0.24405580000923516    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.53\n",
      "episode: 1747   score: 3.0   memory length: 382120   epsilon: 0.24359842000923226    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1748   score: 10.0   memory length: 382499   epsilon: 0.24284800000922752    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1749   score: 3.0   memory length: 382745   epsilon: 0.24236092000922443    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1750   score: 4.0   memory length: 383020   epsilon: 0.241816420009221    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.55\n",
      "episode: 1751   score: 6.0   memory length: 383417   epsilon: 0.24103036000921602    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 4.55\n",
      "episode: 1752   score: 3.0   memory length: 383630   epsilon: 0.24060862000921335    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1753   score: 6.0   memory length: 383989   epsilon: 0.23989780000920885    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 4.56\n",
      "episode: 1754   score: 6.0   memory length: 384361   epsilon: 0.2391612400092042    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1755   score: 4.0   memory length: 384657   epsilon: 0.23857516000920048    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1756   score: 4.0   memory length: 384932   epsilon: 0.23803066000919704    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1757   score: 4.0   memory length: 385195   epsilon: 0.23750992000919374    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 4.56\n",
      "episode: 1758   score: 5.0   memory length: 385481   epsilon: 0.23694364000919016    steps: 286    lr: 6.400000000000001e-06     evaluation reward: 4.56\n",
      "episode: 1759   score: 4.0   memory length: 385741   epsilon: 0.2364288400091869    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1760   score: 7.0   memory length: 386164   epsilon: 0.2355913000091816    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 4.56\n",
      "episode: 1761   score: 6.0   memory length: 386537   epsilon: 0.23485276000917693    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1762   score: 6.0   memory length: 386910   epsilon: 0.23411422000917226    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1763   score: 3.0   memory length: 387140   epsilon: 0.23365882000916938    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1764   score: 6.0   memory length: 387479   epsilon: 0.23298760000916513    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1765   score: 4.0   memory length: 387776   epsilon: 0.2323995400091614    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1766   score: 5.0   memory length: 388046   epsilon: 0.23186494000915803    steps: 270    lr: 6.400000000000001e-06     evaluation reward: 4.53\n",
      "episode: 1767   score: 4.0   memory length: 388344   epsilon: 0.2312749000091543    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.52\n",
      "episode: 1768   score: 4.0   memory length: 388643   epsilon: 0.23068288000915055    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1769   score: 4.0   memory length: 388888   epsilon: 0.23019778000914748    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 4.54\n",
      "episode: 1770   score: 4.0   memory length: 389146   epsilon: 0.22968694000914425    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.55\n",
      "episode: 1771   score: 7.0   memory length: 389547   epsilon: 0.22889296000913922    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 4.59\n",
      "episode: 1772   score: 4.0   memory length: 389845   epsilon: 0.2283029200091355    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.56\n",
      "episode: 1773   score: 6.0   memory length: 390202   epsilon: 0.22759606000913102    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 4.57\n",
      "episode: 1774   score: 3.0   memory length: 390412   epsilon: 0.2271802600091284    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.58\n",
      "episode: 1775   score: 5.0   memory length: 390743   epsilon: 0.22652488000912424    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 4.6\n",
      "episode: 1776   score: 4.0   memory length: 391020   epsilon: 0.22597642000912077    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.61\n",
      "episode: 1777   score: 3.0   memory length: 391233   epsilon: 0.2255546800091181    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 4.61\n",
      "episode: 1778   score: 4.0   memory length: 391492   epsilon: 0.22504186000911486    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.59\n",
      "episode: 1779   score: 5.0   memory length: 391821   epsilon: 0.22439044000911074    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 4.6\n",
      "episode: 1780   score: 7.0   memory length: 392190   epsilon: 0.22365982000910611    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1781   score: 5.0   memory length: 392497   epsilon: 0.22305196000910227    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.63\n",
      "episode: 1782   score: 4.0   memory length: 392756   epsilon: 0.22253914000909902    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1783   score: 5.0   memory length: 393065   epsilon: 0.22192732000909515    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1784   score: 3.0   memory length: 393295   epsilon: 0.22147192000909227    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1785   score: 3.0   memory length: 393543   epsilon: 0.22098088000908916    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1786   score: 4.0   memory length: 393818   epsilon: 0.22043638000908572    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 4.66\n",
      "episode: 1787   score: 3.0   memory length: 394028   epsilon: 0.2200205800090831    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1788   score: 4.0   memory length: 394331   epsilon: 0.2194206400090793    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1789   score: 5.0   memory length: 394640   epsilon: 0.21880882000907542    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.67\n",
      "episode: 1790   score: 4.0   memory length: 394902   epsilon: 0.21829006000907214    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.67\n",
      "episode: 1791   score: 4.0   memory length: 395181   epsilon: 0.21773764000906864    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1792   score: 6.0   memory length: 395519   epsilon: 0.2170684000090644    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1793   score: 5.0   memory length: 395817   epsilon: 0.21647836000906068    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.66\n",
      "episode: 1794   score: 6.0   memory length: 396149   epsilon: 0.21582100000905652    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1795   score: 4.0   memory length: 396407   epsilon: 0.2153101600090533    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1796   score: 4.0   memory length: 396704   epsilon: 0.21472210000904957    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.63\n",
      "episode: 1797   score: 5.0   memory length: 397010   epsilon: 0.21411622000904573    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1798   score: 7.0   memory length: 397395   epsilon: 0.2133539200090409    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 4.66\n",
      "episode: 1799   score: 4.0   memory length: 397672   epsilon: 0.21280546000903744    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1800   score: 3.0   memory length: 397901   epsilon: 0.21235204000903457    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.63\n",
      "episode: 1801   score: 5.0   memory length: 398191   epsilon: 0.21177784000903094    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1802   score: 3.0   memory length: 398418   epsilon: 0.2113283800090281    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.64\n",
      "episode: 1803   score: 6.0   memory length: 398773   epsilon: 0.21062548000902365    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.65\n",
      "episode: 1804   score: 13.0   memory length: 399293   epsilon: 0.20959588000901713    steps: 520    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1805   score: 2.0   memory length: 399475   epsilon: 0.20923552000901485    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1806   score: 4.0   memory length: 399751   epsilon: 0.2086890400090114    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.73\n",
      "episode: 1807   score: 5.0   memory length: 400084   epsilon: 0.20802970000900722    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 4.75\n",
      "episode: 1808   score: 5.0   memory length: 400410   epsilon: 0.20738422000900314    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1809   score: 5.0   memory length: 400724   epsilon: 0.2067625000089992    steps: 314    lr: 2.560000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1810   score: 3.0   memory length: 400935   epsilon: 0.20634472000899656    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1811   score: 6.0   memory length: 401330   epsilon: 0.20556262000899161    steps: 395    lr: 2.560000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1812   score: 7.0   memory length: 401755   epsilon: 0.2047211200089863    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1813   score: 3.0   memory length: 401984   epsilon: 0.20426770000898342    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1814   score: 6.0   memory length: 402336   epsilon: 0.203570740008979    steps: 352    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1815   score: 6.0   memory length: 402691   epsilon: 0.20286784000897456    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1816   score: 4.0   memory length: 402950   epsilon: 0.20235502000897132    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1817   score: 3.0   memory length: 403179   epsilon: 0.20190160000896845    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1818   score: 6.0   memory length: 403536   epsilon: 0.20119474000896398    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1819   score: 4.0   memory length: 403815   epsilon: 0.20064232000896048    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1820   score: 6.0   memory length: 404152   epsilon: 0.19997506000895626    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1821   score: 4.0   memory length: 404413   epsilon: 0.199458280008953    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1822   score: 5.0   memory length: 404739   epsilon: 0.1988128000089489    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1823   score: 4.0   memory length: 405017   epsilon: 0.19826236000894543    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1824   score: 7.0   memory length: 405422   epsilon: 0.19746046000894035    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1825   score: 4.0   memory length: 405701   epsilon: 0.19690804000893686    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1826   score: 5.0   memory length: 406027   epsilon: 0.19626256000893277    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1827   score: 3.0   memory length: 406256   epsilon: 0.1958091400089299    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1828   score: 7.0   memory length: 406685   epsilon: 0.19495972000892453    steps: 429    lr: 2.560000000000001e-06     evaluation reward: 4.85\n",
      "episode: 1829   score: 3.0   memory length: 406933   epsilon: 0.19446868000892142    steps: 248    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1830   score: 6.0   memory length: 407315   epsilon: 0.19371232000891664    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1831   score: 4.0   memory length: 407591   epsilon: 0.19316584000891318    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1832   score: 4.0   memory length: 407869   epsilon: 0.1926154000089097    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1833   score: 5.0   memory length: 408154   epsilon: 0.19205110000890613    steps: 285    lr: 2.560000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1834   score: 4.0   memory length: 408415   epsilon: 0.19153432000890286    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1835   score: 6.0   memory length: 408748   epsilon: 0.1908749800088987    steps: 333    lr: 2.560000000000001e-06     evaluation reward: 4.78\n",
      "episode: 1836   score: 6.0   memory length: 409070   epsilon: 0.19023742000889465    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1837   score: 4.0   memory length: 409328   epsilon: 0.18972658000889142    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1838   score: 6.0   memory length: 409675   epsilon: 0.18903952000888707    steps: 347    lr: 2.560000000000001e-06     evaluation reward: 4.8\n",
      "episode: 1839   score: 5.0   memory length: 409979   epsilon: 0.18843760000888327    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1840   score: 7.0   memory length: 410427   epsilon: 0.18755056000887765    steps: 448    lr: 2.560000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1841   score: 6.0   memory length: 410800   epsilon: 0.18681202000887298    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1842   score: 6.0   memory length: 411178   epsilon: 0.18606358000886825    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1843   score: 6.0   memory length: 411554   epsilon: 0.18531910000886354    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1844   score: 4.0   memory length: 411813   epsilon: 0.1848062800088603    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1845   score: 4.0   memory length: 412090   epsilon: 0.18425782000885682    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1846   score: 5.0   memory length: 412397   epsilon: 0.18364996000885297    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1847   score: 3.0   memory length: 412610   epsilon: 0.1832282200088503    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1848   score: 4.0   memory length: 412871   epsilon: 0.18271144000884704    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 4.77\n",
      "episode: 1849   score: 8.0   memory length: 413304   epsilon: 0.1818541000088416    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1850   score: 6.0   memory length: 413635   epsilon: 0.18119872000883747    steps: 331    lr: 2.560000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1851   score: 4.0   memory length: 413915   epsilon: 0.18064432000883396    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 4.82\n",
      "episode: 1852   score: 7.0   memory length: 414322   epsilon: 0.17983846000882886    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1853   score: 7.0   memory length: 414708   epsilon: 0.17907418000882402    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1854   score: 2.0   memory length: 414888   epsilon: 0.17871778000882177    steps: 180    lr: 2.560000000000001e-06     evaluation reward: 4.83\n",
      "episode: 1855   score: 9.0   memory length: 415360   epsilon: 0.17778322000881586    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 4.88\n",
      "episode: 1856   score: 8.0   memory length: 415798   epsilon: 0.17691598000881037    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1857   score: 7.0   memory length: 416164   epsilon: 0.17619130000880578    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1858   score: 9.0   memory length: 416621   epsilon: 0.17528644000880006    steps: 457    lr: 2.560000000000001e-06     evaluation reward: 4.99\n",
      "episode: 1859   score: 6.0   memory length: 416978   epsilon: 0.1745795800087956    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 5.01\n",
      "episode: 1860   score: 3.0   memory length: 417209   epsilon: 0.1741222000087927    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1861   score: 5.0   memory length: 417509   epsilon: 0.17352820000878894    steps: 300    lr: 2.560000000000001e-06     evaluation reward: 4.96\n",
      "episode: 1862   score: 9.0   memory length: 417962   epsilon: 0.17263126000878326    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 4.99\n",
      "episode: 1863   score: 7.0   memory length: 418366   epsilon: 0.1718313400087782    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1864   score: 6.0   memory length: 418766   epsilon: 0.1710393400087732    steps: 400    lr: 2.560000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1865   score: 5.0   memory length: 419074   epsilon: 0.17042950000876933    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 5.04\n",
      "episode: 1866   score: 6.0   memory length: 419431   epsilon: 0.16972264000876486    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 5.05\n",
      "episode: 1867   score: 5.0   memory length: 419735   epsilon: 0.16912072000876105    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 5.06\n",
      "episode: 1868   score: 7.0   memory length: 420124   epsilon: 0.16835050000875618    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 5.09\n",
      "episode: 1869   score: 12.0   memory length: 420581   epsilon: 0.16744564000875045    steps: 457    lr: 2.560000000000001e-06     evaluation reward: 5.17\n",
      "episode: 1870   score: 7.0   memory length: 421006   epsilon: 0.16660414000874513    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 5.2\n",
      "episode: 1871   score: 4.0   memory length: 421281   epsilon: 0.16605964000874168    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 5.17\n",
      "episode: 1872   score: 3.0   memory length: 421494   epsilon: 0.16563790000873901    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.16\n",
      "episode: 1873   score: 6.0   memory length: 421851   epsilon: 0.16493104000873454    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 5.16\n",
      "episode: 1874   score: 6.0   memory length: 422210   epsilon: 0.16422022000873004    steps: 359    lr: 2.560000000000001e-06     evaluation reward: 5.19\n",
      "episode: 1875   score: 8.0   memory length: 422646   epsilon: 0.16335694000872458    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 5.22\n",
      "episode: 1876   score: 5.0   memory length: 422955   epsilon: 0.1627451200087207    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.23\n",
      "episode: 1877   score: 3.0   memory length: 423186   epsilon: 0.16228774000871782    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 5.23\n",
      "episode: 1878   score: 12.0   memory length: 423675   epsilon: 0.1613195200087117    steps: 489    lr: 2.560000000000001e-06     evaluation reward: 5.31\n",
      "episode: 1879   score: 4.0   memory length: 423950   epsilon: 0.16077502000870825    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 5.3\n",
      "episode: 1880   score: 6.0   memory length: 424282   epsilon: 0.1601176600087041    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 5.29\n",
      "episode: 1881   score: 10.0   memory length: 424692   epsilon: 0.15930586000869895    steps: 410    lr: 2.560000000000001e-06     evaluation reward: 5.34\n",
      "episode: 1882   score: 5.0   memory length: 425000   epsilon: 0.1586960200086951    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 5.35\n",
      "episode: 1883   score: 5.0   memory length: 425320   epsilon: 0.15806242000869108    steps: 320    lr: 2.560000000000001e-06     evaluation reward: 5.35\n",
      "episode: 1884   score: 4.0   memory length: 425599   epsilon: 0.1575100000086876    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 5.36\n",
      "episode: 1885   score: 4.0   memory length: 425857   epsilon: 0.15699916000868436    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 5.37\n",
      "episode: 1886   score: 5.0   memory length: 426183   epsilon: 0.15635368000868027    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 5.38\n",
      "episode: 1887   score: 5.0   memory length: 426489   epsilon: 0.15574780000867644    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1888   score: 11.0   memory length: 427062   epsilon: 0.15461326000866926    steps: 573    lr: 2.560000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1889   score: 3.0   memory length: 427292   epsilon: 0.15415786000866638    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1890   score: 7.0   memory length: 427676   epsilon: 0.15339754000866157    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1891   score: 6.0   memory length: 427998   epsilon: 0.15275998000865754    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1892   score: 8.0   memory length: 428435   epsilon: 0.15189472000865206    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 5.52\n",
      "episode: 1893   score: 8.0   memory length: 428868   epsilon: 0.15103738000864664    steps: 433    lr: 2.560000000000001e-06     evaluation reward: 5.55\n",
      "episode: 1894   score: 7.0   memory length: 429317   epsilon: 0.150148360008641    steps: 449    lr: 2.560000000000001e-06     evaluation reward: 5.56\n",
      "episode: 1895   score: 7.0   memory length: 429704   epsilon: 0.14938210000863617    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 5.59\n",
      "episode: 1896   score: 6.0   memory length: 430080   epsilon: 0.14863762000863145    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 5.61\n",
      "episode: 1897   score: 6.0   memory length: 430437   epsilon: 0.14793076000862698    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 5.62\n",
      "episode: 1898   score: 10.0   memory length: 430852   epsilon: 0.14710906000862178    steps: 415    lr: 2.560000000000001e-06     evaluation reward: 5.65\n",
      "episode: 1899   score: 4.0   memory length: 431109   epsilon: 0.14660020000861856    steps: 257    lr: 2.560000000000001e-06     evaluation reward: 5.65\n",
      "episode: 1900   score: 4.0   memory length: 431369   epsilon: 0.1460854000086153    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.66\n",
      "episode: 1901   score: 5.0   memory length: 431658   epsilon: 0.1455131800086117    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 5.66\n",
      "episode: 1902   score: 8.0   memory length: 431953   epsilon: 0.144929080008608    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 1903   score: 8.0   memory length: 432387   epsilon: 0.14406976000860255    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 5.73\n",
      "episode: 1904   score: 6.0   memory length: 432780   epsilon: 0.14329162000859763    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 5.66\n",
      "episode: 1905   score: 5.0   memory length: 433084   epsilon: 0.14268970000859382    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 1906   score: 7.0   memory length: 433473   epsilon: 0.14191948000858895    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 1907   score: 7.0   memory length: 433881   epsilon: 0.14111164000858384    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 1908   score: 5.0   memory length: 434204   epsilon: 0.1404721000085798    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 1909   score: 3.0   memory length: 434417   epsilon: 0.14005036000857712    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 1910   score: 7.0   memory length: 434804   epsilon: 0.13928410000857228    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 1911   score: 5.0   memory length: 435133   epsilon: 0.13863268000856815    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 5.75\n",
      "episode: 1912   score: 7.0   memory length: 435543   epsilon: 0.13782088000856302    steps: 410    lr: 2.560000000000001e-06     evaluation reward: 5.75\n",
      "episode: 1913   score: 5.0   memory length: 435832   epsilon: 0.1372486600085594    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 1914   score: 5.0   memory length: 436135   epsilon: 0.1366487200085556    steps: 303    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 1915   score: 6.0   memory length: 436509   epsilon: 0.13590820000855092    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 1916   score: 5.0   memory length: 436830   epsilon: 0.1352726200085469    steps: 321    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 1917   score: 8.0   memory length: 437253   epsilon: 0.1344350800085416    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 1918   score: 5.0   memory length: 437581   epsilon: 0.1337856400085375    steps: 328    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 1919   score: 6.0   memory length: 437955   epsilon: 0.1330451200085328    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 5.83\n",
      "episode: 1920   score: 5.0   memory length: 438244   epsilon: 0.13247290000852918    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 1921   score: 5.0   memory length: 438568   epsilon: 0.13183138000852512    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 5.83\n",
      "episode: 1922   score: 3.0   memory length: 438798   epsilon: 0.13137598000852224    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 1923   score: 4.0   memory length: 439080   epsilon: 0.1308176200085187    steps: 282    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 1924   score: 7.0   memory length: 439487   epsilon: 0.1300117600085136    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 1925   score: 5.0   memory length: 439814   epsilon: 0.12936430000850951    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 1926   score: 6.0   memory length: 440189   epsilon: 0.12862180000850482    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 5.83\n",
      "episode: 1927   score: 9.0   memory length: 440649   epsilon: 0.12771100000849905    steps: 460    lr: 2.560000000000001e-06     evaluation reward: 5.89\n",
      "episode: 1928   score: 8.0   memory length: 441074   epsilon: 0.12686950000849373    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 5.9\n",
      "episode: 1929   score: 9.0   memory length: 441510   epsilon: 0.12600622000848827    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 5.96\n",
      "episode: 1930   score: 7.0   memory length: 441899   epsilon: 0.1252360000084834    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 5.97\n",
      "episode: 1931   score: 6.0   memory length: 442297   epsilon: 0.12444796000848228    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 1932   score: 4.0   memory length: 442558   epsilon: 0.12393118000848263    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 1933   score: 6.0   memory length: 442929   epsilon: 0.12319660000848313    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 1934   score: 7.0   memory length: 443315   epsilon: 0.12243232000848366    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 1935   score: 6.0   memory length: 443688   epsilon: 0.12169378000848416    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 1936   score: 5.0   memory length: 444021   epsilon: 0.12103444000848461    steps: 333    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 1937   score: 8.0   memory length: 444316   epsilon: 0.12045034000848501    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 1938   score: 5.0   memory length: 444625   epsilon: 0.11983852000848542    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 1939   score: 6.0   memory length: 444999   epsilon: 0.11909800000848593    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 1940   score: 5.0   memory length: 445344   epsilon: 0.1184149000084864    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 1941   score: 6.0   memory length: 445664   epsilon: 0.11778130000848683    steps: 320    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 1942   score: 9.0   memory length: 446135   epsilon: 0.11684872000848746    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 1943   score: 7.0   memory length: 446558   epsilon: 0.11601118000848804    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 1944   score: 11.0   memory length: 447139   epsilon: 0.11486080000848882    steps: 581    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1945   score: 8.0   memory length: 447529   epsilon: 0.11408860000848935    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 1946   score: 7.0   memory length: 447898   epsilon: 0.11335798000848984    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 1947   score: 7.0   memory length: 448329   epsilon: 0.11250460000849043    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1948   score: 4.0   memory length: 448570   epsilon: 0.11202742000849075    steps: 241    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1949   score: 6.0   memory length: 448927   epsilon: 0.11132056000849123    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 6.23\n",
      "episode: 1950   score: 7.0   memory length: 449332   epsilon: 0.11051866000849178    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1951   score: 4.0   memory length: 449610   epsilon: 0.10996822000849216    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1952   score: 5.0   memory length: 449897   epsilon: 0.10939996000849254    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 1953   score: 5.0   memory length: 450188   epsilon: 0.10882378000849294    steps: 291    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 1954   score: 6.0   memory length: 450546   epsilon: 0.10811494000849342    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1955   score: 8.0   memory length: 450964   epsilon: 0.10728730000849399    steps: 418    lr: 2.560000000000001e-06     evaluation reward: 6.23\n",
      "episode: 1956   score: 14.0   memory length: 451482   epsilon: 0.10626166000849468    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1957   score: 6.0   memory length: 451859   epsilon: 0.1055152000084952    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 6.28\n",
      "episode: 1958   score: 6.0   memory length: 452237   epsilon: 0.1047667600084957    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1959   score: 5.0   memory length: 452584   epsilon: 0.10407970000849617    steps: 347    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1960   score: 10.0   memory length: 453128   epsilon: 0.10300258000849691    steps: 544    lr: 2.560000000000001e-06     evaluation reward: 6.31\n",
      "episode: 1961   score: 6.0   memory length: 453465   epsilon: 0.10233532000849736    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 6.32\n",
      "episode: 1962   score: 3.0   memory length: 453692   epsilon: 0.10188586000849767    steps: 227    lr: 2.560000000000001e-06     evaluation reward: 6.26\n",
      "episode: 1963   score: 6.0   memory length: 454069   epsilon: 0.10113940000849818    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1964   score: 6.0   memory length: 454425   epsilon: 0.10043452000849866    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1965   score: 9.0   memory length: 454870   epsilon: 0.09955342000849926    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1966   score: 3.0   memory length: 455119   epsilon: 0.0990604000084996    steps: 249    lr: 2.560000000000001e-06     evaluation reward: 6.26\n",
      "episode: 1967   score: 4.0   memory length: 455397   epsilon: 0.09850996000849997    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1968   score: 5.0   memory length: 455685   epsilon: 0.09793972000850036    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 6.23\n",
      "episode: 1969   score: 6.0   memory length: 456040   epsilon: 0.09723682000850084    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 1970   score: 3.0   memory length: 456271   epsilon: 0.09677944000850115    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1971   score: 6.0   memory length: 456609   epsilon: 0.09611020000850161    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1972   score: 7.0   memory length: 456990   epsilon: 0.09535582000850212    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 1973   score: 6.0   memory length: 457328   epsilon: 0.09468658000850258    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 1974   score: 7.0   memory length: 457688   epsilon: 0.09397378000850307    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 1975   score: 4.0   memory length: 457926   epsilon: 0.09350254000850339    steps: 238    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1976   score: 5.0   memory length: 458293   epsilon: 0.09277588000850388    steps: 367    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1977   score: 7.0   memory length: 458680   epsilon: 0.0920096200085044    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 1978   score: 2.0   memory length: 458880   epsilon: 0.09161362000850468    steps: 200    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 1979   score: 7.0   memory length: 459265   epsilon: 0.0908513200085052    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1980   score: 4.0   memory length: 459544   epsilon: 0.09029890000850557    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1981   score: 7.0   memory length: 459916   epsilon: 0.08956234000850608    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 1982   score: 6.0   memory length: 460245   epsilon: 0.08891092000850652    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1983   score: 8.0   memory length: 460681   epsilon: 0.08804764000850711    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 1984   score: 6.0   memory length: 461037   epsilon: 0.08734276000850759    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1985   score: 5.0   memory length: 461364   epsilon: 0.08669530000850803    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1986   score: 6.0   memory length: 461720   epsilon: 0.08599042000850851    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1987   score: 7.0   memory length: 462104   epsilon: 0.08523010000850903    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 1988   score: 7.0   memory length: 462529   epsilon: 0.0843886000085096    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1989   score: 5.0   memory length: 462862   epsilon: 0.08372926000851005    steps: 333    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1990   score: 7.0   memory length: 463266   epsilon: 0.0829293400085106    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1991   score: 7.0   memory length: 463688   epsilon: 0.08209378000851117    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 1992   score: 8.0   memory length: 464109   epsilon: 0.08126020000851174    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 1993   score: 7.0   memory length: 464445   epsilon: 0.08059492000851219    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1994   score: 7.0   memory length: 464815   epsilon: 0.07986232000851269    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1995   score: 6.0   memory length: 465168   epsilon: 0.07916338000851317    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1996   score: 7.0   memory length: 465577   epsilon: 0.07835356000851372    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1997   score: 6.0   memory length: 465952   epsilon: 0.07761106000851423    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 1998   score: 7.0   memory length: 466353   epsilon: 0.07681708000851477    steps: 401    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1999   score: 6.0   memory length: 466728   epsilon: 0.07607458000851527    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2000   score: 2.0   memory length: 466908   epsilon: 0.07571818000851552    steps: 180    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2001   score: 7.0   memory length: 467324   epsilon: 0.07489450000851608    steps: 416    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2002   score: 7.0   memory length: 467722   epsilon: 0.07410646000851662    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2003   score: 4.0   memory length: 468001   epsilon: 0.073554040008517    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2004   score: 4.0   memory length: 468279   epsilon: 0.07300360000851737    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2005   score: 7.0   memory length: 468615   epsilon: 0.07233832000851782    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2006   score: 3.0   memory length: 468842   epsilon: 0.07188886000851813    steps: 227    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2007   score: 9.0   memory length: 469345   epsilon: 0.07089292000851881    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2008   score: 5.0   memory length: 469653   epsilon: 0.07028308000851922    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2009   score: 8.0   memory length: 470042   epsilon: 0.06951286000851975    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2010   score: 6.0   memory length: 470379   epsilon: 0.0688456000085202    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2011   score: 6.0   memory length: 470736   epsilon: 0.06813874000852069    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2012   score: 5.0   memory length: 471063   epsilon: 0.06749128000852113    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2013   score: 6.0   memory length: 471400   epsilon: 0.06682402000852158    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2014   score: 5.0   memory length: 471748   epsilon: 0.06613498000852205    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2015   score: 7.0   memory length: 472150   epsilon: 0.0653390200085226    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2016   score: 3.0   memory length: 472378   epsilon: 0.0648875800085229    steps: 228    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2017   score: 4.0   memory length: 472656   epsilon: 0.06433714000852328    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2018   score: 6.0   memory length: 472994   epsilon: 0.06366790000852374    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2019   score: 7.0   memory length: 473377   epsilon: 0.06290956000852425    steps: 383    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2020   score: 8.0   memory length: 473832   epsilon: 0.06200866000852487    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2021   score: 5.0   memory length: 474139   epsilon: 0.06140080000852528    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2022   score: 5.0   memory length: 474446   epsilon: 0.0607929400085257    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2023   score: 6.0   memory length: 474801   epsilon: 0.06009004000852618    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2024   score: 5.0   memory length: 475109   epsilon: 0.05948020000852659    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2025   score: 10.0   memory length: 475467   epsilon: 0.05877136000852708    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2026   score: 7.0   memory length: 475894   epsilon: 0.05792590000852765    steps: 427    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2027   score: 7.0   memory length: 476281   epsilon: 0.057159640008528176    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2028   score: 7.0   memory length: 476705   epsilon: 0.05632012000852875    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2029   score: 6.0   memory length: 477060   epsilon: 0.05561722000852923    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2030   score: 7.0   memory length: 477484   epsilon: 0.0547777000085298    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2031   score: 5.0   memory length: 477791   epsilon: 0.054169840008530215    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2032   score: 4.0   memory length: 478063   epsilon: 0.05363128000853058    steps: 272    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2033   score: 4.0   memory length: 478323   epsilon: 0.053116480008530934    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2034   score: 5.0   memory length: 478649   epsilon: 0.052471000008531374    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2035   score: 7.0   memory length: 479071   epsilon: 0.051635440008531944    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2036   score: 7.0   memory length: 479512   epsilon: 0.05076226000853254    steps: 441    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2037   score: 7.0   memory length: 479899   epsilon: 0.04999600000853306    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2038   score: 6.0   memory length: 480237   epsilon: 0.04932676000853352    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2039   score: 10.0   memory length: 480741   epsilon: 0.0483288400085342    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2040   score: 5.0   memory length: 481050   epsilon: 0.047717020008534616    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2041   score: 7.0   memory length: 481436   epsilon: 0.04695274000853514    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2042   score: 3.0   memory length: 481661   epsilon: 0.04650724000853544    steps: 225    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2043   score: 8.0   memory length: 482074   epsilon: 0.045689500008536    steps: 413    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2044   score: 5.0   memory length: 482423   epsilon: 0.04499848000853647    steps: 349    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2045   score: 7.0   memory length: 482811   epsilon: 0.044230240008536995    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2046   score: 6.0   memory length: 483169   epsilon: 0.04352140000853748    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2047   score: 5.0   memory length: 483470   epsilon: 0.042925420008537885    steps: 301    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2048   score: 7.0   memory length: 483898   epsilon: 0.04207798000853846    steps: 428    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2049   score: 9.0   memory length: 484389   epsilon: 0.041105800008539126    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2050   score: 6.0   memory length: 484762   epsilon: 0.04036726000853963    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2051   score: 6.0   memory length: 485160   epsilon: 0.03957922000854017    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2052   score: 3.0   memory length: 485389   epsilon: 0.039125800008540476    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2053   score: 4.0   memory length: 485646   epsilon: 0.03861694000854082    steps: 257    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2054   score: 5.0   memory length: 485949   epsilon: 0.03801700000854123    steps: 303    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2055   score: 6.0   memory length: 486281   epsilon: 0.03735964000854168    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2056   score: 5.0   memory length: 486582   epsilon: 0.03676366000854209    steps: 301    lr: 2.560000000000001e-06     evaluation reward: 5.94\n",
      "episode: 2057   score: 5.0   memory length: 486869   epsilon: 0.036195400008542475    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 5.93\n",
      "episode: 2058   score: 12.0   memory length: 487355   epsilon: 0.03523312000854313    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2059   score: 5.0   memory length: 487704   epsilon: 0.0345421000085436    steps: 349    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2060   score: 7.0   memory length: 488105   epsilon: 0.033748120008544144    steps: 401    lr: 2.560000000000001e-06     evaluation reward: 5.96\n",
      "episode: 2061   score: 4.0   memory length: 488379   epsilon: 0.033205600008544514    steps: 274    lr: 2.560000000000001e-06     evaluation reward: 5.94\n",
      "episode: 2062   score: 7.0   memory length: 488803   epsilon: 0.03236608000854509    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 5.98\n",
      "episode: 2063   score: 8.0   memory length: 489217   epsilon: 0.031546360008545646    steps: 414    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 2064   score: 8.0   memory length: 489712   epsilon: 0.030566260008546314    steps: 495    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2065   score: 7.0   memory length: 490118   epsilon: 0.029762380008546863    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 2066   score: 5.0   memory length: 490462   epsilon: 0.029081260008547327    steps: 344    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2067   score: 5.0   memory length: 490749   epsilon: 0.028513000008547715    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2068   score: 9.0   memory length: 491189   epsilon: 0.02764180000854831    steps: 440    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2069   score: 9.0   memory length: 491691   epsilon: 0.026647840008548987    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2070   score: 6.0   memory length: 492027   epsilon: 0.02598256000854944    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2071   score: 3.0   memory length: 492239   epsilon: 0.025562800008549727    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2072   score: 4.0   memory length: 492495   epsilon: 0.025055920008550073    steps: 256    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2073   score: 6.0   memory length: 492855   epsilon: 0.02434312000855056    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2074   score: 7.0   memory length: 493237   epsilon: 0.023586760008551075    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2075   score: 9.0   memory length: 493691   epsilon: 0.022687840008551688    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2076   score: 4.0   memory length: 493947   epsilon: 0.022180960008552034    steps: 256    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2077   score: 8.0   memory length: 494415   epsilon: 0.021254320008552666    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2078   score: 6.0   memory length: 494767   epsilon: 0.02055736000855314    steps: 352    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2079   score: 5.0   memory length: 495070   epsilon: 0.01995742000855355    steps: 303    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2080   score: 9.0   memory length: 495550   epsilon: 0.0190070200085542    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2081   score: 3.0   memory length: 495798   epsilon: 0.018515980008554533    steps: 248    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2082   score: 6.0   memory length: 496136   epsilon: 0.01784674000855499    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2083   score: 6.0   memory length: 496469   epsilon: 0.01718740000855544    steps: 333    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2084   score: 8.0   memory length: 496940   epsilon: 0.016254820008556076    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2085   score: 6.0   memory length: 497304   epsilon: 0.015534100008556487    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2086   score: 7.0   memory length: 497706   epsilon: 0.014738140008556333    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2087   score: 5.0   memory length: 497991   epsilon: 0.014173840008556223    steps: 285    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2088   score: 8.0   memory length: 498441   epsilon: 0.01328284000855605    steps: 450    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2089   score: 9.0   memory length: 498923   epsilon: 0.012328480008555865    steps: 482    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2090   score: 5.0   memory length: 499212   epsilon: 0.011756260008555754    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2091   score: 6.0   memory length: 499568   epsilon: 0.011051380008555618    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2092   score: 6.0   memory length: 499921   epsilon: 0.010352440008555482    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2093   score: 5.0   memory length: 500248   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.13\n",
      "episode: 2094   score: 10.0   memory length: 500758   epsilon: 0.009998020008555413    steps: 510    lr: 1.0240000000000005e-06     evaluation reward: 6.16\n",
      "episode: 2095   score: 10.0   memory length: 501173   epsilon: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     evaluation reward: 6.2\n",
      "episode: 2096   score: 8.0   memory length: 501626   epsilon: 0.009998020008555413    steps: 453    lr: 1.0240000000000005e-06     evaluation reward: 6.21\n",
      "episode: 2097   score: 8.0   memory length: 502037   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 6.23\n",
      "episode: 2098   score: 5.0   memory length: 502351   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.21\n",
      "episode: 2099   score: 8.0   memory length: 502786   epsilon: 0.009998020008555413    steps: 435    lr: 1.0240000000000005e-06     evaluation reward: 6.23\n",
      "episode: 2100   score: 7.0   memory length: 503193   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2101   score: 6.0   memory length: 503529   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2102   score: 5.0   memory length: 503873   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 6.25\n",
      "episode: 2103   score: 7.0   memory length: 504311   epsilon: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2104   score: 10.0   memory length: 504840   epsilon: 0.009998020008555413    steps: 529    lr: 1.0240000000000005e-06     evaluation reward: 6.34\n",
      "episode: 2105   score: 6.0   memory length: 505212   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2106   score: 3.0   memory length: 505440   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2107   score: 5.0   memory length: 505748   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2108   score: 5.0   memory length: 506053   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2109   score: 3.0   memory length: 506281   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.24\n",
      "episode: 2110   score: 10.0   memory length: 506690   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2111   score: 9.0   memory length: 507076   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2112   score: 5.0   memory length: 507376   epsilon: 0.009998020008555413    steps: 300    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2113   score: 7.0   memory length: 507780   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2114   score: 3.0   memory length: 508008   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2115   score: 7.0   memory length: 508390   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2116   score: 8.0   memory length: 508850   epsilon: 0.009998020008555413    steps: 460    lr: 1.0240000000000005e-06     evaluation reward: 6.35\n",
      "episode: 2117   score: 7.0   memory length: 509255   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2118   score: 10.0   memory length: 509790   epsilon: 0.009998020008555413    steps: 535    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2119   score: 6.0   memory length: 510153   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2120   score: 5.0   memory length: 510457   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2121   score: 5.0   memory length: 510784   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2122   score: 5.0   memory length: 511098   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2123   score: 5.0   memory length: 511402   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2124   score: 10.0   memory length: 511920   epsilon: 0.009998020008555413    steps: 518    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2125   score: 7.0   memory length: 512308   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2126   score: 8.0   memory length: 512746   epsilon: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2127   score: 7.0   memory length: 513132   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2128   score: 8.0   memory length: 513557   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2129   score: 9.0   memory length: 514032   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2130   score: 4.0   memory length: 514289   epsilon: 0.009998020008555413    steps: 257    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2131   score: 7.0   memory length: 514664   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2132   score: 10.0   memory length: 515169   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2133   score: 7.0   memory length: 515573   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2134   score: 8.0   memory length: 516019   epsilon: 0.009998020008555413    steps: 446    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2135   score: 8.0   memory length: 516475   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2136   score: 6.0   memory length: 516847   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2137   score: 7.0   memory length: 517247   epsilon: 0.009998020008555413    steps: 400    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2138   score: 6.0   memory length: 517602   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2139   score: 5.0   memory length: 517924   epsilon: 0.009998020008555413    steps: 322    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2140   score: 5.0   memory length: 518268   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2141   score: 11.0   memory length: 518706   epsilon: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2142   score: 7.0   memory length: 519092   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2143   score: 6.0   memory length: 519485   epsilon: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2144   score: 10.0   memory length: 519878   epsilon: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2145   score: 6.0   memory length: 520276   epsilon: 0.009998020008555413    steps: 398    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2146   score: 7.0   memory length: 520663   epsilon: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2147   score: 5.0   memory length: 520952   epsilon: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2148   score: 6.0   memory length: 521288   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2149   score: 8.0   memory length: 521721   epsilon: 0.009998020008555413    steps: 433    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2150   score: 5.0   memory length: 522045   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2151   score: 4.0   memory length: 522304   epsilon: 0.009998020008555413    steps: 259    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2152   score: 6.0   memory length: 522658   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2153   score: 7.0   memory length: 523046   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 6.62\n",
      "episode: 2154   score: 5.0   memory length: 523369   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.62\n",
      "episode: 2155   score: 4.0   memory length: 523606   epsilon: 0.009998020008555413    steps: 237    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2156   score: 2.0   memory length: 523785   epsilon: 0.009998020008555413    steps: 179    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2157   score: 6.0   memory length: 524116   epsilon: 0.009998020008555413    steps: 331    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2158   score: 6.0   memory length: 524469   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2159   score: 3.0   memory length: 524697   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2160   score: 6.0   memory length: 525033   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2161   score: 5.0   memory length: 525360   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2162   score: 4.0   memory length: 525636   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2163   score: 4.0   memory length: 525893   epsilon: 0.009998020008555413    steps: 257    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2164   score: 9.0   memory length: 526217   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2165   score: 8.0   memory length: 526680   epsilon: 0.009998020008555413    steps: 463    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2166   score: 5.0   memory length: 526949   epsilon: 0.009998020008555413    steps: 269    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2167   score: 7.0   memory length: 527338   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2168   score: 6.0   memory length: 527709   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2169   score: 8.0   memory length: 528139   epsilon: 0.009998020008555413    steps: 430    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2170   score: 7.0   memory length: 528540   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2171   score: 7.0   memory length: 528949   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2172   score: 7.0   memory length: 529355   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2173   score: 8.0   memory length: 529783   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2174   score: 7.0   memory length: 530171   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2175   score: 5.0   memory length: 530475   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2176   score: 6.0   memory length: 530828   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2177   score: 6.0   memory length: 531173   epsilon: 0.009998020008555413    steps: 345    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2178   score: 5.0   memory length: 531487   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2179   score: 6.0   memory length: 531860   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2180   score: 7.0   memory length: 532273   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2181   score: 5.0   memory length: 532617   epsilon: 0.009998020008555413    steps: 344    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2182   score: 5.0   memory length: 532940   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2183   score: 6.0   memory length: 533303   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2184   score: 8.0   memory length: 533774   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2185   score: 6.0   memory length: 534110   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2186   score: 6.0   memory length: 534473   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2187   score: 9.0   memory length: 534967   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2188   score: 6.0   memory length: 535304   epsilon: 0.009998020008555413    steps: 337    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2189   score: 8.0   memory length: 535723   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2190   score: 9.0   memory length: 536136   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2191   score: 7.0   memory length: 536538   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2192   score: 10.0   memory length: 536895   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2193   score: 8.0   memory length: 537338   epsilon: 0.009998020008555413    steps: 443    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2194   score: 4.0   memory length: 537596   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2195   score: 7.0   memory length: 537982   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2196   score: 6.0   memory length: 538318   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2197   score: 5.0   memory length: 538632   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2198   score: 7.0   memory length: 538995   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2199   score: 6.0   memory length: 539331   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2200   score: 7.0   memory length: 539717   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2201   score: 6.0   memory length: 540080   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2202   score: 5.0   memory length: 540384   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2203   score: 8.0   memory length: 540808   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2204   score: 6.0   memory length: 541125   epsilon: 0.009998020008555413    steps: 317    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2205   score: 6.0   memory length: 541479   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2206   score: 6.0   memory length: 541843   epsilon: 0.009998020008555413    steps: 364    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2207   score: 4.0   memory length: 542101   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2208   score: 4.0   memory length: 542359   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2209   score: 9.0   memory length: 542880   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2210   score: 8.0   memory length: 543335   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2211   score: 8.0   memory length: 543756   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2212   score: 10.0   memory length: 544184   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2213   score: 6.0   memory length: 544539   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2214   score: 4.0   memory length: 544777   epsilon: 0.009998020008555413    steps: 238    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2215   score: 6.0   memory length: 545111   epsilon: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2216   score: 11.0   memory length: 545632   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2217   score: 3.0   memory length: 545840   epsilon: 0.009998020008555413    steps: 208    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2218   score: 7.0   memory length: 546263   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2219   score: 8.0   memory length: 546699   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2220   score: 5.0   memory length: 547003   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2221   score: 4.0   memory length: 547277   epsilon: 0.009998020008555413    steps: 274    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2222   score: 7.0   memory length: 547725   epsilon: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2223   score: 7.0   memory length: 548110   epsilon: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2224   score: 5.0   memory length: 548434   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2225   score: 6.0   memory length: 548787   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2226   score: 3.0   memory length: 548995   epsilon: 0.009998020008555413    steps: 208    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2227   score: 7.0   memory length: 549400   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2228   score: 5.0   memory length: 549706   epsilon: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2229   score: 8.0   memory length: 550159   epsilon: 0.009998020008555413    steps: 453    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2230   score: 5.0   memory length: 550463   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2231   score: 3.0   memory length: 550672   epsilon: 0.009998020008555413    steps: 209    lr: 1.0240000000000005e-06     evaluation reward: 6.34\n",
      "episode: 2232   score: 4.0   memory length: 550950   epsilon: 0.009998020008555413    steps: 278    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2233   score: 6.0   memory length: 551288   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2234   score: 7.0   memory length: 551690   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2235   score: 9.0   memory length: 552185   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2236   score: 8.0   memory length: 552635   epsilon: 0.009998020008555413    steps: 450    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2237   score: 4.0   memory length: 552893   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2238   score: 11.0   memory length: 553333   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2239   score: 5.0   memory length: 553647   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2240   score: 6.0   memory length: 554002   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2241   score: 5.0   memory length: 554325   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2242   score: 7.0   memory length: 554704   epsilon: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2243   score: 8.0   memory length: 555123   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2244   score: 8.0   memory length: 555586   epsilon: 0.009998020008555413    steps: 463    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2245   score: 7.0   memory length: 555974   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2246   score: 6.0   memory length: 556293   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2247   score: 8.0   memory length: 556745   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2248   score: 3.0   memory length: 556974   epsilon: 0.009998020008555413    steps: 229    lr: 1.0240000000000005e-06     evaluation reward: 6.26\n",
      "episode: 2249   score: 6.0   memory length: 557312   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 6.24\n",
      "episode: 2250   score: 6.0   memory length: 557631   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 6.25\n",
      "episode: 2251   score: 8.0   memory length: 558093   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2252   score: 7.0   memory length: 558480   epsilon: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2253   score: 6.0   memory length: 558837   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2254   score: 7.0   memory length: 559226   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2255   score: 6.0   memory length: 559598   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2256   score: 11.0   memory length: 560038   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2257   score: 7.0   memory length: 560421   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2258   score: 5.0   memory length: 560708   epsilon: 0.009998020008555413    steps: 287    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2259   score: 7.0   memory length: 561129   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2260   score: 8.0   memory length: 561513   epsilon: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2261   score: 9.0   memory length: 562004   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2262   score: 4.0   memory length: 562260   epsilon: 0.009998020008555413    steps: 256    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2263   score: 14.0   memory length: 562940   epsilon: 0.009998020008555413    steps: 680    lr: 1.0240000000000005e-06     evaluation reward: 6.62\n",
      "episode: 2264   score: 7.0   memory length: 563364   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2265   score: 6.0   memory length: 563702   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2266   score: 3.0   memory length: 563930   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2267   score: 7.0   memory length: 564360   epsilon: 0.009998020008555413    steps: 430    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2268   score: 5.0   memory length: 564649   epsilon: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2269   score: 5.0   memory length: 564975   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2270   score: 8.0   memory length: 565411   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2271   score: 7.0   memory length: 565813   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2272   score: 8.0   memory length: 566265   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2273   score: 5.0   memory length: 566592   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2274   score: 2.0   memory length: 566771   epsilon: 0.009998020008555413    steps: 179    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2275   score: 10.0   memory length: 567323   epsilon: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2276   score: 13.0   memory length: 567818   epsilon: 0.009998020008555413    steps: 495    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2277   score: 5.0   memory length: 568143   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2278   score: 5.0   memory length: 568470   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2279   score: 9.0   memory length: 568974   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2280   score: 3.0   memory length: 569182   epsilon: 0.009998020008555413    steps: 208    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2281   score: 6.0   memory length: 569556   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2282   score: 5.0   memory length: 569861   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2283   score: 5.0   memory length: 570169   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2284   score: 5.0   memory length: 570454   epsilon: 0.009998020008555413    steps: 285    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2285   score: 4.0   memory length: 570709   epsilon: 0.009998020008555413    steps: 255    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2286   score: 6.0   memory length: 571084   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2287   score: 10.0   memory length: 571498   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2288   score: 8.0   memory length: 571924   epsilon: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2289   score: 7.0   memory length: 572329   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2290   score: 5.0   memory length: 572635   epsilon: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2291   score: 5.0   memory length: 572940   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2292   score: 5.0   memory length: 573246   epsilon: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2293   score: 5.0   memory length: 573550   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2294   score: 11.0   memory length: 574098   epsilon: 0.009998020008555413    steps: 548    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2295   score: 6.0   memory length: 574448   epsilon: 0.009998020008555413    steps: 350    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2296   score: 7.0   memory length: 574891   epsilon: 0.009998020008555413    steps: 443    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2297   score: 7.0   memory length: 575274   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2298   score: 6.0   memory length: 575649   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2299   score: 7.0   memory length: 576031   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2300   score: 6.0   memory length: 576362   epsilon: 0.009998020008555413    steps: 331    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2301   score: 7.0   memory length: 576810   epsilon: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2302   score: 6.0   memory length: 577183   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2303   score: 6.0   memory length: 577517   epsilon: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2304   score: 5.0   memory length: 577844   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2305   score: 10.0   memory length: 578381   epsilon: 0.009998020008555413    steps: 537    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2306   score: 7.0   memory length: 578808   epsilon: 0.009998020008555413    steps: 427    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2307   score: 7.0   memory length: 579227   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2308   score: 7.0   memory length: 579593   epsilon: 0.009998020008555413    steps: 366    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2309   score: 5.0   memory length: 579901   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2310   score: 6.0   memory length: 580237   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2311   score: 6.0   memory length: 580553   epsilon: 0.009998020008555413    steps: 316    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2312   score: 6.0   memory length: 580889   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2313   score: 7.0   memory length: 581317   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2314   score: 5.0   memory length: 581643   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2315   score: 6.0   memory length: 581980   epsilon: 0.009998020008555413    steps: 337    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2316   score: 6.0   memory length: 582341   epsilon: 0.009998020008555413    steps: 361    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2317   score: 8.0   memory length: 582755   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2318   score: 8.0   memory length: 583191   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2319   score: 8.0   memory length: 583622   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2320   score: 7.0   memory length: 584010   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2321   score: 6.0   memory length: 584364   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2322   score: 6.0   memory length: 584700   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2323   score: 2.0   memory length: 584879   epsilon: 0.009998020008555413    steps: 179    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2324   score: 4.0   memory length: 585135   epsilon: 0.009998020008555413    steps: 256    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2325   score: 5.0   memory length: 585428   epsilon: 0.009998020008555413    steps: 293    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2326   score: 7.0   memory length: 585811   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2327   score: 10.0   memory length: 586303   epsilon: 0.009998020008555413    steps: 492    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2328   score: 6.0   memory length: 586694   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2329   score: 7.0   memory length: 587079   epsilon: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2330   score: 11.0   memory length: 587496   epsilon: 0.009998020008555413    steps: 417    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2331   score: 5.0   memory length: 587782   epsilon: 0.009998020008555413    steps: 286    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2332   score: 5.0   memory length: 588107   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2333   score: 5.0   memory length: 588392   epsilon: 0.009998020008555413    steps: 285    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2334   score: 8.0   memory length: 588835   epsilon: 0.009998020008555413    steps: 443    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2335   score: 5.0   memory length: 589105   epsilon: 0.009998020008555413    steps: 270    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2336   score: 8.0   memory length: 589524   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2337   score: 5.0   memory length: 589811   epsilon: 0.009998020008555413    steps: 287    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2338   score: 7.0   memory length: 590146   epsilon: 0.009998020008555413    steps: 335    lr: 1.0240000000000005e-06     evaluation reward: 6.53\n",
      "episode: 2339   score: 8.0   memory length: 590560   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2340   score: 5.0   memory length: 590865   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2341   score: 6.0   memory length: 591256   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2342   score: 7.0   memory length: 591624   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2343   score: 4.0   memory length: 591882   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2344   score: 7.0   memory length: 592286   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2345   score: 5.0   memory length: 592613   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2346   score: 8.0   memory length: 593027   epsilon: 0.009998020008555413    steps: 414    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2347   score: 6.0   memory length: 593343   epsilon: 0.009998020008555413    steps: 316    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2348   score: 6.0   memory length: 593737   epsilon: 0.009998020008555413    steps: 394    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2349   score: 8.0   memory length: 594213   epsilon: 0.009998020008555413    steps: 476    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2350   score: 7.0   memory length: 594597   epsilon: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2351   score: 8.0   memory length: 595052   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2352   score: 9.0   memory length: 595576   epsilon: 0.009998020008555413    steps: 524    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2353   score: 5.0   memory length: 595883   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2354   score: 11.0   memory length: 596303   epsilon: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2355   score: 5.0   memory length: 596607   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2356   score: 7.0   memory length: 597013   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2357   score: 8.0   memory length: 597408   epsilon: 0.009998020008555413    steps: 395    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2358   score: 7.0   memory length: 597856   epsilon: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2359   score: 9.0   memory length: 598323   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2360   score: 6.0   memory length: 598664   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2361   score: 9.0   memory length: 599135   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2362   score: 6.0   memory length: 599498   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2363   score: 8.0   memory length: 599915   epsilon: 0.009998020008555413    steps: 417    lr: 1.0240000000000005e-06     evaluation reward: 6.54\n",
      "episode: 2364   score: 11.0   memory length: 600356   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2365   score: 15.0   memory length: 600915   epsilon: 0.009998020008555413    steps: 559    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2366   score: 10.0   memory length: 601395   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 6.74\n",
      "episode: 2367   score: 7.0   memory length: 601778   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 6.74\n",
      "episode: 2368   score: 7.0   memory length: 602162   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 6.76\n",
      "episode: 2369   score: 9.0   memory length: 602646   epsilon: 0.009998020008555413    steps: 484    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2370   score: 7.0   memory length: 603030   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 6.79\n",
      "episode: 2371   score: 8.0   memory length: 603458   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2372   score: 3.0   memory length: 603666   epsilon: 0.009998020008555413    steps: 208    lr: 4.0960000000000023e-07     evaluation reward: 6.75\n",
      "episode: 2373   score: 7.0   memory length: 604048   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 6.77\n",
      "episode: 2374   score: 7.0   memory length: 604436   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 6.82\n",
      "episode: 2375   score: 14.0   memory length: 605015   epsilon: 0.009998020008555413    steps: 579    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2376   score: 8.0   memory length: 605490   epsilon: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     evaluation reward: 6.81\n",
      "episode: 2377   score: 10.0   memory length: 606061   epsilon: 0.009998020008555413    steps: 571    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2378   score: 7.0   memory length: 606484   epsilon: 0.009998020008555413    steps: 423    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2379   score: 7.0   memory length: 606891   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2380   score: 7.0   memory length: 607273   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 6.9\n",
      "episode: 2381   score: 9.0   memory length: 607760   epsilon: 0.009998020008555413    steps: 487    lr: 4.0960000000000023e-07     evaluation reward: 6.93\n",
      "episode: 2382   score: 7.0   memory length: 608164   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 6.95\n",
      "episode: 2383   score: 6.0   memory length: 608480   epsilon: 0.009998020008555413    steps: 316    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2384   score: 5.0   memory length: 608784   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2385   score: 5.0   memory length: 609069   epsilon: 0.009998020008555413    steps: 285    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2386   score: 8.0   memory length: 609505   epsilon: 0.009998020008555413    steps: 436    lr: 4.0960000000000023e-07     evaluation reward: 6.99\n",
      "episode: 2387   score: 7.0   memory length: 609888   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2388   score: 8.0   memory length: 610364   epsilon: 0.009998020008555413    steps: 476    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2389   score: 8.0   memory length: 610820   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2390   score: 8.0   memory length: 611251   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2391   score: 7.0   memory length: 611633   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2392   score: 6.0   memory length: 611969   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2393   score: 9.0   memory length: 612399   epsilon: 0.009998020008555413    steps: 430    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2394   score: 7.0   memory length: 612847   epsilon: 0.009998020008555413    steps: 448    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2395   score: 7.0   memory length: 613231   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2396   score: 9.0   memory length: 613755   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2397   score: 8.0   memory length: 614167   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2398   score: 7.0   memory length: 614575   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 7.08\n",
      "episode: 2399   score: 7.0   memory length: 614959   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 7.08\n",
      "episode: 2400   score: 5.0   memory length: 615263   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2401   score: 8.0   memory length: 615717   epsilon: 0.009998020008555413    steps: 454    lr: 4.0960000000000023e-07     evaluation reward: 7.08\n",
      "episode: 2402   score: 14.0   memory length: 616275   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 7.16\n",
      "episode: 2403   score: 6.0   memory length: 616614   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 7.16\n",
      "episode: 2404   score: 5.0   memory length: 616901   epsilon: 0.009998020008555413    steps: 287    lr: 4.0960000000000023e-07     evaluation reward: 7.16\n",
      "episode: 2405   score: 11.0   memory length: 617500   epsilon: 0.009998020008555413    steps: 599    lr: 4.0960000000000023e-07     evaluation reward: 7.17\n",
      "episode: 2406   score: 5.0   memory length: 617827   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2407   score: 6.0   memory length: 618178   epsilon: 0.009998020008555413    steps: 351    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2408   score: 6.0   memory length: 618533   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2409   score: 5.0   memory length: 618860   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2410   score: 7.0   memory length: 619264   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2411   score: 6.0   memory length: 619598   epsilon: 0.009998020008555413    steps: 334    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2412   score: 6.0   memory length: 619915   epsilon: 0.009998020008555413    steps: 317    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2413   score: 8.0   memory length: 620343   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2414   score: 3.0   memory length: 620551   epsilon: 0.009998020008555413    steps: 208    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2415   score: 12.0   memory length: 621121   epsilon: 0.009998020008555413    steps: 570    lr: 4.0960000000000023e-07     evaluation reward: 7.19\n",
      "episode: 2416   score: 5.0   memory length: 621425   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.18\n",
      "episode: 2417   score: 7.0   memory length: 621811   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.17\n",
      "episode: 2418   score: 5.0   memory length: 622138   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2419   score: 5.0   memory length: 622465   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2420   score: 6.0   memory length: 622798   epsilon: 0.009998020008555413    steps: 333    lr: 4.0960000000000023e-07     evaluation reward: 7.1\n",
      "episode: 2421   score: 7.0   memory length: 623220   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2422   score: 8.0   memory length: 623650   epsilon: 0.009998020008555413    steps: 430    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2423   score: 5.0   memory length: 623954   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.16\n",
      "episode: 2424   score: 6.0   memory length: 624309   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 7.18\n",
      "episode: 2425   score: 8.0   memory length: 624760   epsilon: 0.009998020008555413    steps: 451    lr: 4.0960000000000023e-07     evaluation reward: 7.21\n",
      "episode: 2426   score: 15.0   memory length: 625167   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2427   score: 5.0   memory length: 625494   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.24\n",
      "episode: 2428   score: 7.0   memory length: 625901   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.25\n",
      "episode: 2429   score: 5.0   memory length: 626228   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.23\n",
      "episode: 2430   score: 5.0   memory length: 626535   epsilon: 0.009998020008555413    steps: 307    lr: 4.0960000000000023e-07     evaluation reward: 7.17\n",
      "episode: 2431   score: 9.0   memory length: 626989   epsilon: 0.009998020008555413    steps: 454    lr: 4.0960000000000023e-07     evaluation reward: 7.21\n",
      "episode: 2432   score: 8.0   memory length: 627446   epsilon: 0.009998020008555413    steps: 457    lr: 4.0960000000000023e-07     evaluation reward: 7.24\n",
      "episode: 2433   score: 7.0   memory length: 627848   epsilon: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     evaluation reward: 7.26\n",
      "episode: 2434   score: 7.0   memory length: 628216   epsilon: 0.009998020008555413    steps: 368    lr: 4.0960000000000023e-07     evaluation reward: 7.25\n",
      "episode: 2435   score: 7.0   memory length: 628591   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2436   score: 7.0   memory length: 629006   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 7.26\n",
      "episode: 2437   score: 8.0   memory length: 629434   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2438   score: 7.0   memory length: 629822   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2439   score: 6.0   memory length: 630181   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2440   score: 7.0   memory length: 630549   epsilon: 0.009998020008555413    steps: 368    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2441   score: 7.0   memory length: 630934   epsilon: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2442   score: 6.0   memory length: 631291   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2443   score: 5.0   memory length: 631618   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2444   score: 7.0   memory length: 632006   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2445   score: 4.0   memory length: 632263   epsilon: 0.009998020008555413    steps: 257    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2446   score: 4.0   memory length: 632539   epsilon: 0.009998020008555413    steps: 276    lr: 4.0960000000000023e-07     evaluation reward: 7.25\n",
      "episode: 2447   score: 9.0   memory length: 632992   epsilon: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2448   score: 5.0   memory length: 633278   epsilon: 0.009998020008555413    steps: 286    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2449   score: 8.0   memory length: 633685   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2450   score: 11.0   memory length: 634129   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2451   score: 8.0   memory length: 634585   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2452   score: 8.0   memory length: 634997   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2453   score: 8.0   memory length: 635437   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2454   score: 7.0   memory length: 635818   epsilon: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     evaluation reward: 7.29\n",
      "episode: 2455   score: 7.0   memory length: 636202   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2456   score: 8.0   memory length: 636619   epsilon: 0.009998020008555413    steps: 417    lr: 4.0960000000000023e-07     evaluation reward: 7.32\n",
      "episode: 2457   score: 9.0   memory length: 637108   epsilon: 0.009998020008555413    steps: 489    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2458   score: 5.0   memory length: 637393   epsilon: 0.009998020008555413    steps: 285    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2459   score: 11.0   memory length: 637899   epsilon: 0.009998020008555413    steps: 506    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2460   score: 7.0   memory length: 638286   epsilon: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     evaluation reward: 7.34\n",
      "episode: 2461   score: 5.0   memory length: 638575   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2462   score: 6.0   memory length: 638929   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2463   score: 8.0   memory length: 639385   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2464   score: 5.0   memory length: 639690   epsilon: 0.009998020008555413    steps: 305    lr: 4.0960000000000023e-07     evaluation reward: 7.24\n",
      "episode: 2465   score: 2.0   memory length: 639869   epsilon: 0.009998020008555413    steps: 179    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2466   score: 5.0   memory length: 640158   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2467   score: 5.0   memory length: 640482   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2468   score: 9.0   memory length: 640940   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2469   score: 7.0   memory length: 641350   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2470   score: 6.0   memory length: 641686   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2471   score: 7.0   memory length: 642062   epsilon: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2472   score: 7.0   memory length: 642443   epsilon: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2473   score: 6.0   memory length: 642779   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 7.05\n",
      "episode: 2474   score: 6.0   memory length: 643131   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2475   score: 7.0   memory length: 643478   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2476   score: 5.0   memory length: 643782   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.94\n",
      "episode: 2477   score: 3.0   memory length: 644010   epsilon: 0.009998020008555413    steps: 228    lr: 4.0960000000000023e-07     evaluation reward: 6.87\n",
      "episode: 2478   score: 7.0   memory length: 644382   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 6.87\n",
      "episode: 2479   score: 6.0   memory length: 644718   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2480   score: 10.0   memory length: 645108   epsilon: 0.009998020008555413    steps: 390    lr: 4.0960000000000023e-07     evaluation reward: 6.89\n",
      "episode: 2481   score: 8.0   memory length: 645523   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2482   score: 6.0   memory length: 645859   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 6.87\n",
      "episode: 2483   score: 7.0   memory length: 646244   epsilon: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2484   score: 10.0   memory length: 646658   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 6.93\n",
      "episode: 2485   score: 7.0   memory length: 647041   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 6.95\n",
      "episode: 2486   score: 4.0   memory length: 647335   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 6.91\n",
      "episode: 2487   score: 5.0   memory length: 647620   epsilon: 0.009998020008555413    steps: 285    lr: 4.0960000000000023e-07     evaluation reward: 6.89\n",
      "episode: 2488   score: 9.0   memory length: 648074   epsilon: 0.009998020008555413    steps: 454    lr: 4.0960000000000023e-07     evaluation reward: 6.9\n",
      "episode: 2489   score: 5.0   memory length: 648378   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.87\n",
      "episode: 2490   score: 5.0   memory length: 648682   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.84\n",
      "episode: 2491   score: 8.0   memory length: 649096   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 6.85\n",
      "episode: 2492   score: 9.0   memory length: 649641   epsilon: 0.009998020008555413    steps: 545    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2493   score: 8.0   memory length: 650076   epsilon: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     evaluation reward: 6.87\n",
      "episode: 2494   score: 5.0   memory length: 650365   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 6.85\n",
      "episode: 2495   score: 14.0   memory length: 650885   epsilon: 0.009998020008555413    steps: 520    lr: 4.0960000000000023e-07     evaluation reward: 6.92\n",
      "episode: 2496   score: 8.0   memory length: 651325   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 6.91\n",
      "episode: 2497   score: 10.0   memory length: 651852   epsilon: 0.009998020008555413    steps: 527    lr: 4.0960000000000023e-07     evaluation reward: 6.93\n",
      "episode: 2498   score: 8.0   memory length: 652302   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 6.94\n",
      "episode: 2499   score: 9.0   memory length: 652790   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2500   score: 5.0   memory length: 653094   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2501   score: 8.0   memory length: 653552   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2502   score: 6.0   memory length: 653907   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2503   score: 8.0   memory length: 654340   epsilon: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     evaluation reward: 6.9\n",
      "episode: 2504   score: 7.0   memory length: 654717   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 6.92\n",
      "episode: 2505   score: 9.0   memory length: 655196   epsilon: 0.009998020008555413    steps: 479    lr: 4.0960000000000023e-07     evaluation reward: 6.9\n",
      "episode: 2506   score: 10.0   memory length: 655684   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 6.95\n",
      "episode: 2507   score: 6.0   memory length: 656036   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 6.95\n",
      "episode: 2508   score: 8.0   memory length: 656425   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2509   score: 8.0   memory length: 656851   epsilon: 0.009998020008555413    steps: 426    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2510   score: 5.0   memory length: 657155   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.98\n",
      "episode: 2511   score: 5.0   memory length: 657459   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2512   score: 8.0   memory length: 657871   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 6.99\n",
      "episode: 2513   score: 5.0   memory length: 658196   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 6.96\n",
      "episode: 2514   score: 8.0   memory length: 658654   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 7.01\n",
      "episode: 2515   score: 8.0   memory length: 659066   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2516   score: 8.0   memory length: 659483   epsilon: 0.009998020008555413    steps: 417    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2517   score: 5.0   memory length: 659787   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.98\n",
      "episode: 2518   score: 4.0   memory length: 660061   epsilon: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2519   score: 5.0   memory length: 660365   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2520   score: 8.0   memory length: 660777   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 6.99\n",
      "episode: 2521   score: 8.0   memory length: 661204   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2522   score: 10.0   memory length: 661729   epsilon: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2523   score: 6.0   memory length: 662102   epsilon: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2524   score: 10.0   memory length: 662516   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2525   score: 12.0   memory length: 663104   epsilon: 0.009998020008555413    steps: 588    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2526   score: 5.0   memory length: 663429   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 7.01\n",
      "episode: 2527   score: 8.0   memory length: 663889   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2528   score: 11.0   memory length: 664334   epsilon: 0.009998020008555413    steps: 445    lr: 4.0960000000000023e-07     evaluation reward: 7.08\n",
      "episode: 2529   score: 10.0   memory length: 664748   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2530   score: 7.0   memory length: 665126   epsilon: 0.009998020008555413    steps: 378    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2531   score: 7.0   memory length: 665509   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2532   score: 6.0   memory length: 665864   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2533   score: 7.0   memory length: 666247   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2534   score: 5.0   memory length: 666551   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.09\n",
      "episode: 2535   score: 5.0   memory length: 666855   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2536   score: 5.0   memory length: 667161   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.05\n",
      "episode: 2537   score: 7.0   memory length: 667547   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.04\n",
      "episode: 2538   score: 10.0   memory length: 667933   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2539   score: 10.0   memory length: 668458   epsilon: 0.009998020008555413    steps: 525    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2540   score: 7.0   memory length: 668805   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2541   score: 8.0   memory length: 669217   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 7.12\n",
      "episode: 2542   score: 9.0   memory length: 669678   epsilon: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2543   score: 7.0   memory length: 670084   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 7.17\n",
      "episode: 2544   score: 7.0   memory length: 670488   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 7.17\n",
      "episode: 2545   score: 6.0   memory length: 670843   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 7.19\n",
      "episode: 2546   score: 9.0   memory length: 671306   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 7.24\n",
      "episode: 2547   score: 8.0   memory length: 671735   epsilon: 0.009998020008555413    steps: 429    lr: 4.0960000000000023e-07     evaluation reward: 7.23\n",
      "episode: 2548   score: 5.0   memory length: 672081   epsilon: 0.009998020008555413    steps: 346    lr: 4.0960000000000023e-07     evaluation reward: 7.23\n",
      "episode: 2549   score: 5.0   memory length: 672368   epsilon: 0.009998020008555413    steps: 287    lr: 4.0960000000000023e-07     evaluation reward: 7.2\n",
      "episode: 2550   score: 5.0   memory length: 672674   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2551   score: 9.0   memory length: 673122   epsilon: 0.009998020008555413    steps: 448    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2552   score: 5.0   memory length: 673428   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.12\n",
      "episode: 2553   score: 11.0   memory length: 673855   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 7.15\n",
      "episode: 2554   score: 5.0   memory length: 674161   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2555   score: 7.0   memory length: 674529   epsilon: 0.009998020008555413    steps: 368    lr: 4.0960000000000023e-07     evaluation reward: 7.13\n",
      "episode: 2556   score: 6.0   memory length: 674868   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 7.11\n",
      "episode: 2557   score: 7.0   memory length: 675215   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 7.09\n",
      "episode: 2558   score: 5.0   memory length: 675508   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 7.09\n",
      "episode: 2559   score: 9.0   memory length: 675951   epsilon: 0.009998020008555413    steps: 443    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2560   score: 7.0   memory length: 676298   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 7.07\n",
      "episode: 2561   score: 3.0   memory length: 676506   epsilon: 0.009998020008555413    steps: 208    lr: 4.0960000000000023e-07     evaluation reward: 7.05\n",
      "episode: 2562   score: 7.0   memory length: 676892   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2563   score: 5.0   memory length: 677199   epsilon: 0.009998020008555413    steps: 307    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2564   score: 8.0   memory length: 677639   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2565   score: 10.0   memory length: 678037   epsilon: 0.009998020008555413    steps: 398    lr: 4.0960000000000023e-07     evaluation reward: 7.14\n",
      "episode: 2566   score: 12.0   memory length: 678530   epsilon: 0.009998020008555413    steps: 493    lr: 4.0960000000000023e-07     evaluation reward: 7.21\n",
      "episode: 2567   score: 9.0   memory length: 679043   epsilon: 0.009998020008555413    steps: 513    lr: 4.0960000000000023e-07     evaluation reward: 7.25\n",
      "episode: 2568   score: 7.0   memory length: 679446   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 7.23\n",
      "episode: 2569   score: 12.0   memory length: 680061   epsilon: 0.009998020008555413    steps: 615    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2570   score: 8.0   memory length: 680479   epsilon: 0.009998020008555413    steps: 418    lr: 4.0960000000000023e-07     evaluation reward: 7.3\n",
      "episode: 2571   score: 8.0   memory length: 680894   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2572   score: 7.0   memory length: 681280   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2573   score: 7.0   memory length: 681668   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.32\n",
      "episode: 2574   score: 8.0   memory length: 682138   epsilon: 0.009998020008555413    steps: 470    lr: 4.0960000000000023e-07     evaluation reward: 7.34\n",
      "episode: 2575   score: 8.0   memory length: 682578   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 7.35\n",
      "episode: 2576   score: 4.0   memory length: 682837   epsilon: 0.009998020008555413    steps: 259    lr: 4.0960000000000023e-07     evaluation reward: 7.34\n",
      "episode: 2577   score: 11.0   memory length: 683387   epsilon: 0.009998020008555413    steps: 550    lr: 4.0960000000000023e-07     evaluation reward: 7.42\n",
      "episode: 2578   score: 5.0   memory length: 683693   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.4\n",
      "episode: 2579   score: 4.0   memory length: 683952   epsilon: 0.009998020008555413    steps: 259    lr: 4.0960000000000023e-07     evaluation reward: 7.38\n",
      "episode: 2580   score: 7.0   memory length: 684337   epsilon: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     evaluation reward: 7.35\n",
      "episode: 2581   score: 10.0   memory length: 684825   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 7.37\n",
      "episode: 2582   score: 8.0   memory length: 685304   epsilon: 0.009998020008555413    steps: 479    lr: 4.0960000000000023e-07     evaluation reward: 7.39\n",
      "episode: 2583   score: 5.0   memory length: 685610   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 7.37\n",
      "episode: 2584   score: 6.0   memory length: 685946   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2585   score: 7.0   memory length: 686394   epsilon: 0.009998020008555413    steps: 448    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2586   score: 4.0   memory length: 686668   epsilon: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2587   score: 8.0   memory length: 687097   epsilon: 0.009998020008555413    steps: 429    lr: 4.0960000000000023e-07     evaluation reward: 7.36\n",
      "episode: 2588   score: 8.0   memory length: 687511   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 7.35\n",
      "episode: 2589   score: 6.0   memory length: 687847   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 7.36\n",
      "episode: 2590   score: 6.0   memory length: 688169   epsilon: 0.009998020008555413    steps: 322    lr: 4.0960000000000023e-07     evaluation reward: 7.37\n",
      "episode: 2591   score: 10.0   memory length: 688583   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 7.39\n",
      "episode: 2592   score: 9.0   memory length: 689053   epsilon: 0.009998020008555413    steps: 470    lr: 4.0960000000000023e-07     evaluation reward: 7.39\n",
      "episode: 2593   score: 8.0   memory length: 689516   epsilon: 0.009998020008555413    steps: 463    lr: 4.0960000000000023e-07     evaluation reward: 7.39\n",
      "episode: 2594   score: 9.0   memory length: 689954   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 7.43\n",
      "episode: 2595   score: 4.0   memory length: 690214   epsilon: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2596   score: 10.0   memory length: 690727   epsilon: 0.009998020008555413    steps: 513    lr: 4.0960000000000023e-07     evaluation reward: 7.35\n",
      "episode: 2597   score: 7.0   memory length: 691113   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.32\n",
      "episode: 2598   score: 4.0   memory length: 691369   epsilon: 0.009998020008555413    steps: 256    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2599   score: 6.0   memory length: 691743   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 7.25\n",
      "episode: 2600   score: 7.0   memory length: 692133   epsilon: 0.009998020008555413    steps: 390    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2601   score: 13.0   memory length: 692634   epsilon: 0.009998020008555413    steps: 501    lr: 4.0960000000000023e-07     evaluation reward: 7.32\n",
      "episode: 2602   score: 7.0   memory length: 693022   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2603   score: 3.0   memory length: 693230   epsilon: 0.009998020008555413    steps: 208    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2604   score: 7.0   memory length: 693618   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2605   score: 3.0   memory length: 693826   epsilon: 0.009998020008555413    steps: 208    lr: 4.0960000000000023e-07     evaluation reward: 7.22\n",
      "episode: 2606   score: 7.0   memory length: 694214   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 7.19\n",
      "episode: 2607   score: 7.0   memory length: 694600   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 7.2\n",
      "episode: 2608   score: 7.0   memory length: 695003   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 7.19\n",
      "episode: 2609   score: 10.0   memory length: 695550   epsilon: 0.009998020008555413    steps: 547    lr: 4.0960000000000023e-07     evaluation reward: 7.21\n",
      "episode: 2610   score: 10.0   memory length: 696040   epsilon: 0.009998020008555413    steps: 490    lr: 4.0960000000000023e-07     evaluation reward: 7.26\n",
      "episode: 2611   score: 5.0   memory length: 696327   epsilon: 0.009998020008555413    steps: 287    lr: 4.0960000000000023e-07     evaluation reward: 7.26\n",
      "episode: 2612   score: 5.0   memory length: 696654   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 7.23\n",
      "episode: 2613   score: 10.0   memory length: 697142   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2614   score: 7.0   memory length: 697509   epsilon: 0.009998020008555413    steps: 367    lr: 4.0960000000000023e-07     evaluation reward: 7.27\n",
      "episode: 2615   score: 9.0   memory length: 697989   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 7.28\n",
      "episode: 2616   score: 11.0   memory length: 698519   epsilon: 0.009998020008555413    steps: 530    lr: 4.0960000000000023e-07     evaluation reward: 7.31\n",
      "episode: 2617   score: 7.0   memory length: 698866   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 7.33\n",
      "episode: 2618   score: 8.0   memory length: 699278   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 7.37\n",
      "episode: 2619   score: 8.0   memory length: 699718   epsilon: 0.009998020008555413    steps: 440    lr: 4.0960000000000023e-07     evaluation reward: 7.4\n",
      "episode: 2620   score: 8.0   memory length: 700161   epsilon: 0.009998020008555413    steps: 443    lr: 1.638400000000001e-07     evaluation reward: 7.4\n",
      "episode: 2621   score: 8.0   memory length: 700643   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.4\n",
      "episode: 2622   score: 8.0   memory length: 701125   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.38\n",
      "episode: 2623   score: 8.0   memory length: 701562   epsilon: 0.009998020008555413    steps: 437    lr: 1.638400000000001e-07     evaluation reward: 7.4\n",
      "episode: 2624   score: 9.0   memory length: 702021   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.39\n",
      "episode: 2625   score: 8.0   memory length: 702461   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 7.35\n",
      "episode: 2626   score: 7.0   memory length: 702849   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 7.37\n",
      "episode: 2627   score: 8.0   memory length: 703286   epsilon: 0.009998020008555413    steps: 437    lr: 1.638400000000001e-07     evaluation reward: 7.37\n",
      "episode: 2628   score: 8.0   memory length: 703712   epsilon: 0.009998020008555413    steps: 426    lr: 1.638400000000001e-07     evaluation reward: 7.34\n",
      "episode: 2629   score: 9.0   memory length: 704231   epsilon: 0.009998020008555413    steps: 519    lr: 1.638400000000001e-07     evaluation reward: 7.33\n",
      "episode: 2630   score: 9.0   memory length: 704704   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 7.35\n",
      "episode: 2631   score: 5.0   memory length: 705011   epsilon: 0.009998020008555413    steps: 307    lr: 1.638400000000001e-07     evaluation reward: 7.33\n",
      "episode: 2632   score: 6.0   memory length: 705347   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 7.33\n",
      "episode: 2633   score: 8.0   memory length: 705773   epsilon: 0.009998020008555413    steps: 426    lr: 1.638400000000001e-07     evaluation reward: 7.34\n",
      "episode: 2634   score: 8.0   memory length: 706264   epsilon: 0.009998020008555413    steps: 491    lr: 1.638400000000001e-07     evaluation reward: 7.37\n",
      "episode: 2635   score: 6.0   memory length: 706601   epsilon: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     evaluation reward: 7.38\n",
      "episode: 2636   score: 8.0   memory length: 707019   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.41\n",
      "episode: 2637   score: 7.0   memory length: 707408   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 7.41\n",
      "episode: 2638   score: 3.0   memory length: 707616   epsilon: 0.009998020008555413    steps: 208    lr: 1.638400000000001e-07     evaluation reward: 7.34\n",
      "episode: 2639   score: 11.0   memory length: 708031   epsilon: 0.009998020008555413    steps: 415    lr: 1.638400000000001e-07     evaluation reward: 7.35\n",
      "episode: 2640   score: 11.0   memory length: 708550   epsilon: 0.009998020008555413    steps: 519    lr: 1.638400000000001e-07     evaluation reward: 7.39\n",
      "episode: 2641   score: 9.0   memory length: 709043   epsilon: 0.009998020008555413    steps: 493    lr: 1.638400000000001e-07     evaluation reward: 7.4\n",
      "episode: 2642   score: 9.0   memory length: 709530   epsilon: 0.009998020008555413    steps: 487    lr: 1.638400000000001e-07     evaluation reward: 7.4\n",
      "episode: 2643   score: 5.0   memory length: 709871   epsilon: 0.009998020008555413    steps: 341    lr: 1.638400000000001e-07     evaluation reward: 7.38\n",
      "episode: 2644   score: 14.0   memory length: 710412   epsilon: 0.009998020008555413    steps: 541    lr: 1.638400000000001e-07     evaluation reward: 7.45\n",
      "episode: 2645   score: 8.0   memory length: 710894   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.47\n",
      "episode: 2646   score: 9.0   memory length: 711404   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 7.47\n",
      "episode: 2647   score: 12.0   memory length: 711874   epsilon: 0.009998020008555413    steps: 470    lr: 1.638400000000001e-07     evaluation reward: 7.51\n",
      "episode: 2648   score: 8.0   memory length: 712292   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.54\n",
      "episode: 2649   score: 7.0   memory length: 712740   epsilon: 0.009998020008555413    steps: 448    lr: 1.638400000000001e-07     evaluation reward: 7.56\n",
      "episode: 2650   score: 9.0   memory length: 713215   epsilon: 0.009998020008555413    steps: 475    lr: 1.638400000000001e-07     evaluation reward: 7.6\n",
      "episode: 2651   score: 9.0   memory length: 713718   epsilon: 0.009998020008555413    steps: 503    lr: 1.638400000000001e-07     evaluation reward: 7.6\n",
      "episode: 2652   score: 10.0   memory length: 714176   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2653   score: 5.0   memory length: 714465   epsilon: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     evaluation reward: 7.59\n",
      "episode: 2654   score: 8.0   memory length: 714905   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2655   score: 3.0   memory length: 715113   epsilon: 0.009998020008555413    steps: 208    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2656   score: 6.0   memory length: 715490   epsilon: 0.009998020008555413    steps: 377    lr: 1.638400000000001e-07     evaluation reward: 7.58\n",
      "episode: 2657   score: 8.0   memory length: 715908   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.59\n",
      "episode: 2658   score: 8.0   memory length: 716390   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2659   score: 9.0   memory length: 716912   epsilon: 0.009998020008555413    steps: 522    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2660   score: 9.0   memory length: 717397   epsilon: 0.009998020008555413    steps: 485    lr: 1.638400000000001e-07     evaluation reward: 7.64\n",
      "episode: 2661   score: 9.0   memory length: 717864   epsilon: 0.009998020008555413    steps: 467    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2662   score: 8.0   memory length: 718346   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2663   score: 6.0   memory length: 718698   epsilon: 0.009998020008555413    steps: 352    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2664   score: 12.0   memory length: 719182   epsilon: 0.009998020008555413    steps: 484    lr: 1.638400000000001e-07     evaluation reward: 7.76\n",
      "episode: 2665   score: 9.0   memory length: 719649   epsilon: 0.009998020008555413    steps: 467    lr: 1.638400000000001e-07     evaluation reward: 7.75\n",
      "episode: 2666   score: 8.0   memory length: 720089   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2667   score: 4.0   memory length: 720346   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2668   score: 10.0   memory length: 720756   epsilon: 0.009998020008555413    steps: 410    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2669   score: 8.0   memory length: 721165   epsilon: 0.009998020008555413    steps: 409    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2670   score: 10.0   memory length: 721579   epsilon: 0.009998020008555413    steps: 414    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2671   score: 7.0   memory length: 722007   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2672   score: 8.0   memory length: 722464   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2673   score: 7.0   memory length: 722884   epsilon: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2674   score: 8.0   memory length: 723335   epsilon: 0.009998020008555413    steps: 451    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2675   score: 6.0   memory length: 723709   epsilon: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2676   score: 8.0   memory length: 724166   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2677   score: 8.0   memory length: 724584   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.66\n",
      "episode: 2678   score: 8.0   memory length: 725010   epsilon: 0.009998020008555413    steps: 426    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2679   score: 8.0   memory length: 725439   epsilon: 0.009998020008555413    steps: 429    lr: 1.638400000000001e-07     evaluation reward: 7.73\n",
      "episode: 2680   score: 11.0   memory length: 725969   epsilon: 0.009998020008555413    steps: 530    lr: 1.638400000000001e-07     evaluation reward: 7.77\n",
      "episode: 2681   score: 7.0   memory length: 726357   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 7.74\n",
      "episode: 2682   score: 6.0   memory length: 726710   epsilon: 0.009998020008555413    steps: 353    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2683   score: 9.0   memory length: 727214   epsilon: 0.009998020008555413    steps: 504    lr: 1.638400000000001e-07     evaluation reward: 7.76\n",
      "episode: 2684   score: 9.0   memory length: 727723   epsilon: 0.009998020008555413    steps: 509    lr: 1.638400000000001e-07     evaluation reward: 7.79\n",
      "episode: 2685   score: 8.0   memory length: 728182   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 7.8\n",
      "episode: 2686   score: 10.0   memory length: 728692   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2687   score: 6.0   memory length: 729044   epsilon: 0.009998020008555413    steps: 352    lr: 1.638400000000001e-07     evaluation reward: 7.84\n",
      "episode: 2688   score: 7.0   memory length: 729430   epsilon: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     evaluation reward: 7.83\n",
      "episode: 2689   score: 8.0   memory length: 729909   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 7.85\n",
      "episode: 2690   score: 8.0   memory length: 730372   epsilon: 0.009998020008555413    steps: 463    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2691   score: 9.0   memory length: 730882   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2692   score: 10.0   memory length: 731382   epsilon: 0.009998020008555413    steps: 500    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2693   score: 6.0   memory length: 731778   epsilon: 0.009998020008555413    steps: 396    lr: 1.638400000000001e-07     evaluation reward: 7.85\n",
      "episode: 2694   score: 11.0   memory length: 732326   epsilon: 0.009998020008555413    steps: 548    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2695   score: 11.0   memory length: 732784   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 7.94\n",
      "episode: 2696   score: 5.0   memory length: 733092   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 7.89\n",
      "episode: 2697   score: 9.0   memory length: 733546   epsilon: 0.009998020008555413    steps: 454    lr: 1.638400000000001e-07     evaluation reward: 7.91\n",
      "episode: 2698   score: 8.0   memory length: 733935   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 7.95\n",
      "episode: 2699   score: 6.0   memory length: 734289   epsilon: 0.009998020008555413    steps: 354    lr: 1.638400000000001e-07     evaluation reward: 7.95\n",
      "episode: 2700   score: 4.0   memory length: 734546   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 7.92\n",
      "episode: 2701   score: 8.0   memory length: 734964   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.87\n",
      "episode: 2702   score: 11.0   memory length: 735494   epsilon: 0.009998020008555413    steps: 530    lr: 1.638400000000001e-07     evaluation reward: 7.91\n",
      "episode: 2703   score: 8.0   memory length: 735951   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 7.96\n",
      "episode: 2704   score: 11.0   memory length: 736373   epsilon: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     evaluation reward: 8.0\n",
      "episode: 2705   score: 11.0   memory length: 736831   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 8.08\n",
      "episode: 2706   score: 7.0   memory length: 737217   epsilon: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     evaluation reward: 8.08\n",
      "episode: 2707   score: 8.0   memory length: 737699   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 8.09\n",
      "episode: 2708   score: 14.0   memory length: 738239   epsilon: 0.009998020008555413    steps: 540    lr: 1.638400000000001e-07     evaluation reward: 8.16\n",
      "episode: 2709   score: 14.0   memory length: 738802   epsilon: 0.009998020008555413    steps: 563    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2710   score: 10.0   memory length: 739336   epsilon: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2711   score: 9.0   memory length: 739834   epsilon: 0.009998020008555413    steps: 498    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2712   score: 8.0   memory length: 740252   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 8.27\n",
      "episode: 2713   score: 7.0   memory length: 740626   epsilon: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2714   score: 13.0   memory length: 741247   epsilon: 0.009998020008555413    steps: 621    lr: 1.638400000000001e-07     evaluation reward: 8.3\n",
      "episode: 2715   score: 5.0   memory length: 741555   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2716   score: 8.0   memory length: 742034   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 8.23\n",
      "episode: 2717   score: 11.0   memory length: 742575   epsilon: 0.009998020008555413    steps: 541    lr: 1.638400000000001e-07     evaluation reward: 8.27\n",
      "episode: 2718   score: 9.0   memory length: 743013   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2719   score: 8.0   memory length: 743447   epsilon: 0.009998020008555413    steps: 434    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2720   score: 5.0   memory length: 743753   epsilon: 0.009998020008555413    steps: 306    lr: 1.638400000000001e-07     evaluation reward: 8.25\n",
      "episode: 2721   score: 12.0   memory length: 744155   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2722   score: 8.0   memory length: 744632   epsilon: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2723   score: 6.0   memory length: 744991   epsilon: 0.009998020008555413    steps: 359    lr: 1.638400000000001e-07     evaluation reward: 8.27\n",
      "episode: 2724   score: 6.0   memory length: 745345   epsilon: 0.009998020008555413    steps: 354    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2725   score: 10.0   memory length: 745833   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2726   score: 9.0   memory length: 746325   epsilon: 0.009998020008555413    steps: 492    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2727   score: 10.0   memory length: 746820   epsilon: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     evaluation reward: 8.3\n",
      "episode: 2728   score: 10.0   memory length: 747308   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 8.32\n",
      "episode: 2729   score: 10.0   memory length: 747813   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 8.33\n",
      "episode: 2730   score: 9.0   memory length: 748311   epsilon: 0.009998020008555413    steps: 498    lr: 1.638400000000001e-07     evaluation reward: 8.33\n",
      "episode: 2731   score: 5.0   memory length: 748637   epsilon: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     evaluation reward: 8.33\n",
      "episode: 2732   score: 7.0   memory length: 749039   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 8.34\n",
      "episode: 2733   score: 5.0   memory length: 749366   epsilon: 0.009998020008555413    steps: 327    lr: 1.638400000000001e-07     evaluation reward: 8.31\n",
      "episode: 2734   score: 8.0   memory length: 749845   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 8.31\n",
      "episode: 2735   score: 8.0   memory length: 750263   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 8.33\n",
      "episode: 2736   score: 10.0   memory length: 750753   epsilon: 0.009998020008555413    steps: 490    lr: 1.638400000000001e-07     evaluation reward: 8.35\n",
      "episode: 2737   score: 7.0   memory length: 751139   epsilon: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     evaluation reward: 8.35\n",
      "episode: 2738   score: 10.0   memory length: 751627   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 8.42\n",
      "episode: 2739   score: 7.0   memory length: 752026   epsilon: 0.009998020008555413    steps: 399    lr: 1.638400000000001e-07     evaluation reward: 8.38\n",
      "episode: 2740   score: 8.0   memory length: 752464   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.35\n",
      "episode: 2741   score: 8.0   memory length: 752896   epsilon: 0.009998020008555413    steps: 432    lr: 1.638400000000001e-07     evaluation reward: 8.34\n",
      "episode: 2742   score: 7.0   memory length: 753277   epsilon: 0.009998020008555413    steps: 381    lr: 1.638400000000001e-07     evaluation reward: 8.32\n",
      "episode: 2743   score: 8.0   memory length: 753736   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.35\n",
      "episode: 2744   score: 4.0   memory length: 753992   epsilon: 0.009998020008555413    steps: 256    lr: 1.638400000000001e-07     evaluation reward: 8.25\n",
      "episode: 2745   score: 6.0   memory length: 754328   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 8.23\n",
      "episode: 2746   score: 6.0   memory length: 754681   epsilon: 0.009998020008555413    steps: 353    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2747   score: 4.0   memory length: 754938   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2748   score: 6.0   memory length: 755274   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2749   score: 7.0   memory length: 755681   epsilon: 0.009998020008555413    steps: 407    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2750   score: 7.0   memory length: 756103   epsilon: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     evaluation reward: 8.08\n",
      "episode: 2751   score: 7.0   memory length: 756502   epsilon: 0.009998020008555413    steps: 399    lr: 1.638400000000001e-07     evaluation reward: 8.06\n",
      "episode: 2752   score: 9.0   memory length: 757012   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 8.05\n",
      "episode: 2753   score: 10.0   memory length: 757529   epsilon: 0.009998020008555413    steps: 517    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2754   score: 8.0   memory length: 757988   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2755   score: 11.0   memory length: 758536   epsilon: 0.009998020008555413    steps: 548    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2756   score: 5.0   memory length: 758844   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 8.17\n",
      "episode: 2757   score: 8.0   memory length: 759302   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 8.17\n",
      "episode: 2758   score: 8.0   memory length: 759761   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.17\n",
      "episode: 2759   score: 6.0   memory length: 760097   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 8.14\n",
      "episode: 2760   score: 8.0   memory length: 760556   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.13\n",
      "episode: 2761   score: 8.0   memory length: 760994   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2762   score: 8.0   memory length: 761432   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2763   score: 9.0   memory length: 761870   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.15\n",
      "episode: 2764   score: 8.0   memory length: 762310   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 8.11\n",
      "episode: 2765   score: 8.0   memory length: 762750   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2766   score: 7.0   memory length: 763153   epsilon: 0.009998020008555413    steps: 403    lr: 1.638400000000001e-07     evaluation reward: 8.09\n",
      "episode: 2767   score: 7.0   memory length: 763559   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2768   score: 8.0   memory length: 763987   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2769   score: 10.0   memory length: 764500   epsilon: 0.009998020008555413    steps: 513    lr: 1.638400000000001e-07     evaluation reward: 8.12\n",
      "episode: 2770   score: 8.0   memory length: 764957   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 8.1\n",
      "episode: 2771   score: 8.0   memory length: 765375   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 8.11\n",
      "episode: 2772   score: 8.0   memory length: 765803   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.11\n",
      "episode: 2773   score: 9.0   memory length: 766241   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.13\n",
      "episode: 2774   score: 9.0   memory length: 766707   epsilon: 0.009998020008555413    steps: 466    lr: 1.638400000000001e-07     evaluation reward: 8.14\n",
      "episode: 2775   score: 12.0   memory length: 767306   epsilon: 0.009998020008555413    steps: 599    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2776   score: 6.0   memory length: 767664   epsilon: 0.009998020008555413    steps: 358    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2777   score: 7.0   memory length: 768093   epsilon: 0.009998020008555413    steps: 429    lr: 1.638400000000001e-07     evaluation reward: 8.17\n",
      "episode: 2778   score: 12.0   memory length: 768545   epsilon: 0.009998020008555413    steps: 452    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2779   score: 8.0   memory length: 768952   epsilon: 0.009998020008555413    steps: 407    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2780   score: 9.0   memory length: 769449   epsilon: 0.009998020008555413    steps: 497    lr: 1.638400000000001e-07     evaluation reward: 8.19\n",
      "episode: 2781   score: 8.0   memory length: 769908   epsilon: 0.009998020008555413    steps: 459    lr: 1.638400000000001e-07     evaluation reward: 8.2\n",
      "episode: 2782   score: 14.0   memory length: 770485   epsilon: 0.009998020008555413    steps: 577    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2783   score: 7.0   memory length: 770888   epsilon: 0.009998020008555413    steps: 403    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2784   score: 9.0   memory length: 771391   epsilon: 0.009998020008555413    steps: 503    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2785   score: 10.0   memory length: 771804   epsilon: 0.009998020008555413    steps: 413    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2786   score: 6.0   memory length: 772175   epsilon: 0.009998020008555413    steps: 371    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2787   score: 8.0   memory length: 772633   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2788   score: 10.0   memory length: 773139   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 8.29\n",
      "episode: 2789   score: 6.0   memory length: 773459   epsilon: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     evaluation reward: 8.27\n",
      "episode: 2790   score: 7.0   memory length: 773817   epsilon: 0.009998020008555413    steps: 358    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2791   score: 9.0   memory length: 774274   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2792   score: 7.0   memory length: 774722   epsilon: 0.009998020008555413    steps: 448    lr: 1.638400000000001e-07     evaluation reward: 8.23\n",
      "episode: 2793   score: 9.0   memory length: 775224   epsilon: 0.009998020008555413    steps: 502    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2794   score: 6.0   memory length: 775560   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2795   score: 8.0   memory length: 775995   epsilon: 0.009998020008555413    steps: 435    lr: 1.638400000000001e-07     evaluation reward: 8.18\n",
      "episode: 2796   score: 8.0   memory length: 776416   epsilon: 0.009998020008555413    steps: 421    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2797   score: 9.0   memory length: 776913   epsilon: 0.009998020008555413    steps: 497    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2798   score: 9.0   memory length: 777423   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 8.22\n",
      "episode: 2799   score: 10.0   memory length: 777923   epsilon: 0.009998020008555413    steps: 500    lr: 1.638400000000001e-07     evaluation reward: 8.26\n",
      "episode: 2800   score: 10.0   memory length: 778423   epsilon: 0.009998020008555413    steps: 500    lr: 1.638400000000001e-07     evaluation reward: 8.32\n",
      "episode: 2801   score: 7.0   memory length: 778791   epsilon: 0.009998020008555413    steps: 368    lr: 1.638400000000001e-07     evaluation reward: 8.31\n",
      "episode: 2802   score: 7.0   memory length: 779156   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 8.27\n",
      "episode: 2803   score: 9.0   memory length: 779666   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 8.28\n",
      "episode: 2804   score: 7.0   memory length: 780035   epsilon: 0.009998020008555413    steps: 369    lr: 1.638400000000001e-07     evaluation reward: 8.24\n",
      "episode: 2805   score: 10.0   memory length: 780523   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 8.23\n",
      "episode: 2806   score: 6.0   memory length: 780859   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 8.22\n",
      "episode: 2807   score: 7.0   memory length: 781247   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 8.21\n",
      "episode: 2808   score: 7.0   memory length: 781651   epsilon: 0.009998020008555413    steps: 404    lr: 1.638400000000001e-07     evaluation reward: 8.14\n",
      "episode: 2809   score: 7.0   memory length: 782033   epsilon: 0.009998020008555413    steps: 382    lr: 1.638400000000001e-07     evaluation reward: 8.07\n",
      "episode: 2810   score: 7.0   memory length: 782424   epsilon: 0.009998020008555413    steps: 391    lr: 1.638400000000001e-07     evaluation reward: 8.04\n",
      "episode: 2811   score: 4.0   memory length: 782681   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 7.99\n",
      "episode: 2812   score: 6.0   memory length: 783016   epsilon: 0.009998020008555413    steps: 335    lr: 1.638400000000001e-07     evaluation reward: 7.97\n",
      "episode: 2813   score: 6.0   memory length: 783344   epsilon: 0.009998020008555413    steps: 328    lr: 1.638400000000001e-07     evaluation reward: 7.96\n",
      "episode: 2814   score: 5.0   memory length: 783652   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 7.88\n",
      "episode: 2815   score: 8.0   memory length: 784126   epsilon: 0.009998020008555413    steps: 474    lr: 1.638400000000001e-07     evaluation reward: 7.91\n",
      "episode: 2816   score: 10.0   memory length: 784644   epsilon: 0.009998020008555413    steps: 518    lr: 1.638400000000001e-07     evaluation reward: 7.93\n",
      "episode: 2817   score: 10.0   memory length: 785150   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 7.92\n",
      "episode: 2818   score: 7.0   memory length: 785554   epsilon: 0.009998020008555413    steps: 404    lr: 1.638400000000001e-07     evaluation reward: 7.9\n",
      "episode: 2819   score: 4.0   memory length: 785811   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2820   score: 7.0   memory length: 786214   epsilon: 0.009998020008555413    steps: 403    lr: 1.638400000000001e-07     evaluation reward: 7.88\n",
      "episode: 2821   score: 10.0   memory length: 786702   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 7.86\n",
      "episode: 2822   score: 5.0   memory length: 786971   epsilon: 0.009998020008555413    steps: 269    lr: 1.638400000000001e-07     evaluation reward: 7.83\n",
      "episode: 2823   score: 8.0   memory length: 787424   epsilon: 0.009998020008555413    steps: 453    lr: 1.638400000000001e-07     evaluation reward: 7.85\n",
      "episode: 2824   score: 4.0   memory length: 787680   epsilon: 0.009998020008555413    steps: 256    lr: 1.638400000000001e-07     evaluation reward: 7.83\n",
      "episode: 2825   score: 8.0   memory length: 788098   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 7.81\n",
      "episode: 2826   score: 4.0   memory length: 788355   epsilon: 0.009998020008555413    steps: 257    lr: 1.638400000000001e-07     evaluation reward: 7.76\n",
      "episode: 2827   score: 5.0   memory length: 788642   epsilon: 0.009998020008555413    steps: 287    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2828   score: 6.0   memory length: 788979   epsilon: 0.009998020008555413    steps: 337    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2829   score: 6.0   memory length: 789295   epsilon: 0.009998020008555413    steps: 316    lr: 1.638400000000001e-07     evaluation reward: 7.63\n",
      "episode: 2830   score: 7.0   memory length: 789678   epsilon: 0.009998020008555413    steps: 383    lr: 1.638400000000001e-07     evaluation reward: 7.61\n",
      "episode: 2831   score: 9.0   memory length: 790157   epsilon: 0.009998020008555413    steps: 479    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2832   score: 6.0   memory length: 790493   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 7.64\n",
      "episode: 2833   score: 6.0   memory length: 790851   epsilon: 0.009998020008555413    steps: 358    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2834   score: 10.0   memory length: 791315   epsilon: 0.009998020008555413    steps: 464    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2835   score: 6.0   memory length: 791651   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 7.65\n",
      "episode: 2836   score: 7.0   memory length: 792046   epsilon: 0.009998020008555413    steps: 395    lr: 1.638400000000001e-07     evaluation reward: 7.62\n",
      "episode: 2837   score: 14.0   memory length: 792472   epsilon: 0.009998020008555413    steps: 426    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2838   score: 9.0   memory length: 792977   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2839   score: 11.0   memory length: 793506   epsilon: 0.009998020008555413    steps: 529    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2840   score: 5.0   memory length: 793832   epsilon: 0.009998020008555413    steps: 326    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2841   score: 8.0   memory length: 794229   epsilon: 0.009998020008555413    steps: 397    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2842   score: 7.0   memory length: 794596   epsilon: 0.009998020008555413    steps: 367    lr: 1.638400000000001e-07     evaluation reward: 7.69\n",
      "episode: 2843   score: 6.0   memory length: 794935   epsilon: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2844   score: 7.0   memory length: 795364   epsilon: 0.009998020008555413    steps: 429    lr: 1.638400000000001e-07     evaluation reward: 7.7\n",
      "episode: 2845   score: 7.0   memory length: 795729   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2846   score: 6.0   memory length: 796065   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2847   score: 5.0   memory length: 796354   epsilon: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     evaluation reward: 7.72\n",
      "episode: 2848   score: 7.0   memory length: 796759   epsilon: 0.009998020008555413    steps: 405    lr: 1.638400000000001e-07     evaluation reward: 7.73\n",
      "episode: 2849   score: 9.0   memory length: 797231   epsilon: 0.009998020008555413    steps: 472    lr: 1.638400000000001e-07     evaluation reward: 7.75\n",
      "episode: 2850   score: 6.0   memory length: 797548   epsilon: 0.009998020008555413    steps: 317    lr: 1.638400000000001e-07     evaluation reward: 7.74\n",
      "episode: 2851   score: 7.0   memory length: 797953   epsilon: 0.009998020008555413    steps: 405    lr: 1.638400000000001e-07     evaluation reward: 7.74\n",
      "episode: 2852   score: 6.0   memory length: 798313   epsilon: 0.009998020008555413    steps: 360    lr: 1.638400000000001e-07     evaluation reward: 7.71\n",
      "episode: 2853   score: 6.0   memory length: 798628   epsilon: 0.009998020008555413    steps: 315    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2854   score: 9.0   memory length: 799083   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 7.68\n",
      "episode: 2855   score: 7.0   memory length: 799471   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 7.64\n",
      "episode: 2856   score: 8.0   memory length: 799908   epsilon: 0.009998020008555413    steps: 437    lr: 1.638400000000001e-07     evaluation reward: 7.67\n",
      "episode: 2857   score: 10.0   memory length: 800396   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 7.69\n",
      "episode: 2858   score: 4.0   memory length: 800655   epsilon: 0.009998020008555413    steps: 259    lr: 6.553600000000004e-08     evaluation reward: 7.65\n",
      "episode: 2859   score: 8.0   memory length: 801052   epsilon: 0.009998020008555413    steps: 397    lr: 6.553600000000004e-08     evaluation reward: 7.67\n",
      "episode: 2860   score: 8.0   memory length: 801449   epsilon: 0.009998020008555413    steps: 397    lr: 6.553600000000004e-08     evaluation reward: 7.67\n",
      "episode: 2861   score: 7.0   memory length: 801809   epsilon: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     evaluation reward: 7.66\n",
      "episode: 2862   score: 6.0   memory length: 802164   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.64\n",
      "episode: 2863   score: 8.0   memory length: 802561   epsilon: 0.009998020008555413    steps: 397    lr: 6.553600000000004e-08     evaluation reward: 7.63\n",
      "episode: 2864   score: 6.0   memory length: 802916   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.61\n",
      "episode: 2865   score: 7.0   memory length: 803281   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 7.6\n",
      "episode: 2866   score: 6.0   memory length: 803636   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.59\n",
      "episode: 2867   score: 10.0   memory length: 804144   epsilon: 0.009998020008555413    steps: 508    lr: 6.553600000000004e-08     evaluation reward: 7.62\n",
      "episode: 2868   score: 8.0   memory length: 804618   epsilon: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     evaluation reward: 7.62\n",
      "episode: 2869   score: 9.0   memory length: 805102   epsilon: 0.009998020008555413    steps: 484    lr: 6.553600000000004e-08     evaluation reward: 7.61\n",
      "episode: 2870   score: 8.0   memory length: 805560   epsilon: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     evaluation reward: 7.61\n",
      "episode: 2871   score: 9.0   memory length: 805995   epsilon: 0.009998020008555413    steps: 435    lr: 6.553600000000004e-08     evaluation reward: 7.62\n",
      "episode: 2872   score: 9.0   memory length: 806472   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 7.63\n",
      "episode: 2873   score: 10.0   memory length: 806960   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 7.64\n",
      "episode: 2874   score: 9.0   memory length: 807437   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 7.64\n",
      "episode: 2875   score: 9.0   memory length: 807947   epsilon: 0.009998020008555413    steps: 510    lr: 6.553600000000004e-08     evaluation reward: 7.61\n",
      "episode: 2876   score: 9.0   memory length: 808424   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 7.64\n",
      "episode: 2877   score: 7.0   memory length: 808853   epsilon: 0.009998020008555413    steps: 429    lr: 6.553600000000004e-08     evaluation reward: 7.64\n",
      "episode: 2878   score: 6.0   memory length: 809189   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.58\n",
      "episode: 2879   score: 7.0   memory length: 809554   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 7.57\n",
      "episode: 2880   score: 9.0   memory length: 810033   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 7.57\n",
      "episode: 2881   score: 9.0   memory length: 810499   epsilon: 0.009998020008555413    steps: 466    lr: 6.553600000000004e-08     evaluation reward: 7.58\n",
      "episode: 2882   score: 6.0   memory length: 810854   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.5\n",
      "episode: 2883   score: 6.0   memory length: 811209   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.49\n",
      "episode: 2884   score: 6.0   memory length: 811545   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.46\n",
      "episode: 2885   score: 6.0   memory length: 811881   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.42\n",
      "episode: 2886   score: 6.0   memory length: 812217   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.42\n",
      "episode: 2887   score: 6.0   memory length: 812553   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.4\n",
      "episode: 2888   score: 6.0   memory length: 812889   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.36\n",
      "episode: 2889   score: 6.0   memory length: 813225   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.36\n",
      "episode: 2890   score: 8.0   memory length: 813642   epsilon: 0.009998020008555413    steps: 417    lr: 6.553600000000004e-08     evaluation reward: 7.37\n",
      "episode: 2891   score: 6.0   memory length: 813978   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.34\n",
      "episode: 2892   score: 6.0   memory length: 814315   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 7.33\n",
      "episode: 2893   score: 6.0   memory length: 814651   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.3\n",
      "episode: 2894   score: 6.0   memory length: 814987   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.3\n",
      "episode: 2895   score: 5.0   memory length: 815276   epsilon: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     evaluation reward: 7.27\n",
      "episode: 2896   score: 6.0   memory length: 815612   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.25\n",
      "episode: 2897   score: 6.0   memory length: 815949   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 7.22\n",
      "episode: 2898   score: 5.0   memory length: 816273   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2899   score: 9.0   memory length: 816801   epsilon: 0.009998020008555413    steps: 528    lr: 6.553600000000004e-08     evaluation reward: 7.17\n",
      "episode: 2900   score: 7.0   memory length: 817221   epsilon: 0.009998020008555413    steps: 420    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 2901   score: 7.0   memory length: 817644   epsilon: 0.009998020008555413    steps: 423    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 2902   score: 9.0   memory length: 818151   epsilon: 0.009998020008555413    steps: 507    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 2903   score: 5.0   memory length: 818454   epsilon: 0.009998020008555413    steps: 303    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 2904   score: 13.0   memory length: 818914   epsilon: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2905   score: 10.0   memory length: 819438   epsilon: 0.009998020008555413    steps: 524    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2906   score: 6.0   memory length: 819774   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2907   score: 7.0   memory length: 820183   epsilon: 0.009998020008555413    steps: 409    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2908   score: 7.0   memory length: 820587   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.18\n",
      "episode: 2909   score: 6.0   memory length: 820923   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.17\n",
      "episode: 2910   score: 7.0   memory length: 821327   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.17\n",
      "episode: 2911   score: 6.0   memory length: 821682   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2912   score: 7.0   memory length: 822086   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.2\n",
      "episode: 2913   score: 9.0   memory length: 822571   epsilon: 0.009998020008555413    steps: 485    lr: 6.553600000000004e-08     evaluation reward: 7.23\n",
      "episode: 2914   score: 5.0   memory length: 822860   epsilon: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     evaluation reward: 7.23\n",
      "episode: 2915   score: 7.0   memory length: 823264   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.22\n",
      "episode: 2916   score: 7.0   memory length: 823668   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2917   score: 6.0   memory length: 823986   epsilon: 0.009998020008555413    steps: 318    lr: 6.553600000000004e-08     evaluation reward: 7.15\n",
      "episode: 2918   score: 6.0   memory length: 824302   epsilon: 0.009998020008555413    steps: 316    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 2919   score: 9.0   memory length: 824782   epsilon: 0.009998020008555413    steps: 480    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2920   score: 7.0   memory length: 825186   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2921   score: 7.0   memory length: 825590   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 2922   score: 9.0   memory length: 826028   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.2\n",
      "episode: 2923   score: 4.0   memory length: 826284   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 2924   score: 4.0   memory length: 826540   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 2925   score: 6.0   memory length: 826876   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 2926   score: 6.0   memory length: 827231   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 2927   score: 8.0   memory length: 827670   epsilon: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2928   score: 6.0   memory length: 828006   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2929   score: 7.0   memory length: 828371   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 7.2\n",
      "episode: 2930   score: 6.0   memory length: 828707   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 2931   score: 13.0   memory length: 829263   epsilon: 0.009998020008555413    steps: 556    lr: 6.553600000000004e-08     evaluation reward: 7.23\n",
      "episode: 2932   score: 6.0   memory length: 829581   epsilon: 0.009998020008555413    steps: 318    lr: 6.553600000000004e-08     evaluation reward: 7.23\n",
      "episode: 2933   score: 6.0   memory length: 829896   epsilon: 0.009998020008555413    steps: 315    lr: 6.553600000000004e-08     evaluation reward: 7.23\n",
      "episode: 2934   score: 8.0   memory length: 830354   epsilon: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     evaluation reward: 7.21\n",
      "episode: 2935   score: 5.0   memory length: 830641   epsilon: 0.009998020008555413    steps: 287    lr: 6.553600000000004e-08     evaluation reward: 7.2\n",
      "episode: 2936   score: 7.0   memory length: 831018   epsilon: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     evaluation reward: 7.2\n",
      "episode: 2937   score: 6.0   memory length: 831370   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 2938   score: 5.0   memory length: 831659   epsilon: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     evaluation reward: 7.08\n",
      "episode: 2939   score: 6.0   memory length: 832051   epsilon: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2940   score: 5.0   memory length: 832400   epsilon: 0.009998020008555413    steps: 349    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2941   score: 9.0   memory length: 832949   epsilon: 0.009998020008555413    steps: 549    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 2942   score: 6.0   memory length: 833285   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2943   score: 8.0   memory length: 833761   epsilon: 0.009998020008555413    steps: 476    lr: 6.553600000000004e-08     evaluation reward: 7.05\n",
      "episode: 2944   score: 7.0   memory length: 834126   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 7.05\n",
      "episode: 2945   score: 5.0   memory length: 834450   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2946   score: 6.0   memory length: 834786   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2947   score: 7.0   memory length: 835230   epsilon: 0.009998020008555413    steps: 444    lr: 6.553600000000004e-08     evaluation reward: 7.05\n",
      "episode: 2948   score: 8.0   memory length: 835704   epsilon: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     evaluation reward: 7.06\n",
      "episode: 2949   score: 7.0   memory length: 836126   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 2950   score: 6.0   memory length: 836462   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 2951   score: 6.0   memory length: 836798   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2952   score: 6.0   memory length: 837134   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 2953   score: 4.0   memory length: 837390   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 2954   score: 6.0   memory length: 837717   epsilon: 0.009998020008555413    steps: 327    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 2955   score: 6.0   memory length: 838109   epsilon: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 2956   score: 8.0   memory length: 838562   epsilon: 0.009998020008555413    steps: 453    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 2957   score: 10.0   memory length: 839050   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 2958   score: 9.0   memory length: 839576   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 2959   score: 6.0   memory length: 839934   epsilon: 0.009998020008555413    steps: 358    lr: 6.553600000000004e-08     evaluation reward: 7.0\n",
      "episode: 2960   score: 4.0   memory length: 840190   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 2961   score: 6.0   memory length: 840526   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.95\n",
      "episode: 2962   score: 10.0   memory length: 840916   epsilon: 0.009998020008555413    steps: 390    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 2963   score: 7.0   memory length: 841281   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 2964   score: 6.0   memory length: 841617   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 2965   score: 8.0   memory length: 842034   epsilon: 0.009998020008555413    steps: 417    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 2966   score: 6.0   memory length: 842370   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 2967   score: 8.0   memory length: 842646   epsilon: 0.009998020008555413    steps: 276    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 2968   score: 10.0   memory length: 843196   epsilon: 0.009998020008555413    steps: 550    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 2969   score: 6.0   memory length: 843532   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 2970   score: 8.0   memory length: 843967   epsilon: 0.009998020008555413    steps: 435    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 2971   score: 10.0   memory length: 844455   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 2972   score: 8.0   memory length: 844933   epsilon: 0.009998020008555413    steps: 478    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 2973   score: 6.0   memory length: 845269   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 2974   score: 9.0   memory length: 845707   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 2975   score: 6.0   memory length: 846043   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.89\n",
      "episode: 2976   score: 6.0   memory length: 846379   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.86\n",
      "episode: 2977   score: 6.0   memory length: 846715   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.85\n",
      "episode: 2978   score: 6.0   memory length: 847051   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.85\n",
      "episode: 2979   score: 6.0   memory length: 847387   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.84\n",
      "episode: 2980   score: 6.0   memory length: 847723   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.81\n",
      "episode: 2981   score: 9.0   memory length: 848189   epsilon: 0.009998020008555413    steps: 466    lr: 6.553600000000004e-08     evaluation reward: 6.81\n",
      "episode: 2982   score: 9.0   memory length: 848696   epsilon: 0.009998020008555413    steps: 507    lr: 6.553600000000004e-08     evaluation reward: 6.84\n",
      "episode: 2983   score: 6.0   memory length: 849035   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 6.84\n",
      "episode: 2984   score: 8.0   memory length: 849488   epsilon: 0.009998020008555413    steps: 453    lr: 6.553600000000004e-08     evaluation reward: 6.86\n",
      "episode: 2985   score: 9.0   memory length: 849954   epsilon: 0.009998020008555413    steps: 466    lr: 6.553600000000004e-08     evaluation reward: 6.89\n",
      "episode: 2986   score: 4.0   memory length: 850249   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 6.87\n",
      "episode: 2987   score: 6.0   memory length: 850623   epsilon: 0.009998020008555413    steps: 374    lr: 6.553600000000004e-08     evaluation reward: 6.87\n",
      "episode: 2988   score: 9.0   memory length: 851089   epsilon: 0.009998020008555413    steps: 466    lr: 6.553600000000004e-08     evaluation reward: 6.9\n",
      "episode: 2989   score: 7.0   memory length: 851513   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 6.91\n",
      "episode: 2990   score: 9.0   memory length: 852044   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 2991   score: 8.0   memory length: 852498   epsilon: 0.009998020008555413    steps: 454    lr: 6.553600000000004e-08     evaluation reward: 6.94\n",
      "episode: 2992   score: 5.0   memory length: 852846   epsilon: 0.009998020008555413    steps: 348    lr: 6.553600000000004e-08     evaluation reward: 6.93\n",
      "episode: 2993   score: 5.0   memory length: 853170   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 2994   score: 9.0   memory length: 853675   epsilon: 0.009998020008555413    steps: 505    lr: 6.553600000000004e-08     evaluation reward: 6.95\n",
      "episode: 2995   score: 6.0   memory length: 854011   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 2996   score: 8.0   memory length: 854428   epsilon: 0.009998020008555413    steps: 417    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 2997   score: 6.0   memory length: 854764   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 2998   score: 9.0   memory length: 855243   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 2999   score: 6.0   memory length: 855579   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 3000   score: 7.0   memory length: 855981   epsilon: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 3001   score: 10.0   memory length: 856481   epsilon: 0.009998020008555413    steps: 500    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3002   score: 9.0   memory length: 856947   epsilon: 0.009998020008555413    steps: 466    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3003   score: 9.0   memory length: 857385   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.06\n",
      "episode: 3004   score: 9.0   memory length: 857908   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3005   score: 8.0   memory length: 858346   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.0\n",
      "episode: 3006   score: 9.0   memory length: 858823   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 3007   score: 5.0   memory length: 859147   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3008   score: 6.0   memory length: 859525   epsilon: 0.009998020008555413    steps: 378    lr: 6.553600000000004e-08     evaluation reward: 7.0\n",
      "episode: 3009   score: 8.0   memory length: 859963   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3010   score: 4.0   memory length: 860258   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 3011   score: 5.0   memory length: 860581   epsilon: 0.009998020008555413    steps: 323    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 3012   score: 6.0   memory length: 860917   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 3013   score: 6.0   memory length: 861288   epsilon: 0.009998020008555413    steps: 371    lr: 6.553600000000004e-08     evaluation reward: 6.94\n",
      "episode: 3014   score: 6.0   memory length: 861624   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.95\n",
      "episode: 3015   score: 10.0   memory length: 862109   epsilon: 0.009998020008555413    steps: 485    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 3016   score: 5.0   memory length: 862398   epsilon: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 3017   score: 6.0   memory length: 862734   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 3018   score: 6.0   memory length: 863070   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.96\n",
      "episode: 3019   score: 6.0   memory length: 863406   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.93\n",
      "episode: 3020   score: 6.0   memory length: 863742   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 3021   score: 6.0   memory length: 864078   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.91\n",
      "episode: 3022   score: 6.0   memory length: 864414   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.88\n",
      "episode: 3023   score: 11.0   memory length: 864987   epsilon: 0.009998020008555413    steps: 573    lr: 6.553600000000004e-08     evaluation reward: 6.95\n",
      "episode: 3024   score: 7.0   memory length: 865364   epsilon: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 3025   score: 7.0   memory length: 865741   epsilon: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 3026   score: 8.0   memory length: 866179   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3027   score: 7.0   memory length: 866584   epsilon: 0.009998020008555413    steps: 405    lr: 6.553600000000004e-08     evaluation reward: 7.0\n",
      "episode: 3028   score: 7.0   memory length: 866967   epsilon: 0.009998020008555413    steps: 383    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3029   score: 7.0   memory length: 867389   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3030   score: 6.0   memory length: 867725   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3031   score: 7.0   memory length: 868108   epsilon: 0.009998020008555413    steps: 383    lr: 6.553600000000004e-08     evaluation reward: 6.95\n",
      "episode: 3032   score: 8.0   memory length: 868523   epsilon: 0.009998020008555413    steps: 415    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 3033   score: 6.0   memory length: 868878   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 3034   score: 5.0   memory length: 869202   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 6.94\n",
      "episode: 3035   score: 8.0   memory length: 869640   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 6.97\n",
      "episode: 3036   score: 8.0   memory length: 870111   epsilon: 0.009998020008555413    steps: 471    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 3037   score: 10.0   memory length: 870612   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3038   score: 8.0   memory length: 871050   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.05\n",
      "episode: 3039   score: 6.0   memory length: 871402   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 7.05\n",
      "episode: 3040   score: 6.0   memory length: 871738   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.06\n",
      "episode: 3041   score: 6.0   memory length: 872075   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 3042   score: 10.0   memory length: 872584   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 7.07\n",
      "episode: 3043   score: 5.0   memory length: 872892   epsilon: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 3044   score: 5.0   memory length: 873240   epsilon: 0.009998020008555413    steps: 348    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3045   score: 5.0   memory length: 873554   epsilon: 0.009998020008555413    steps: 314    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3046   score: 7.0   memory length: 873905   epsilon: 0.009998020008555413    steps: 351    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 3047   score: 7.0   memory length: 874290   epsilon: 0.009998020008555413    steps: 385    lr: 6.553600000000004e-08     evaluation reward: 7.03\n",
      "episode: 3048   score: 6.0   memory length: 874662   epsilon: 0.009998020008555413    steps: 372    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3049   score: 5.0   memory length: 875008   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 6.99\n",
      "episode: 3050   score: 7.0   memory length: 875417   epsilon: 0.009998020008555413    steps: 409    lr: 6.553600000000004e-08     evaluation reward: 7.0\n",
      "episode: 3051   score: 8.0   memory length: 875855   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.02\n",
      "episode: 3052   score: 8.0   memory length: 876293   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 3053   score: 7.0   memory length: 876735   epsilon: 0.009998020008555413    steps: 442    lr: 6.553600000000004e-08     evaluation reward: 7.07\n",
      "episode: 3054   score: 9.0   memory length: 877260   epsilon: 0.009998020008555413    steps: 525    lr: 6.553600000000004e-08     evaluation reward: 7.1\n",
      "episode: 3055   score: 8.0   memory length: 877698   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3056   score: 7.0   memory length: 878085   epsilon: 0.009998020008555413    steps: 387    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3057   score: 8.0   memory length: 878539   epsilon: 0.009998020008555413    steps: 454    lr: 6.553600000000004e-08     evaluation reward: 7.09\n",
      "episode: 3058   score: 10.0   memory length: 879117   epsilon: 0.009998020008555413    steps: 578    lr: 6.553600000000004e-08     evaluation reward: 7.1\n",
      "episode: 3059   score: 5.0   memory length: 879463   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 7.09\n",
      "episode: 3060   score: 7.0   memory length: 879870   epsilon: 0.009998020008555413    steps: 407    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3061   score: 8.0   memory length: 880308   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 3062   score: 5.0   memory length: 880657   epsilon: 0.009998020008555413    steps: 349    lr: 6.553600000000004e-08     evaluation reward: 7.09\n",
      "episode: 3063   score: 6.0   memory length: 881056   epsilon: 0.009998020008555413    steps: 399    lr: 6.553600000000004e-08     evaluation reward: 7.08\n",
      "episode: 3064   score: 9.0   memory length: 881533   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3065   score: 8.0   memory length: 881971   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3066   score: 14.0   memory length: 882620   epsilon: 0.009998020008555413    steps: 649    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 3067   score: 8.0   memory length: 883058   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 3068   score: 13.0   memory length: 883680   epsilon: 0.009998020008555413    steps: 622    lr: 6.553600000000004e-08     evaluation reward: 7.22\n",
      "episode: 3069   score: 5.0   memory length: 884026   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 7.21\n",
      "episode: 3070   score: 6.0   memory length: 884381   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.19\n",
      "episode: 3071   score: 4.0   memory length: 884676   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 7.13\n",
      "episode: 3072   score: 6.0   memory length: 885012   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3073   score: 8.0   memory length: 885469   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 7.13\n",
      "episode: 3074   score: 8.0   memory length: 885941   epsilon: 0.009998020008555413    steps: 472    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3075   score: 5.0   memory length: 886287   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3076   score: 5.0   memory length: 886636   epsilon: 0.009998020008555413    steps: 349    lr: 6.553600000000004e-08     evaluation reward: 7.1\n",
      "episode: 3077   score: 10.0   memory length: 887202   epsilon: 0.009998020008555413    steps: 566    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 3078   score: 8.0   memory length: 887628   epsilon: 0.009998020008555413    steps: 426    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 3079   score: 6.0   memory length: 887964   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 3080   score: 6.0   memory length: 888300   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.16\n",
      "episode: 3081   score: 6.0   memory length: 888637   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 7.13\n",
      "episode: 3082   score: 7.0   memory length: 889039   epsilon: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3083   score: 10.0   memory length: 889556   epsilon: 0.009998020008555413    steps: 517    lr: 6.553600000000004e-08     evaluation reward: 7.15\n",
      "episode: 3084   score: 8.0   memory length: 890012   epsilon: 0.009998020008555413    steps: 456    lr: 6.553600000000004e-08     evaluation reward: 7.15\n",
      "episode: 3085   score: 6.0   memory length: 890348   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3086   score: 6.0   memory length: 890740   epsilon: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     evaluation reward: 7.14\n",
      "episode: 3087   score: 7.0   memory length: 891146   epsilon: 0.009998020008555413    steps: 406    lr: 6.553600000000004e-08     evaluation reward: 7.15\n",
      "episode: 3088   score: 6.0   memory length: 891482   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3089   score: 6.0   memory length: 891818   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.11\n",
      "episode: 3090   score: 6.0   memory length: 892210   epsilon: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     evaluation reward: 7.08\n",
      "episode: 3091   score: 7.0   memory length: 892587   epsilon: 0.009998020008555413    steps: 377    lr: 6.553600000000004e-08     evaluation reward: 7.07\n",
      "episode: 3092   score: 6.0   memory length: 892923   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.08\n",
      "episode: 3093   score: 9.0   memory length: 893401   epsilon: 0.009998020008555413    steps: 478    lr: 6.553600000000004e-08     evaluation reward: 7.12\n",
      "episode: 3094   score: 4.0   memory length: 893657   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 7.07\n",
      "episode: 3095   score: 7.0   memory length: 894032   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 7.08\n",
      "episode: 3096   score: 6.0   memory length: 894368   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 7.06\n",
      "episode: 3097   score: 4.0   memory length: 894624   epsilon: 0.009998020008555413    steps: 256    lr: 6.553600000000004e-08     evaluation reward: 7.04\n",
      "episode: 3098   score: 6.0   memory length: 895000   epsilon: 0.009998020008555413    steps: 376    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3099   score: 6.0   memory length: 895355   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 7.01\n",
      "episode: 3100   score: 4.0   memory length: 895650   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 6.98\n",
      "episode: 3101   score: 4.0   memory length: 895945   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 6.92\n",
      "episode: 3102   score: 4.0   memory length: 896243   epsilon: 0.009998020008555413    steps: 298    lr: 6.553600000000004e-08     evaluation reward: 6.87\n",
      "episode: 3103   score: 7.0   memory length: 896626   epsilon: 0.009998020008555413    steps: 383    lr: 6.553600000000004e-08     evaluation reward: 6.85\n",
      "episode: 3104   score: 6.0   memory length: 896962   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.82\n",
      "episode: 3105   score: 6.0   memory length: 897298   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.8\n",
      "episode: 3106   score: 6.0   memory length: 897634   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.77\n",
      "episode: 3107   score: 4.0   memory length: 897929   epsilon: 0.009998020008555413    steps: 295    lr: 6.553600000000004e-08     evaluation reward: 6.76\n",
      "episode: 3108   score: 12.0   memory length: 898435   epsilon: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     evaluation reward: 6.82\n",
      "episode: 3109   score: 5.0   memory length: 898745   epsilon: 0.009998020008555413    steps: 310    lr: 6.553600000000004e-08     evaluation reward: 6.79\n",
      "episode: 3110   score: 6.0   memory length: 899084   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 6.81\n",
      "episode: 3111   score: 6.0   memory length: 899420   epsilon: 0.009998020008555413    steps: 336    lr: 6.553600000000004e-08     evaluation reward: 6.82\n",
      "episode: 3112   score: 8.0   memory length: 899846   epsilon: 0.009998020008555413    steps: 426    lr: 6.553600000000004e-08     evaluation reward: 6.84\n",
      "episode: 3113   score: 9.0   memory length: 900343   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3114   score: 5.0   memory length: 900692   epsilon: 0.009998020008555413    steps: 349    lr: 2.6214400000000017e-08     evaluation reward: 6.86\n",
      "episode: 3115   score: 8.0   memory length: 901190   epsilon: 0.009998020008555413    steps: 498    lr: 2.6214400000000017e-08     evaluation reward: 6.84\n",
      "episode: 3116   score: 8.0   memory length: 901628   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3117   score: 8.0   memory length: 902087   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 6.89\n",
      "episode: 3118   score: 5.0   memory length: 902411   epsilon: 0.009998020008555413    steps: 324    lr: 2.6214400000000017e-08     evaluation reward: 6.88\n",
      "episode: 3119   score: 7.0   memory length: 902797   epsilon: 0.009998020008555413    steps: 386    lr: 2.6214400000000017e-08     evaluation reward: 6.89\n",
      "episode: 3120   score: 8.0   memory length: 903268   epsilon: 0.009998020008555413    steps: 471    lr: 2.6214400000000017e-08     evaluation reward: 6.91\n",
      "episode: 3121   score: 9.0   memory length: 903722   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 6.94\n",
      "episode: 3122   score: 11.0   memory length: 904252   epsilon: 0.009998020008555413    steps: 530    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3123   score: 8.0   memory length: 904688   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.96\n",
      "episode: 3124   score: 8.0   memory length: 905099   epsilon: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3125   score: 6.0   memory length: 905459   epsilon: 0.009998020008555413    steps: 360    lr: 2.6214400000000017e-08     evaluation reward: 6.96\n",
      "episode: 3126   score: 7.0   memory length: 905864   epsilon: 0.009998020008555413    steps: 405    lr: 2.6214400000000017e-08     evaluation reward: 6.95\n",
      "episode: 3127   score: 6.0   memory length: 906219   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 6.94\n",
      "episode: 3128   score: 9.0   memory length: 906719   epsilon: 0.009998020008555413    steps: 500    lr: 2.6214400000000017e-08     evaluation reward: 6.96\n",
      "episode: 3129   score: 6.0   memory length: 907074   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 6.95\n",
      "episode: 3130   score: 8.0   memory length: 907510   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3131   score: 5.0   memory length: 907856   epsilon: 0.009998020008555413    steps: 346    lr: 2.6214400000000017e-08     evaluation reward: 6.95\n",
      "episode: 3132   score: 12.0   memory length: 908352   epsilon: 0.009998020008555413    steps: 496    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3133   score: 7.0   memory length: 908761   epsilon: 0.009998020008555413    steps: 409    lr: 2.6214400000000017e-08     evaluation reward: 7.0\n",
      "episode: 3134   score: 6.0   memory length: 909097   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3135   score: 8.0   memory length: 909533   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3136   score: 8.0   memory length: 909969   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3137   score: 7.0   memory length: 910392   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 6.98\n",
      "episode: 3138   score: 7.0   memory length: 910799   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3139   score: 10.0   memory length: 911298   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3140   score: 6.0   memory length: 911672   epsilon: 0.009998020008555413    steps: 374    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3141   score: 14.0   memory length: 912215   epsilon: 0.009998020008555413    steps: 543    lr: 2.6214400000000017e-08     evaluation reward: 7.09\n",
      "episode: 3142   score: 4.0   memory length: 912513   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.03\n",
      "episode: 3143   score: 4.0   memory length: 912811   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.02\n",
      "episode: 3144   score: 4.0   memory length: 913109   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3145   score: 4.0   memory length: 913407   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.0\n",
      "episode: 3146   score: 5.0   memory length: 913714   epsilon: 0.009998020008555413    steps: 307    lr: 2.6214400000000017e-08     evaluation reward: 6.98\n",
      "episode: 3147   score: 7.0   memory length: 914123   epsilon: 0.009998020008555413    steps: 409    lr: 2.6214400000000017e-08     evaluation reward: 6.98\n",
      "episode: 3148   score: 6.0   memory length: 914459   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 6.98\n",
      "episode: 3149   score: 4.0   memory length: 914757   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3150   score: 4.0   memory length: 915055   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.94\n",
      "episode: 3151   score: 4.0   memory length: 915353   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.9\n",
      "episode: 3152   score: 6.0   memory length: 915689   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 6.88\n",
      "episode: 3153   score: 4.0   memory length: 915987   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.85\n",
      "episode: 3154   score: 4.0   memory length: 916285   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.8\n",
      "episode: 3155   score: 4.0   memory length: 916582   epsilon: 0.009998020008555413    steps: 297    lr: 2.6214400000000017e-08     evaluation reward: 6.76\n",
      "episode: 3156   score: 4.0   memory length: 916880   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.73\n",
      "episode: 3157   score: 4.0   memory length: 917178   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.69\n",
      "episode: 3158   score: 4.0   memory length: 917476   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.63\n",
      "episode: 3159   score: 11.0   memory length: 918049   epsilon: 0.009998020008555413    steps: 573    lr: 2.6214400000000017e-08     evaluation reward: 6.69\n",
      "episode: 3160   score: 8.0   memory length: 918485   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.7\n",
      "episode: 3161   score: 7.0   memory length: 918891   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 6.69\n",
      "episode: 3162   score: 12.0   memory length: 919324   epsilon: 0.009998020008555413    steps: 433    lr: 2.6214400000000017e-08     evaluation reward: 6.76\n",
      "episode: 3163   score: 6.0   memory length: 919660   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 6.76\n",
      "episode: 3164   score: 5.0   memory length: 919968   epsilon: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     evaluation reward: 6.72\n",
      "episode: 3165   score: 7.0   memory length: 920353   epsilon: 0.009998020008555413    steps: 385    lr: 2.6214400000000017e-08     evaluation reward: 6.71\n",
      "episode: 3166   score: 7.0   memory length: 920776   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 6.64\n",
      "episode: 3167   score: 8.0   memory length: 921234   epsilon: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     evaluation reward: 6.64\n",
      "episode: 3168   score: 8.0   memory length: 921670   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.59\n",
      "episode: 3169   score: 7.0   memory length: 922034   epsilon: 0.009998020008555413    steps: 364    lr: 2.6214400000000017e-08     evaluation reward: 6.61\n",
      "episode: 3170   score: 8.0   memory length: 922457   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 6.63\n",
      "episode: 3171   score: 8.0   memory length: 922913   epsilon: 0.009998020008555413    steps: 456    lr: 2.6214400000000017e-08     evaluation reward: 6.67\n",
      "episode: 3172   score: 11.0   memory length: 923446   epsilon: 0.009998020008555413    steps: 533    lr: 2.6214400000000017e-08     evaluation reward: 6.72\n",
      "episode: 3173   score: 9.0   memory length: 923928   epsilon: 0.009998020008555413    steps: 482    lr: 2.6214400000000017e-08     evaluation reward: 6.73\n",
      "episode: 3174   score: 8.0   memory length: 924339   epsilon: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     evaluation reward: 6.73\n",
      "episode: 3175   score: 6.0   memory length: 924715   epsilon: 0.009998020008555413    steps: 376    lr: 2.6214400000000017e-08     evaluation reward: 6.74\n",
      "episode: 3176   score: 8.0   memory length: 925189   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 6.77\n",
      "episode: 3177   score: 5.0   memory length: 925512   epsilon: 0.009998020008555413    steps: 323    lr: 2.6214400000000017e-08     evaluation reward: 6.72\n",
      "episode: 3178   score: 7.0   memory length: 925917   epsilon: 0.009998020008555413    steps: 405    lr: 2.6214400000000017e-08     evaluation reward: 6.71\n",
      "episode: 3179   score: 8.0   memory length: 926353   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.73\n",
      "episode: 3180   score: 7.0   memory length: 926776   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 6.74\n",
      "episode: 3181   score: 8.0   memory length: 927191   epsilon: 0.009998020008555413    steps: 415    lr: 2.6214400000000017e-08     evaluation reward: 6.76\n",
      "episode: 3182   score: 6.0   memory length: 927583   epsilon: 0.009998020008555413    steps: 392    lr: 2.6214400000000017e-08     evaluation reward: 6.75\n",
      "episode: 3183   score: 9.0   memory length: 928055   epsilon: 0.009998020008555413    steps: 472    lr: 2.6214400000000017e-08     evaluation reward: 6.74\n",
      "episode: 3184   score: 4.0   memory length: 928353   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.7\n",
      "episode: 3185   score: 8.0   memory length: 928764   epsilon: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     evaluation reward: 6.72\n",
      "episode: 3186   score: 7.0   memory length: 929171   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 6.73\n",
      "episode: 3187   score: 8.0   memory length: 929607   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.74\n",
      "episode: 3188   score: 7.0   memory length: 930012   epsilon: 0.009998020008555413    steps: 405    lr: 2.6214400000000017e-08     evaluation reward: 6.75\n",
      "episode: 3189   score: 8.0   memory length: 930446   epsilon: 0.009998020008555413    steps: 434    lr: 2.6214400000000017e-08     evaluation reward: 6.77\n",
      "episode: 3190   score: 8.0   memory length: 930899   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 6.79\n",
      "episode: 3191   score: 9.0   memory length: 931422   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 6.81\n",
      "episode: 3192   score: 8.0   memory length: 931875   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 6.83\n",
      "episode: 3193   score: 6.0   memory length: 932269   epsilon: 0.009998020008555413    steps: 394    lr: 2.6214400000000017e-08     evaluation reward: 6.8\n",
      "episode: 3194   score: 7.0   memory length: 932692   epsilon: 0.009998020008555413    steps: 423    lr: 2.6214400000000017e-08     evaluation reward: 6.83\n",
      "episode: 3195   score: 6.0   memory length: 933084   epsilon: 0.009998020008555413    steps: 392    lr: 2.6214400000000017e-08     evaluation reward: 6.82\n",
      "episode: 3196   score: 8.0   memory length: 933520   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.84\n",
      "episode: 3197   score: 8.0   memory length: 933956   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 6.88\n",
      "episode: 3198   score: 5.0   memory length: 934279   epsilon: 0.009998020008555413    steps: 323    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3199   score: 7.0   memory length: 934711   epsilon: 0.009998020008555413    steps: 432    lr: 2.6214400000000017e-08     evaluation reward: 6.88\n",
      "episode: 3200   score: 6.0   memory length: 935066   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 6.9\n",
      "episode: 3201   score: 7.0   memory length: 935451   epsilon: 0.009998020008555413    steps: 385    lr: 2.6214400000000017e-08     evaluation reward: 6.93\n",
      "episode: 3202   score: 9.0   memory length: 935953   epsilon: 0.009998020008555413    steps: 502    lr: 2.6214400000000017e-08     evaluation reward: 6.98\n",
      "episode: 3203   score: 8.0   memory length: 936391   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3204   score: 9.0   memory length: 936860   epsilon: 0.009998020008555413    steps: 469    lr: 2.6214400000000017e-08     evaluation reward: 7.02\n",
      "episode: 3205   score: 7.0   memory length: 937266   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 7.03\n",
      "episode: 3206   score: 6.0   memory length: 937605   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 7.03\n",
      "episode: 3207   score: 6.0   memory length: 937944   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 7.05\n",
      "episode: 3208   score: 6.0   memory length: 938283   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3209   score: 5.0   memory length: 938591   epsilon: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3210   score: 7.0   memory length: 938998   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 7.0\n",
      "episode: 3211   score: 8.0   memory length: 939455   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 7.02\n",
      "episode: 3212   score: 7.0   memory length: 939867   epsilon: 0.009998020008555413    steps: 412    lr: 2.6214400000000017e-08     evaluation reward: 7.01\n",
      "episode: 3213   score: 5.0   memory length: 940191   epsilon: 0.009998020008555413    steps: 324    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3214   score: 4.0   memory length: 940489   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 6.96\n",
      "episode: 3215   score: 7.0   memory length: 940896   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 6.95\n",
      "episode: 3216   score: 5.0   memory length: 941244   epsilon: 0.009998020008555413    steps: 348    lr: 2.6214400000000017e-08     evaluation reward: 6.92\n",
      "episode: 3217   score: 9.0   memory length: 941720   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 6.93\n",
      "episode: 3218   score: 11.0   memory length: 942253   epsilon: 0.009998020008555413    steps: 533    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3219   score: 5.0   memory length: 942579   epsilon: 0.009998020008555413    steps: 326    lr: 2.6214400000000017e-08     evaluation reward: 6.97\n",
      "episode: 3220   score: 6.0   memory length: 942918   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.95\n",
      "episode: 3221   score: 8.0   memory length: 943356   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 6.94\n",
      "episode: 3222   score: 6.0   memory length: 943695   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.89\n",
      "episode: 3223   score: 6.0   memory length: 944034   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3224   score: 5.0   memory length: 944334   epsilon: 0.009998020008555413    steps: 300    lr: 2.6214400000000017e-08     evaluation reward: 6.84\n",
      "episode: 3225   score: 6.0   memory length: 944673   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.84\n",
      "episode: 3226   score: 10.0   memory length: 945190   epsilon: 0.009998020008555413    steps: 517    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3227   score: 6.0   memory length: 945529   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3228   score: 7.0   memory length: 945900   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 6.85\n",
      "episode: 3229   score: 8.0   memory length: 946319   epsilon: 0.009998020008555413    steps: 419    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3230   score: 5.0   memory length: 946627   epsilon: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     evaluation reward: 6.84\n",
      "episode: 3231   score: 8.0   memory length: 947087   epsilon: 0.009998020008555413    steps: 460    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3232   score: 13.0   memory length: 947601   epsilon: 0.009998020008555413    steps: 514    lr: 2.6214400000000017e-08     evaluation reward: 6.88\n",
      "episode: 3233   score: 6.0   memory length: 947940   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.87\n",
      "episode: 3234   score: 5.0   memory length: 948248   epsilon: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     evaluation reward: 6.86\n",
      "episode: 3235   score: 5.0   memory length: 948574   epsilon: 0.009998020008555413    steps: 326    lr: 2.6214400000000017e-08     evaluation reward: 6.83\n",
      "episode: 3236   score: 6.0   memory length: 948913   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.81\n",
      "episode: 3237   score: 6.0   memory length: 949252   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.8\n",
      "episode: 3238   score: 6.0   memory length: 949591   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.79\n",
      "episode: 3239   score: 10.0   memory length: 950138   epsilon: 0.009998020008555413    steps: 547    lr: 2.6214400000000017e-08     evaluation reward: 6.79\n",
      "episode: 3240   score: 12.0   memory length: 950741   epsilon: 0.009998020008555413    steps: 603    lr: 2.6214400000000017e-08     evaluation reward: 6.85\n",
      "episode: 3241   score: 6.0   memory length: 951080   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.77\n",
      "episode: 3242   score: 8.0   memory length: 951499   epsilon: 0.009998020008555413    steps: 419    lr: 2.6214400000000017e-08     evaluation reward: 6.81\n",
      "episode: 3243   score: 3.0   memory length: 951725   epsilon: 0.009998020008555413    steps: 226    lr: 2.6214400000000017e-08     evaluation reward: 6.8\n",
      "episode: 3244   score: 10.0   memory length: 952243   epsilon: 0.009998020008555413    steps: 518    lr: 2.6214400000000017e-08     evaluation reward: 6.86\n",
      "episode: 3245   score: 10.0   memory length: 952742   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 6.92\n",
      "episode: 3246   score: 6.0   memory length: 953081   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.93\n",
      "episode: 3247   score: 13.0   memory length: 953593   epsilon: 0.009998020008555413    steps: 512    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3248   score: 6.0   memory length: 953932   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 6.99\n",
      "episode: 3249   score: 8.0   memory length: 954360   epsilon: 0.009998020008555413    steps: 428    lr: 2.6214400000000017e-08     evaluation reward: 7.03\n",
      "episode: 3250   score: 7.0   memory length: 954766   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 7.06\n",
      "episode: 3251   score: 9.0   memory length: 955221   epsilon: 0.009998020008555413    steps: 455    lr: 2.6214400000000017e-08     evaluation reward: 7.11\n",
      "episode: 3252   score: 7.0   memory length: 955592   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 7.12\n",
      "episode: 3253   score: 7.0   memory length: 956001   epsilon: 0.009998020008555413    steps: 409    lr: 2.6214400000000017e-08     evaluation reward: 7.15\n",
      "episode: 3254   score: 9.0   memory length: 956455   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 7.2\n",
      "episode: 3255   score: 8.0   memory length: 956891   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 7.24\n",
      "episode: 3256   score: 6.0   memory length: 957230   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 7.26\n",
      "episode: 3257   score: 11.0   memory length: 957763   epsilon: 0.009998020008555413    steps: 533    lr: 2.6214400000000017e-08     evaluation reward: 7.33\n",
      "episode: 3258   score: 7.0   memory length: 958167   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 7.36\n",
      "episode: 3259   score: 9.0   memory length: 958643   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.34\n",
      "episode: 3260   score: 9.0   memory length: 959121   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 7.35\n",
      "episode: 3261   score: 9.0   memory length: 959628   epsilon: 0.009998020008555413    steps: 507    lr: 2.6214400000000017e-08     evaluation reward: 7.37\n",
      "episode: 3262   score: 9.0   memory length: 960103   epsilon: 0.009998020008555413    steps: 475    lr: 2.6214400000000017e-08     evaluation reward: 7.34\n",
      "episode: 3263   score: 11.0   memory length: 960660   epsilon: 0.009998020008555413    steps: 557    lr: 2.6214400000000017e-08     evaluation reward: 7.39\n",
      "episode: 3264   score: 10.0   memory length: 961164   epsilon: 0.009998020008555413    steps: 504    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3265   score: 9.0   memory length: 961665   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 7.46\n",
      "episode: 3266   score: 7.0   memory length: 962072   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 7.46\n",
      "episode: 3267   score: 7.0   memory length: 962447   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 7.45\n",
      "episode: 3268   score: 6.0   memory length: 962783   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.43\n",
      "episode: 3269   score: 6.0   memory length: 963119   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3270   score: 6.0   memory length: 963492   epsilon: 0.009998020008555413    steps: 373    lr: 2.6214400000000017e-08     evaluation reward: 7.4\n",
      "episode: 3271   score: 11.0   memory length: 964071   epsilon: 0.009998020008555413    steps: 579    lr: 2.6214400000000017e-08     evaluation reward: 7.43\n",
      "episode: 3272   score: 10.0   memory length: 964610   epsilon: 0.009998020008555413    steps: 539    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3273   score: 9.0   memory length: 965115   epsilon: 0.009998020008555413    steps: 505    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3274   score: 8.0   memory length: 965551   epsilon: 0.009998020008555413    steps: 436    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3275   score: 6.0   memory length: 965922   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3276   score: 6.0   memory length: 966258   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.4\n",
      "episode: 3277   score: 9.0   memory length: 966734   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3278   score: 7.0   memory length: 967138   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3279   score: 9.0   memory length: 967640   epsilon: 0.009998020008555413    steps: 502    lr: 2.6214400000000017e-08     evaluation reward: 7.45\n",
      "episode: 3280   score: 6.0   memory length: 967995   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3281   score: 8.0   memory length: 968388   epsilon: 0.009998020008555413    steps: 393    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3282   score: 8.0   memory length: 968815   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 7.46\n",
      "episode: 3283   score: 7.0   memory length: 969192   epsilon: 0.009998020008555413    steps: 377    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3284   score: 5.0   memory length: 969520   epsilon: 0.009998020008555413    steps: 328    lr: 2.6214400000000017e-08     evaluation reward: 7.45\n",
      "episode: 3285   score: 4.0   memory length: 969818   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.41\n",
      "episode: 3286   score: 7.0   memory length: 970193   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 7.41\n",
      "episode: 3287   score: 8.0   memory length: 970631   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.41\n",
      "episode: 3288   score: 9.0   memory length: 971107   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.43\n",
      "episode: 3289   score: 9.0   memory length: 971583   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.44\n",
      "episode: 3290   score: 6.0   memory length: 971938   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.42\n",
      "episode: 3291   score: 6.0   memory length: 972293   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.39\n",
      "episode: 3292   score: 9.0   memory length: 972713   epsilon: 0.009998020008555413    steps: 420    lr: 2.6214400000000017e-08     evaluation reward: 7.4\n",
      "episode: 3293   score: 9.0   memory length: 973181   epsilon: 0.009998020008555413    steps: 468    lr: 2.6214400000000017e-08     evaluation reward: 7.43\n",
      "episode: 3294   score: 9.0   memory length: 973601   epsilon: 0.009998020008555413    steps: 420    lr: 2.6214400000000017e-08     evaluation reward: 7.45\n",
      "episode: 3295   score: 10.0   memory length: 974119   epsilon: 0.009998020008555413    steps: 518    lr: 2.6214400000000017e-08     evaluation reward: 7.49\n",
      "episode: 3296   score: 6.0   memory length: 974474   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.47\n",
      "episode: 3297   score: 9.0   memory length: 974950   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.48\n",
      "episode: 3298   score: 11.0   memory length: 975470   epsilon: 0.009998020008555413    steps: 520    lr: 2.6214400000000017e-08     evaluation reward: 7.54\n",
      "episode: 3299   score: 8.0   memory length: 975897   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 7.55\n",
      "episode: 3300   score: 7.0   memory length: 976304   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 7.56\n",
      "episode: 3301   score: 6.0   memory length: 976640   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.55\n",
      "episode: 3302   score: 13.0   memory length: 977141   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 7.59\n",
      "episode: 3303   score: 8.0   memory length: 977567   epsilon: 0.009998020008555413    steps: 426    lr: 2.6214400000000017e-08     evaluation reward: 7.59\n",
      "episode: 3304   score: 6.0   memory length: 977903   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.56\n",
      "episode: 3305   score: 9.0   memory length: 978379   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.58\n",
      "episode: 3306   score: 7.0   memory length: 978784   epsilon: 0.009998020008555413    steps: 405    lr: 2.6214400000000017e-08     evaluation reward: 7.59\n",
      "episode: 3307   score: 7.0   memory length: 979182   epsilon: 0.009998020008555413    steps: 398    lr: 2.6214400000000017e-08     evaluation reward: 7.6\n",
      "episode: 3308   score: 7.0   memory length: 979567   epsilon: 0.009998020008555413    steps: 385    lr: 2.6214400000000017e-08     evaluation reward: 7.61\n",
      "episode: 3309   score: 8.0   memory length: 980019   epsilon: 0.009998020008555413    steps: 452    lr: 2.6214400000000017e-08     evaluation reward: 7.64\n",
      "episode: 3310   score: 8.0   memory length: 980457   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.65\n",
      "episode: 3311   score: 5.0   memory length: 980803   epsilon: 0.009998020008555413    steps: 346    lr: 2.6214400000000017e-08     evaluation reward: 7.62\n",
      "episode: 3312   score: 8.0   memory length: 981241   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.63\n",
      "episode: 3313   score: 6.0   memory length: 981580   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 7.64\n",
      "episode: 3314   score: 8.0   memory length: 981856   epsilon: 0.009998020008555413    steps: 276    lr: 2.6214400000000017e-08     evaluation reward: 7.68\n",
      "episode: 3315   score: 8.0   memory length: 982290   epsilon: 0.009998020008555413    steps: 434    lr: 2.6214400000000017e-08     evaluation reward: 7.69\n",
      "episode: 3316   score: 6.0   memory length: 982645   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.7\n",
      "episode: 3317   score: 8.0   memory length: 983083   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.69\n",
      "episode: 3318   score: 8.0   memory length: 983540   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 7.66\n",
      "episode: 3319   score: 7.0   memory length: 983972   epsilon: 0.009998020008555413    steps: 432    lr: 2.6214400000000017e-08     evaluation reward: 7.68\n",
      "episode: 3320   score: 5.0   memory length: 984318   epsilon: 0.009998020008555413    steps: 346    lr: 2.6214400000000017e-08     evaluation reward: 7.67\n",
      "episode: 3321   score: 6.0   memory length: 984673   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.65\n",
      "episode: 3322   score: 8.0   memory length: 985111   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.67\n",
      "episode: 3323   score: 9.0   memory length: 985589   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 7.7\n",
      "episode: 3324   score: 6.0   memory length: 985944   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.71\n",
      "episode: 3325   score: 4.0   memory length: 986242   epsilon: 0.009998020008555413    steps: 298    lr: 2.6214400000000017e-08     evaluation reward: 7.69\n",
      "episode: 3326   score: 9.0   memory length: 986716   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 7.68\n",
      "episode: 3327   score: 9.0   memory length: 987192   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.71\n",
      "episode: 3328   score: 7.0   memory length: 987596   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 7.71\n",
      "episode: 3329   score: 12.0   memory length: 988050   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 7.75\n",
      "episode: 3330   score: 8.0   memory length: 988488   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 7.78\n",
      "episode: 3331   score: 9.0   memory length: 988964   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.79\n",
      "episode: 3332   score: 9.0   memory length: 989440   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.75\n",
      "episode: 3333   score: 9.0   memory length: 989897   epsilon: 0.009998020008555413    steps: 457    lr: 2.6214400000000017e-08     evaluation reward: 7.78\n",
      "episode: 3334   score: 9.0   memory length: 990368   epsilon: 0.009998020008555413    steps: 471    lr: 2.6214400000000017e-08     evaluation reward: 7.82\n",
      "episode: 3335   score: 6.0   memory length: 990704   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.83\n",
      "episode: 3336   score: 13.0   memory length: 991327   epsilon: 0.009998020008555413    steps: 623    lr: 2.6214400000000017e-08     evaluation reward: 7.9\n",
      "episode: 3337   score: 7.0   memory length: 991731   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 7.91\n",
      "episode: 3338   score: 9.0   memory length: 992207   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.94\n",
      "episode: 3339   score: 6.0   memory length: 992603   epsilon: 0.009998020008555413    steps: 396    lr: 2.6214400000000017e-08     evaluation reward: 7.9\n",
      "episode: 3340   score: 7.0   memory length: 992974   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 7.85\n",
      "episode: 3341   score: 12.0   memory length: 993535   epsilon: 0.009998020008555413    steps: 561    lr: 2.6214400000000017e-08     evaluation reward: 7.91\n",
      "episode: 3342   score: 11.0   memory length: 994081   epsilon: 0.009998020008555413    steps: 546    lr: 2.6214400000000017e-08     evaluation reward: 7.94\n",
      "episode: 3343   score: 4.0   memory length: 994337   epsilon: 0.009998020008555413    steps: 256    lr: 2.6214400000000017e-08     evaluation reward: 7.95\n",
      "episode: 3344   score: 5.0   memory length: 994645   epsilon: 0.009998020008555413    steps: 308    lr: 2.6214400000000017e-08     evaluation reward: 7.9\n",
      "episode: 3345   score: 7.0   memory length: 995054   epsilon: 0.009998020008555413    steps: 409    lr: 2.6214400000000017e-08     evaluation reward: 7.87\n",
      "episode: 3346   score: 4.0   memory length: 995310   epsilon: 0.009998020008555413    steps: 256    lr: 2.6214400000000017e-08     evaluation reward: 7.85\n",
      "episode: 3347   score: 5.0   memory length: 995637   epsilon: 0.009998020008555413    steps: 327    lr: 2.6214400000000017e-08     evaluation reward: 7.77\n",
      "episode: 3348   score: 9.0   memory length: 996147   epsilon: 0.009998020008555413    steps: 510    lr: 2.6214400000000017e-08     evaluation reward: 7.8\n",
      "episode: 3349   score: 6.0   memory length: 996483   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 7.78\n",
      "episode: 3350   score: 9.0   memory length: 996905   epsilon: 0.009998020008555413    steps: 422    lr: 2.6214400000000017e-08     evaluation reward: 7.8\n",
      "episode: 3351   score: 10.0   memory length: 997409   epsilon: 0.009998020008555413    steps: 504    lr: 2.6214400000000017e-08     evaluation reward: 7.81\n",
      "episode: 3352   score: 9.0   memory length: 997885   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 7.83\n",
      "episode: 3353   score: 7.0   memory length: 998256   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 7.83\n",
      "episode: 3354   score: 9.0   memory length: 998676   epsilon: 0.009998020008555413    steps: 420    lr: 2.6214400000000017e-08     evaluation reward: 7.83\n",
      "episode: 3355   score: 11.0   memory length: 999209   epsilon: 0.009998020008555413    steps: 533    lr: 2.6214400000000017e-08     evaluation reward: 7.86\n",
      "episode: 3356   score: 6.0   memory length: 999564   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 7.86\n",
      "episode: 3357   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 437    lr: 2.6214400000000017e-08     evaluation reward: 7.83\n",
      "episode: 3358   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3359   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 1.0485760000000008e-08     evaluation reward: 7.79\n",
      "episode: 3360   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 1.0485760000000008e-08     evaluation reward: 7.76\n",
      "episode: 3361   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 535    lr: 1.0485760000000008e-08     evaluation reward: 7.77\n",
      "episode: 3362   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 593    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3363   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 1.0485760000000008e-08     evaluation reward: 7.79\n",
      "episode: 3364   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 413    lr: 1.0485760000000008e-08     evaluation reward: 7.76\n",
      "episode: 3365   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 7.76\n",
      "episode: 3366   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 7.74\n",
      "episode: 3367   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 419    lr: 1.0485760000000008e-08     evaluation reward: 7.75\n",
      "episode: 3368   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 7.74\n",
      "episode: 3369   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 376    lr: 1.0485760000000008e-08     evaluation reward: 7.74\n",
      "episode: 3370   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 1.0485760000000008e-08     evaluation reward: 7.76\n",
      "episode: 3371   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 339    lr: 1.0485760000000008e-08     evaluation reward: 7.71\n",
      "episode: 3372   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 623    lr: 1.0485760000000008e-08     evaluation reward: 7.74\n",
      "episode: 3373   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 455    lr: 1.0485760000000008e-08     evaluation reward: 7.74\n",
      "episode: 3374   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 327    lr: 1.0485760000000008e-08     evaluation reward: 7.71\n",
      "episode: 3375   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 378    lr: 1.0485760000000008e-08     evaluation reward: 7.71\n",
      "episode: 3376   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 7.78\n",
      "episode: 3377   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 7.82\n",
      "episode: 3378   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 1.0485760000000008e-08     evaluation reward: 7.84\n",
      "episode: 3379   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 401    lr: 1.0485760000000008e-08     evaluation reward: 7.86\n",
      "episode: 3380   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 208    lr: 1.0485760000000008e-08     evaluation reward: 7.83\n",
      "episode: 3381   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 1.0485760000000008e-08     evaluation reward: 7.85\n",
      "episode: 3382   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 7.9\n",
      "episode: 3383   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 1.0485760000000008e-08     evaluation reward: 7.94\n",
      "episode: 3384   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.02\n",
      "episode: 3385   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 371    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3386   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 1.0485760000000008e-08     evaluation reward: 8.05\n",
      "episode: 3387   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.1\n",
      "episode: 3388   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 434    lr: 1.0485760000000008e-08     evaluation reward: 8.09\n",
      "episode: 3389   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 1.0485760000000008e-08     evaluation reward: 8.17\n",
      "episode: 3390   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 8.17\n",
      "episode: 3391   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 556    lr: 1.0485760000000008e-08     evaluation reward: 8.21\n",
      "episode: 3392   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 326    lr: 1.0485760000000008e-08     evaluation reward: 8.17\n",
      "episode: 3393   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 545    lr: 1.0485760000000008e-08     evaluation reward: 8.23\n",
      "episode: 3394   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 1.0485760000000008e-08     evaluation reward: 8.22\n",
      "episode: 3395   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 358    lr: 1.0485760000000008e-08     evaluation reward: 8.18\n",
      "episode: 3396   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 259    lr: 1.0485760000000008e-08     evaluation reward: 8.16\n",
      "episode: 3397   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 8.2\n",
      "episode: 3398   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 488    lr: 1.0485760000000008e-08     evaluation reward: 8.18\n",
      "episode: 3399   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 401    lr: 1.0485760000000008e-08     evaluation reward: 8.21\n",
      "episode: 3400   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.27\n",
      "episode: 3401   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 1.0485760000000008e-08     evaluation reward: 8.33\n",
      "episode: 3402   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.33\n",
      "episode: 3403   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 8.38\n",
      "episode: 3404   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 1.0485760000000008e-08     evaluation reward: 8.4\n",
      "episode: 3405   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 8.44\n",
      "episode: 3406   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.5\n",
      "episode: 3407   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 1.0485760000000008e-08     evaluation reward: 8.5\n",
      "episode: 3408   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 8.52\n",
      "episode: 3409   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 1.0485760000000008e-08     evaluation reward: 8.53\n",
      "episode: 3410   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 468    lr: 1.0485760000000008e-08     evaluation reward: 8.57\n",
      "episode: 3411   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 8.57\n",
      "episode: 3412   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 475    lr: 1.0485760000000008e-08     evaluation reward: 8.58\n",
      "episode: 3413   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 1.0485760000000008e-08     evaluation reward: 8.61\n",
      "episode: 3414   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 1.0485760000000008e-08     evaluation reward: 8.62\n",
      "episode: 3415   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 1.0485760000000008e-08     evaluation reward: 8.61\n",
      "episode: 3416   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 1.0485760000000008e-08     evaluation reward: 8.62\n",
      "episode: 3417   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 356    lr: 1.0485760000000008e-08     evaluation reward: 8.6\n",
      "episode: 3418   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.65\n",
      "episode: 3419   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 8.67\n",
      "episode: 3420   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.75\n",
      "episode: 3421   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 558    lr: 1.0485760000000008e-08     evaluation reward: 8.8\n",
      "episode: 3422   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 8.81\n",
      "episode: 3423   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 356    lr: 1.0485760000000008e-08     evaluation reward: 8.78\n",
      "episode: 3424   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 1.0485760000000008e-08     evaluation reward: 8.8\n",
      "episode: 3425   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 419    lr: 1.0485760000000008e-08     evaluation reward: 8.85\n",
      "episode: 3426   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 1.0485760000000008e-08     evaluation reward: 8.87\n",
      "episode: 3427   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.91\n",
      "episode: 3428   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 8.97\n",
      "episode: 3429   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 8.98\n",
      "episode: 3430   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 415    lr: 1.0485760000000008e-08     evaluation reward: 8.98\n",
      "episode: 3431   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 377    lr: 1.0485760000000008e-08     evaluation reward: 8.96\n",
      "episode: 3432   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.0\n",
      "episode: 3433   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 1.0485760000000008e-08     evaluation reward: 9.0\n",
      "episode: 3434   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 1.0485760000000008e-08     evaluation reward: 9.0\n",
      "episode: 3435   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 1.0485760000000008e-08     evaluation reward: 9.01\n",
      "episode: 3436   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 9.01\n",
      "episode: 3437   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 9.03\n",
      "episode: 3438   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 414    lr: 1.0485760000000008e-08     evaluation reward: 9.02\n",
      "episode: 3439   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 9.05\n",
      "episode: 3440   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.11\n",
      "episode: 3441   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 9.04\n",
      "episode: 3442   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 493    lr: 1.0485760000000008e-08     evaluation reward: 9.07\n",
      "episode: 3443   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.16\n",
      "episode: 3444   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 623    lr: 1.0485760000000008e-08     evaluation reward: 9.24\n",
      "episode: 3445   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.3\n",
      "episode: 3446   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 306    lr: 1.0485760000000008e-08     evaluation reward: 9.31\n",
      "episode: 3447   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.39\n",
      "episode: 3448   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 1.0485760000000008e-08     evaluation reward: 9.37\n",
      "episode: 3449   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.44\n",
      "episode: 3450   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.48\n",
      "episode: 3451   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.51\n",
      "episode: 3452   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 9.48\n",
      "episode: 3453   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 439    lr: 1.0485760000000008e-08     evaluation reward: 9.51\n",
      "episode: 3454   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.55\n",
      "episode: 3455   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.57\n",
      "episode: 3456   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.64\n",
      "episode: 3457   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 9.62\n",
      "episode: 3458   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 385    lr: 1.0485760000000008e-08     evaluation reward: 9.63\n",
      "episode: 3459   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.7\n",
      "episode: 3460   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.77\n",
      "episode: 3461   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.8\n",
      "episode: 3462   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.77\n",
      "episode: 3463   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 9.84\n",
      "episode: 3464   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 494    lr: 1.0485760000000008e-08     evaluation reward: 9.91\n",
      "episode: 3465   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 494    lr: 1.0485760000000008e-08     evaluation reward: 9.96\n",
      "episode: 3466   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 470    lr: 1.0485760000000008e-08     evaluation reward: 10.02\n",
      "episode: 3467   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 439    lr: 1.0485760000000008e-08     evaluation reward: 10.03\n",
      "episode: 3468   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 10.11\n",
      "episode: 3469   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 10.18\n",
      "episode: 3470   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 10.23\n",
      "episode: 3471   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 508    lr: 1.0485760000000008e-08     evaluation reward: 10.28\n",
      "episode: 3472   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 423    lr: 1.0485760000000008e-08     evaluation reward: 10.23\n",
      "episode: 3473   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 377    lr: 1.0485760000000008e-08     evaluation reward: 10.21\n",
      "episode: 3474   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 10.29\n",
      "episode: 3475   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 448    lr: 1.0485760000000008e-08     evaluation reward: 10.36\n",
      "episode: 3476   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 1.0485760000000008e-08     evaluation reward: 10.36\n",
      "episode: 3477   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 435    lr: 1.0485760000000008e-08     evaluation reward: 10.31\n",
      "episode: 3478   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 10.28\n",
      "episode: 3479   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 414    lr: 1.0485760000000008e-08     evaluation reward: 10.25\n",
      "episode: 3480   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 10.31\n",
      "episode: 3481   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 1.0485760000000008e-08     evaluation reward: 10.3\n",
      "episode: 3482   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 365    lr: 1.0485760000000008e-08     evaluation reward: 10.24\n",
      "episode: 3483   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 365    lr: 1.0485760000000008e-08     evaluation reward: 10.2\n",
      "episode: 3484   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 10.12\n",
      "episode: 3485   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 1.0485760000000008e-08     evaluation reward: 10.12\n",
      "episode: 3486   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 377    lr: 1.0485760000000008e-08     evaluation reward: 10.12\n",
      "episode: 3487   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 410    lr: 1.0485760000000008e-08     evaluation reward: 10.06\n",
      "episode: 3488   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 385    lr: 1.0485760000000008e-08     evaluation reward: 10.05\n",
      "episode: 3489   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 623    lr: 1.0485760000000008e-08     evaluation reward: 10.01\n",
      "episode: 3490   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 259    lr: 1.0485760000000008e-08     evaluation reward: 9.99\n",
      "episode: 3491   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 308    lr: 1.0485760000000008e-08     evaluation reward: 9.94\n",
      "episode: 3492   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 586    lr: 1.0485760000000008e-08     evaluation reward: 10.0\n",
      "episode: 3493   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 1.0485760000000008e-08     evaluation reward: 9.93\n",
      "episode: 3494   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 452    lr: 1.0485760000000008e-08     evaluation reward: 9.93\n",
      "episode: 3495   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 382    lr: 1.0485760000000008e-08     evaluation reward: 9.94\n",
      "episode: 3496   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 1.0485760000000008e-08     evaluation reward: 9.96\n",
      "episode: 3497   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 378    lr: 1.0485760000000008e-08     evaluation reward: 9.89\n",
      "episode: 3498   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 385    lr: 1.0485760000000008e-08     evaluation reward: 9.87\n",
      "episode: 3499   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 1.0485760000000008e-08     evaluation reward: 9.88\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfXElEQVR4nO3de7QcZZ3u8e+TC2TnCjFbFgQhoIzKMAoYPQocRFER1MFxcEB0BFEZHT3gnPF4wMsR1zgzOh6v44weRBBBwRHxNuAI44XIiECCiAFEMICCwSQkJORibvt3/qi33ZVO9969L11V3fV81uq1u6uqu35d6Tz99ltVbykiMDOz+phSdgFmZlYsB7+ZWc04+M3MasbBb2ZWMw5+M7OacfCbmdWMg98qRdJ3JJ0xya95gaTLJ/M160TSFyR9sOw6bPI4+G3SSXpA0hZJG3O3T3fy3Ig4MSIu7XaNVSBpkaTIbaMHJJ1Xdl3W/6aVXYD1rVdExH+WXUSP2CsidkhaDNwgaVlEXF9GIZKmRsTOMtZtxXGL3wol6UxJ/yXp05LWS/qFpONz838o6U3p/lMk3ZCWWyPpK7nljpJ0a5p3q6SjcvMOSs97XNL1wIKmGp4r6ceSHpP0M0nHNdW3Ij33fkmvbfEe9ku/aObnph2Rapw+Ut0jiYilwJ3A4bnXPUvS3ZLWSfqupAPT9A9I+ud0f7qkTZI+kh4PSPp9oz5JX5X0SKpniaQ/zr3+FyR9RtK1kjYBL0jv5ba0Db4CzOikfusdDn4rw38DfkUWyO8Hrs6HaM7fAdcBewP7A42gmw9cA3wKeALwMeAaSU9Iz/sysCy9/t8Bf9hnIGlheu4HgfnAO4GvSRqUNCu95okRMQc4Cri9uaiI+C1wE/DnucmnA1dFxPZ2dY9G0nOBw4D70uOTgXcDrwIGgR8BV6TFbwCOS/efDTwCHJsePw+4JyLWpsffAQ4BngjcBnypadWnA38PzAFuAb4BXJa2z1eb3qf1AQe/dcs3Uou6cXtzbt4q4BMRsT0ivgLcA7ysxWtsBw4E9ouI30fEjWn6y4B7I+KyiNgREVcAvwBeIekAsiB8X0RsjYglwLdzr/k64NqIuDYihlKXylLgpDR/CDhM0kBErIyIO9u8vy8DrwGQJOC0NG2kuttZI2kL2ZfJv5IFL8BbgH+MiLsjYgfwD8DhqdV/E3BI+rI7Fvg8sFDSbOD5ZF8MAETExRHxeERsBS4AnilpXm7934yI/4qIIbJfG9MZ/ve5Crh1lPqtxzj4rVteGRF75W6fy817OHYdHfBBYL8Wr/EuQMAtku6UdFaavl96Tt6DwMI0b11EbGqa13Ag8Or8lxJwDLBves6pZIG7UtI1kp7W5v19DXiepH3JgneIrEU+Ut3tLABmA39L1oqfnqv1k7k616bXXRgRW8i+sJ6f1n8D8GPgaHLBL2mqpA9J+pWkDcADuXU2/CZ3fz9a//tYH3HwWxkWplZywwHAb5sXiohHIuLNEbEf8FfAv0p6Slr2wKbFDwAeBlYCe6dum/y8ht8AlzV9Kc2KiA+ldX43Il4M7Ev2KyL/hZWvbR1Zd86pZF0lVzbCcoS624qInRHxMeD3wF/nav2rploHIuLHaf4NwAuBI8ha5TcAJwDPAZakZU4HTgZeBMwDFqXp+e2fD/mVtP73sT7i4LcyPBE4J+2UfDXwdODa5oUkvVrS/unhOrKAGkrL/pGk0yVNk3QqcCjw7xHxIFlL+AOS9pB0DPCK3MteTtYldEJqDc+QdJyk/SXtI+nk9KWxFdiY1tfOl4HXA6cw3M0zUt2d+BDwLkkzgM8C5zd2xkqal7ZXww1p/XdFxDbgh8CbgPsjYnVaZk56L48CM8m6i0ZyE7CD4X+fV5F9kVgfcfBbt3xbux7H//XcvJvJdjauIdupeEpEPNriNZ4N3CxpI/At4NyIWJGWfTlZ18ijZF0rL4+INel5p5PtQF5LtvP4i40XjIjfkLWA3w2sJmtV/y+y/wtTgP9J9otiLVmXyVtHeI/fSu/jkYj42Wh1j/A6edeQfVm8OSK+DnwYuDJ10ywHTswt+2NggOHW/V1kvxiW5Jb5IllXzcNp/k9GWnn6AnkVcCbZNjgVuLrD2q1HyBdisSJJOhN4U0QcU3YtZnXlFr+ZWc04+M3MasZdPWZmNeMWv5lZzfTEIG0LFiyIRYsWlV2GmVlPWbZs2ZqIGGye3hPBv2jRIpYuXVp2GWZmPUVSy7Ou3dVjZlYzDn4zs5px8JuZ1YyD38ysZhz8ZmY14+A3M6sZB7+ZWc04+M3MKuQ5zwEJbrqpe+tw8JuZVcit6QrHRx3VvXU4+M3MasbBb2ZWMw5+M7Oa6VrwS7pY0ipJy3PT5ku6XtK96e/e3Vq/mVmv+eUvd318xx3dWU83W/xfAF7aNO084HsRcQjwvfTYzMyAE07Y9fFZZ3VnPV0L/ohYAqxtmnwycGm6fynwym6t38ys1zzwwK6Ply3rznqK7uPfJyJWpvuPAPu0W1DS2ZKWSlq6evXqYqozM6uY7dsn/zVL27kb2cV+217wNyIujIjFEbF4cHC3C8iYmdXCzp2T/5pFB//vJO0LkP6uKnj9ZmaVN306zJ2b3b/xxsl//aKD/1vAGen+GcA3C16/mVnlvf3tcMMN8OEPw9FHT/7rd+2au5KuAI4DFkh6CHg/8CHg3yS9EXgQ+Iturd/MrFd99KPZeD2HH96d1+9a8EfEa9rMOr5b6zQz6wcRWfB3i8/cNTOrgA9+cPj+lC4ns4PfzKwC3ve+4tbl4DczqxkHv5lZzTj4zcwq5Mwzu78OB7+ZWYVcckn31+HgNzMrWbQdvKY7HPxmZiVbsKDY9Tn4zcxKtrZ5APsuc/CbmdWMg9/MrGYc/GZmNePgNzMr0Sc/Wfw6HfxmZiV6xzuG72/eXMw6HfxmZhUxMFDMehz8ZmYVUORJXA5+M7OSPPnJ5azXwW9mVpIVK8pZr4PfzKxmHPxmZjXj4DczK0HRI3LmOfjNzEqQv6D6Y48VvO5iV2dmZs3mzSt2fQ5+M6sUKbuV2RXS7xz8ZlZJU2qSTjt3Fr/OmmxaM6u6Rku/2dDQ8LxW83tdGV9wDn4zq7SpU8uuoP84+M2sdO368/uxhQ/lvy8Hv5mVbizdHWWHZj8oJfgl/Y2kOyUtl3SFpBll1GFm1dPvR/OUsTO3WeHBL2khcA6wOCIOA6YCpxVdh5n1jg0byq5g8kybNny/rC+5srp6pgEDkqYBM4HfllSHmfWAOXPKrqC/FB78EfEw8H+BXwMrgfURcV3zcpLOlrRU0tLVq1cXXaaZFaRVn33jEoQRvd/1U8VDUcvo6tkbOBk4CNgPmCXpdc3LRcSFEbE4IhYPDg4WXaaZlaAR8gMDIwf+0FAx9fSrMrp6XgTcHxGrI2I7cDVwVAl1mFnJxtIKzn8R9Oqx/fn3+5GPlFdHGcH/a+C5kmZKEnA8cHcJdZiZlead7yxv3WX08d8MXAXcBvw81XBh0XWYWXkidm/td9KXnz+6p2r95q1Utb5poy8y+SLi/cD7y1i3mZVvvOPTtDq6p6ojeVY19MFn7ppZwVoF4uOPT/w1qxy0UK0vp1Ja/GZmebNnl13B5GrXjVWV8HeL38xKMzRUnTDsliq+P7f4zaw04+meyQdpRHUu2NLqvSxcWHwdnXDwm1lXFNHnLmW/GqoS/s0eeqjsClqr6OYys6qarNElJ6sLJP8FU9YO3qrvWG7m4Dezjvz2t1nATZs23NJuZ8eO4uqysXNXj5mNqlWLdurU3VvtjevjTp9eTF1VVMWduc3c4jezEW3Z0vmyU6eO3t/ejRE386+XHw2zMcrnaCbrPIA99pj4axTBLX4za2ssYdjJsps2jb+W8Zg1a/QvmXXrhu833sN4v5i2bh3f84rmFr+ZTVi7oGxu3c+cWUw9YzF/fvt5jV8CvdB9MxYOfjNrqVULvl0AltG906nmo36k7JfHSN07zdOb31/+ub14bQB39ZhZR1r1l1fpMMbmfv685qOQOhkiot17yx/OWqX3PxZu8ZvZblqNNTMwkN0fy87esrQ6nLSTXyWdmNYHzWUHv5mNqDkQZ8xov2xj7J2yr5Xb6lDTkWzbNvoy/dTP7+A3s13kW/tjCbtWF1cpWyf97xHD5x2M9H4n64zlKnDwm1nfanVETvMgbyPJ/xKYPn3kL7Ze+kXg4DezMYsYbgFv2tRboQedd0WNdAZy88VjOukuqoo+2E1hZmWYMqV3Ar8bdc6evWv3Vq+ctQtu8Zv1vAhYsiQLoNH6odsdu97oCx9v/34/6WTndHN3Ua9tK7f4zXpc/jDFadN2bYW2C6Sq7YTtJb0W8q24xW/Ww1oFeKszVXtlDJkq6oegb+YWv1kNjHTsvY2uVVdYL3OL36xHdSuEtm7tz1buREzWsM1V4Ra/mf2BA78e3OI3K9mqVWNvUTYvu3FjNojaxo3DR5k89ljnZ5tu3uzQrxO3+M1K9OijsM8+Y3tOqy+IWbN2nzZvXuvnO+DNLX6zEi1YsOvjVkfkjDbEwFjHg3fwm1v8ZhXT7iIgEa2HFh7rTsd+2klp41NKi1/SXpKukvQLSXdLel4ZdZj1krFcEat5mSoMlWzV0VHwSzpX0lxlPi/pNkkvmcB6Pwn8R0Q8DXgmcPcEXsusJ0205d2Ll/yzaui0xX9WRGwAXgLsDfwl8KHxrFDSPOBY4PMAEbEtIh4bz2uZ9YuxtsSrOPa99Y5Og7/xETsJuCwi7sxNG6uDgNXAJZJ+KukiSbsdkyDpbElLJS1dvXr1OFdl1jsaXTHbt8P69e27ZtxdYxPVafAvk3QdWfB/V9IcYLw/NKcBRwKfiYgjgE3Aec0LRcSFEbE4IhYPDg6Oc1Vm1ZQ/vr45yKdNg7lzhx+7S8cmW6dH9bwROBxYERGbJT0BeMM41/kQ8FBE3JweX0WL4DfrZ2O5YHe+S2fTpsmvxepnxI+fpCObJh2sCXYsRsQjkn4j6akRcQ9wPHDXhF7UrIeM59qt7t6xyTRau+Oj6e8M4FnAHWR9+88AlgLjPQzzfwBfkrQHsILx/3ow6ynbtsGee5ZdhdXdiMEfES8AkHQ18KyI+Hl6fBhwwXhXGhG3A4vH+3yzXtUc+m7JWxk63bn71EboA0TEcuDp3SnJrB4c+laWTncx/VzSRcDl6fFrybp9zMysx3Qa/GcCbwXOTY+XAJ/pRkFm/coXMreqGDX4JU0FvpP6+z/e/ZLMzKybRu3jj4idwFAaasHMzHpcp109G8n6+a8nO9MWgIg4pytVmZlZ13Qa/Fenm5mNQ75/fzwncJlNpo6CPyIu7XYhZnXR6mIqZkXqKPglHQL8I3Ao2Vm8AETEwV2qy8zMuqTTtsclZIdv7gBeAHyR4WP6zWwEHjffqqbT4B+IiO8BiogHI+IC4GXdK8usP/n4fauCTnfubpU0BbhX0tuBh4HZ3SvLzMy6pdMW/7nATOAcslE6Xwec0a2izPqFW/hWRZ22+NdGxEay4/k9hLJZh/JH8PhLwKqi0+C/WNL+wK3Aj4Al+dE6zcysd3R6HP/z00VTng0cB1wjaXZEzO9mcWa9ykfyWJV1ehz/McB/T7e9gH8na/mbWY4D33pBp109PwSWkZ3EdW1EbOtaRWZ9aP36siswG9Zp8C8AjgaOBc6RNATcFBHv61plZj1mzZr28+bOLa4Os9F02sf/mKQVwJOA/YGjgOndLMyslzR38ezc6TF5rLo67eNfAfwCuJFs6IY3uLvH+lWnV8ratAlmtzmN0aFvVdZpV89TImKoq5WYVcCmTbs+jmi/w7Zd6JtVXaftkqdI+p6k5QCSniHpvV2sy6wUzWE+ZUoW/M3h3+rLYMeO7IvCJ2pZ1XUa/J8Dzge2A0TEHcBp3SrKrAyjHXnT+AJo9wtg6tTJr8msGzrt6pkZEbdo10/8ji7UY1aKiRx/7xa+9ZpOW/xrJD0ZCABJpwAru1aVWYEmEtw73PyxHtRpi/9twIXA0yQ9DNwPvLZrVZkVpFVLv/mLoN2vge3b3b1jvanT4/hXAC+SNIvsV8Jmsj7+B7tYm1lXtQr05qN6oPWRPe7esV42YlePpLmSzpf0aUkvJgv8M4D7gL8ookCzbtjW4iyUVatg5szWyzeO1tm0CYZ8YLP1uNFa/JcB64CbgDcD7wEE/FlE3D6RFUuaCiwFHo6Il0/ktczGas89d582ODj689p9MZj1ktGC/+CI+BMASReR7dA9ICJ+PwnrPhe4G/AoJlYqd9tY3Yx2VM/2xp2I2Ak8NBmhny7q8jLgoom+llknGsff79jhoZPNRmvxP1PShnRfwEB6LCAiYryt9U8A7wLmjPP5Zh3buXP4/vSmoQXd2rc6GjH4I2LSD1aT9HJgVUQsk3TcCMudDZwNcMABB0x2GVYTbt2b7a6MMQSPBv5U0gPAlcALJV3evFBEXBgRiyNi8WAne93MxshH51hdFR78EXF+ROwfEYvIzgX4fkS8rug6rP+tXbvr43y3zkijbpr1u07P3DWrpIhsh22+736kcfLdp29WcvBHxA/JrudrNmbtzqZtFfoOfLNhvk6Q9YxNm0YeGrnddIe+2a4c/NYzxnPFK4e+2e4c/NYTxrMj1qFv1pqD33pau3B36Ju15+C3SmvVb799O2zZMhzujZEz163zNW/NOuHDOa0SduzILmoyZcqu05o1Qn1ai0/uXnt1pzazfuPgt0poHkMHWoe7mU2cu3qsdD6D1qxYDn4rVaehPzTkvnuzyeLgt0rq9ILnZjZ27kW1ytm6NfvrFr5Zdzj4rTK2bWu9k9fMJpeD30qT775x696sOO7jNzOrGQe/lcI7a83K4+C3wm3evOvj7dvLqcOsrtzHb4Vq1dL3GbpmxXKL38ysZtzWskK069P30TxmxXOL37oiP5xyq9DfutWhb1YWB79Nqohdg75dS3+PPYqpx8x25+C3STXFnyizynMfvxXK3Ttm5XP7zAqxebND36wqHPw2Lo2dt40+/PXrdx97J2J4HP2BgXLqNLPduavHOpIP9eYzbUcafsFDM5hVj1v8NmajDZ3sLh2zanPw26jWr+982Ucf7V4dZjY5HPw2oqEh2GuvzpefP797tZjZ5HAfv41o6tSR57tbx6z3FN7il/QkST+QdJekOyWdW3QN1plWO2YjhrtzHPpmvamMFv8O4G8j4jZJc4Blkq6PiLtKqMXaaBX627Zlf+fPd+ib9bLCW/wRsTIibkv3HwfuBhYWXYe11i7QI3whdLN+UerOXUmLgCOAm1vMO1vSUklLV69eXXRptTVlyu6tfbfuzfpLacEvaTbwNeAdEbGheX5EXBgRiyNi8eDgYPEF1lC7Pn0z6y+lBL+k6WSh/6WIuLqMGuoqP9SCBBs2DE83s3oo46geAZ8H7o6IjxW9/l7WPD7OeJ7fbN681tO3b3dr36xfldHiPxr4S+CFkm5Pt5NKqKOnTeQLoBO+ALpZ/yr8v3dE3AgU2rHQCMitW7t75afGejZsgDlzWi8TMXyxknyLuvHc5lb2jh0jH00jjd4yH+sXxNDQ2JY3s97S9+26fOjtuefkd1+0CtW5c3d9nF9n/gpVjdBu9RpjCet24T80NPKZtzt3Ds/fvt2tfLO68H/1cdqxA5YvH9tzOgn4ifbf578A2oX+li0wY8buy5tZPTj4x2ksJzNJE+8+2bw5C+tGwG/ZAjNntl5XOw55M4M+H52z+YIhkPXzF6E5ZCd6EfKBgV1DfWBgbEHu0Dezhr4O/lY7chtdHBPR6szWoaHhywyOFrIjzX/wwd2XnWhoj2U8fTPrf7Xs6mkE9+bNnV0LNr8Dtt1wBu3Oem2e3ujyaX7ezp3DvwqGhuDxx3ffSdyuttWrYcGC1r8q3NI3s2Z93eIfzcyZux8PPzS061mt0vD4NePZ8docvK2+OPKHeDaW6ST0GwYHs+fku7Ym45eCmfWnWrb4W2l3VutIxrrDtttBPG2aw97MRleb4G93vPxEXq8by5qZdVutunoa3R+N28aN8NBDoz/PZ7KaWT+pTYu/lVmzslurFnn+14HHpzezflLr4B9Jc7g3fiV4+GIz63W16uqZKIe+mfUDB7+ZWc04+M3MasbBb2ZWMw5+M7OacfCbmdWMg9/MrGYc/GZmNePgNzOrGQe/mVnNOPjNzGqmFsG/c2fZFZiZVUctgn+iFzo3M+snjkQzs5px8JuZ1YyD38ysZhz8ZmY1U0rwS3qppHsk3SfpvDJqMDOrq8KDX9JU4F+AE4FDgddIOrToOszM6qqMFv9zgPsiYkVEbAOuBE4uoQ4zs1oqI/gXAr/JPX4oTduFpLMlLZW0dPXq1YUVZ2bW7yq7czciLoyIxRGxeHBwcJyvkd3MzGxYGcH/MPCk3OP90zQzMytAGcF/K3CIpIMk7QGcBnyrhDrMzGppWtErjIgdkt4OfBeYClwcEXcWXYeZWV0VHvwAEXEtcG0Z6zYzq7vK7tw1M7PucPCbmdWMg9/MrGYc/GZmNaPogTOcJK0GHhzn0xcAayaxnG7rpXp7qVborXp7qVborXrrVOuBEbHbGbA9EfwTIWlpRCwuu45O9VK9vVQr9Fa9vVQr9Fa9rtVdPWZmtePgNzOrmToE/4VlFzBGvVRvL9UKvVVvL9UKvVVv7Wvt+z5+MzPbVR1a/GZmluPgNzOrmb4O/ipe1F3SA5J+Lul2SUvTtPmSrpd0b/q7d5ouSZ9K9d8h6cgC6rtY0ipJy3PTxlyfpDPS8vdKOqPAWi+Q9HDavrdLOik37/xU6z2STshN7/rnRNKTJP1A0l2S7pR0bppe1W3brt7KbV9JMyTdIulnqdYPpOkHSbo5rfcraRh4JO2ZHt+X5i8a7T0UVO8XJN2f27aHp+mT/1mIiL68kQ35/CvgYGAP4GfAoRWo6wFgQdO0fwLOS/fPAz6c7p8EfAcQ8Fzg5gLqOxY4Elg+3vqA+cCK9HfvdH/vgmq9AHhni2UPTZ+BPYGD0mdjalGfE2Bf4Mh0fw7wy1RTVbdtu3ort33TNpqd7k8Hbk7b7N+A09L0zwJvTff/Gvhsun8a8JWR3kMXtm27er8AnNJi+Un/LPRzi7+XLup+MnBpun8p8Mrc9C9G5ifAXpL27WYhEbEEWDvB+k4Aro+ItRGxDrgeeGlBtbZzMnBlRGyNiPuB+8g+I4V8TiJiZUTclu4/DtxNdq3pqm7bdvW2U9r2TdtoY3o4Pd0CeCFwVZrevG0b2/wq4HhJGuE9TKoR6m1n0j8L/Rz8HV3UvQQBXCdpmaSz07R9ImJluv8IsE+6X5X3MNb6yq777ekn8cWNrpMRaiq81tS1cARZS6/y27apXqjg9pU0VdLtwCqyAPwV8FhE7Gix3j/UlOavB55QVK2t6o2Ixrb9+7RtPy5pz+Z6m+oad739HPxVdUxEHAmcCLxN0rH5mZH9hqvsMbZVrw/4DPBk4HBgJfDRcsvZlaTZwNeAd0TEhvy8Km7bFvVWcvtGxM6IOJzsGt7PAZ5Wckkjaq5X0mHA+WR1P5us++Z/d2v9/Rz8lbyoe0Q8nP6uAr5O9iH9XaMLJ/1dlRavynsYa32l1R0Rv0v/qYaAzzH8U730WiVNJwvRL0XE1WlyZbdtq3qrvH1TfY8BPwCeR9Yl0rjKYH69f6gpzZ8HPFp0rU31vjR1r0VEbAUuoYvbtp+Dv3IXdZc0S9Kcxn3gJcDyVFdjj/wZwDfT/W8Br0979Z8LrM91CxRprPV9F3iJpL1TV8BL0rSua9oH8mdk27dR62npiI6DgEOAWyjoc5L6kD8P3B0RH8vNquS2bVdvFbevpEFJe6X7A8CLyfZJ/AA4JS3WvG0b2/wU4Pvp11a79zCp2tT7i1wDQGT7I/LbdnI/C2PdI91LN7K94b8k6+97TwXqOZjsqIGfAXc2aiLrX/wecC/wn8D8GN77/y+p/p8Diwuo8Qqyn/DbyfoM3zie+oCzyHaO3Qe8ocBaL0u13JH+w+ybW/49qdZ7gBOL/JwAx5B149wB3J5uJ1V427art3LbF3gG8NNU03Lg/+T+v92SttNXgT3T9Bnp8X1p/sGjvYeC6v1+2rbLgcsZPvJn0j8LHrLBzKxm+rmrx8zMWnDwm5nVjIPfzKxmHPxmZjXj4DczqxkHv9WGpJ25kQ9v1ygjRUp6i6TXT8J6H5C0YKKvYzZZfDin1YakjRExu4T1PkB27PWaotdt1opb/FZ7qUX+T8quk3CLpKek6RdIeme6f46ysenvkHRlmjZf0jfStJ9Iekaa/gRJ1ykba/0ishNwGut6XVrH7ZL+Xxqsa6qysdiXpxr+poTNYDXi4Lc6GWjq6jk1N299RPwJ8GngEy2eex5wREQ8A3hLmvYB4Kdp2ruBL6bp7wdujIg/JhuP6QAASU8HTgWOjmyArp3Aa8kGPFsYEYelGi6ZxPdstptpoy9i1je2pMBt5Yrc34+3mH8H8CVJ3wC+kaYdA/w5QER8P7X055JdIOZVafo1ktal5Y8HngXcmg3HwgDZoGzfBg6W9M/ANcB143+LZqNzi98sE23uN7yMbLyUI8mCezyNJgGXRsTh6fbUiLggsotoPBP4IdmviYvG8dpmHXPwm2VOzf29KT9D0hTgSRHxA7Ix0ucBs4EfkXXVIOk4YE1kY9YvAU5P008kuyweZIOxnSLpiWnefEkHpiN+pkTE14D3kn25mHWNu3qsTgaUXfWo4T8ionFI596S7gC2Aq9pet5U4HJJ88ha7Z+KiMckXQBcnJ63meGhfj8AXCHpTuDHwK8BIuIuSe8luwLbFLJRRd8GbAEuSdMguyCHWdf4cE6rPR9uaXXjrh4zs5pxi9/MrGbc4jczqxkHv5lZzTj4zcxqxsFvZlYzDn4zs5r5/2pLqsUcKRBqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(torch.from_numpy(np.float32(history[:4, :, :]) / 255.).cuda().unsqueeze(0))\n",
    "            # action = agent.get_action(np.float32(history[:4, :, :]) /  /255.)\n",
    "        state = next_state\n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['ale.lives'])\n",
    "\n",
    "        life = info['ale.lives']\n",
    "        r = np.clip(reward, -1, 1) \n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"save_graph/breakout_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joQPoEGj6_Dh"
   },
   "source": [
    "# Visualize Agent Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OymoKdVU6_Dh"
   },
   "source": [
    "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
    "\n",
    "Please save your model before running this portion of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WlF9PvGJ6_Dh"
   },
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "70-E1Wmf6_Dh"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "sOFwDun-6_Di",
    "outputId": "37ba6a8e-4a19-4b43-863f-9f59b87d1dfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f406aae0510>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(torch.from_numpy(np.float32(history[:4, :, :]) / 255.).cuda().unsqueeze(0))\n",
    "        # action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['ale.lives'])\n",
    "        \n",
    "    life = info['ale.lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "MP5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
